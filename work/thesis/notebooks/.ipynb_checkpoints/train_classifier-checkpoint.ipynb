{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = True\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = False\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 14\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# training\n",
    "epochs = 100000\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 15000\n",
    "\n",
    "# train with previous model\n",
    "trainWithPreviousModel = False\n",
    "\n",
    "# include delta errors\n",
    "includeDeltaErrors = True\n",
    "\n",
    "# band\n",
    "# passband = [5]\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "# include ohter feautures\n",
    "includeOtherFeatures = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "batch_training_size = 128\n",
    "\n",
    "# early stopping \n",
    "threshold_early_stop = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp 14 + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0 + include delta errors + max by class 15000 +  other features\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"exp \" + number_experiment + \" + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed) + \" + \" + (\"include delta errors\" if includeDeltaErrors else \"without delta errors\") + \" + max by class \" + str(max_elements_per_class) + \" + \" + (\"\" if includeOtherFeatures else \"not\") + \" other features\"\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory /home/leo/Desktop/thesis/work/thesis/experiments/14/seed0/maxClass15k \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass\" + str(int(max_elements_per_class/1000)) + \"k\"\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets, lightCurvesIds = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# saving ids\n",
    "saveLightCurvesIdsBeforeBalancing(trainIdx, valIdx, testIdx, folder_path, lightCurvesIds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_before_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "        seed = seed\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx,\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx,\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[444. 420. 439. 474. 400. 443.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.ar# return 0# return 0ange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# save ids of dataset to use (train, test and validation)\n",
    "saveLightCurvesIdsAfterBalancing(trainLoader, train_size, testLoader, test_size, validationLoader, validation_size, path = folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_after_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment parameters file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "if trainingOnGuanaco or trainWithJustPython:\n",
    "    text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "    text = \"NÂ° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "    text_file.write(text)\n",
    "    text_file.close()\n",
    "    print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model with default parameters\n"
     ]
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "if trainWithPreviousModel:\n",
    "    \n",
    "    # loadgin model\n",
    "    model = torch.load(pathToSaveModel + \".txt\").to(device = cuda_device)\n",
    "    \n",
    "    print(\"loading saved model\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # defining model\n",
    "    model = EncoderClassifier(\n",
    "        latent_dim = latentDim, \n",
    "        hidden_dim = hiddenDim, \n",
    "        input_dim = inputDim, \n",
    "        num_classes = num_classes, \n",
    "        passband = passband, \n",
    "        includeDeltaErrors = includeDeltaErrors,\n",
    "        includeOtherFeatures = includeOtherFeatures,\n",
    "    )\n",
    "\n",
    "    # mdel to GPU\n",
    "    model = model.to(device = cuda_device)\n",
    "    \n",
    "    print(\"creating model with default parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=780, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 5\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 5\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 5\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    3 / 5\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    4 / 5\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizeraa\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "# prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = threshold_early_stop\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "        \n",
    "        # add other features\n",
    "        # [batch size, features]\n",
    "#         if includeOtherFeatures:\n",
    "        if includeOtherFeatures:\n",
    "            \n",
    "            otherFeatures = getOtherFeatures(data_[0]).to(device = cuda_device)\n",
    "        \n",
    "# #         # testing tensor size \n",
    "# #         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "# #         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data, includeDeltaErrors, otherFeatures)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "    \n",
    "#         print(np.any(torch.isnan(outputs).numpy()))\n",
    "        \n",
    "#         # data validation\n",
    "#         if np.any(torch.isnan(outputs).cpu().numpy()) or np.any(torch.isinf(outputs).cpu().numpy()):\n",
    "            \n",
    "#             print(\"invalid input detected at iteration \", nepoch)\n",
    "            \n",
    "#             print(\"data: \", data)\n",
    "            \n",
    "#             print(\"outputs \", outputs)\n",
    "            \n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "    \n",
    "        if includeOtherFeatures:\n",
    "            \n",
    "            otherFeatures = getOtherFeatures(data_[0]).to(device = cuda_device)\n",
    "        \n",
    "# #         # testing tensor size \n",
    "# #         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "# #         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data, includeDeltaErrors, otherFeatures)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "\n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    #### save losses ####\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ### save f1 scores ####\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    # If minimum global validation error does not decrease in X epochs, so stop training\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the min valid error\n",
    "    if test_loss[nepoch] > minTestLossGlobalSoFar:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "        \n",
    "    # if it is smaller\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop >= threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n\".format(nepoch, count_early_stop)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n",
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(\n",
    "    trainLoader, \n",
    "    nameLabel = \"Train\", \n",
    "    passband = passband, \n",
    "    model = model, \n",
    "    staticLabels = only_these_labels, \n",
    "    number_experiment = number_experiment, \n",
    "    expPath = expPath, \n",
    "    includeDeltaErrors = includeDeltaErrors, \n",
    "    includeOtherFeatures = includeOtherFeatures\n",
    ")\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, \n",
    "                                    nameLabel = \"Validation\", \n",
    "                                    passband = passband, \n",
    "                                    model = model, \n",
    "                                    staticLabels = only_these_labels, \n",
    "                                    number_experiment = number_experiment, \n",
    "                                    expPath = expPath, \n",
    "                                    includeDeltaErrors = includeDeltaErrors, \n",
    "                                    includeOtherFeatures = includeOtherFeatures\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/11/seed2/maxClass15k/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "# losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "losses = pd.read_csv(folder_path + \"/training_losses.csv\")\n",
    "# f1 scores\n",
    "# f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass15k\" + \"/f1Scores.csv\")\n",
    "f1Scores = pd.read_csv(folder_path + \"/f1Scores.csv\")\n",
    "\n",
    "print(folder_path)\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "maxPlot = 6850\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"NÂ° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:maxPlot, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:maxPlot, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"NÂ° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores.iloc[:maxPlot])\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/11/seed2/maxClass15k/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {âtrueâ, âpredâ, âallâ}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv(folder_path  + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv(folder_path + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(folder_path)\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/11/seed2/maxClass15k/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/11/seed2/maxClass15k/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
