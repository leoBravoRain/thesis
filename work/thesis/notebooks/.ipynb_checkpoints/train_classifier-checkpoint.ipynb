{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = False\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = True\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 99\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# training\n",
    "epochs = 5\n",
    "\n",
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 25000\n",
    "\n",
    "# train with previous model\n",
    "trainWithPreviousModel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed)\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAR5ElEQVR4nO3dX4ycV53m8e+z9iDAgEJwbAXbSxvJGkBIIVErCcsIAVkQIWidiw0TtKPxoIx8E0RArFjP3qC5SyQ0/NGgSFYIGGkJiQJRLECByIPE3BC5m6xmEpIIK2OSxt64A0kIIG3Gw28v6m1Nb1wVt7u6+u0+9f1IVtU5dbrfX45OP/3m1PtWp6qQJLXlP/RdgCRp7RnuktQgw12SGmS4S1KDDHdJatDWvgsA2L59e83MzPRdhiRtKvPz889W1SXDXtsQ4T4zM8Pc3FzfZUjSppLkl6Nec1tGkhq0Ic7cJalPM4e+39uxT9563US+r2fuktQgw12SGmS4S1KD3HOXNqi+9oEntQes9eWZuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQl0KOwUvVJG1UnrlLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUErCvckJ5P8c5L/nWSu67s4yYNJftE9vrHrT5KvJDmR5J+SXDHJ/wBJ0rku5Mz9/VX1rqqa7dqHgGNVtQ841rUBrgX2df8OArevVbGSpJUZZ1tmP3Cke34EuH5Z/zdr4KfARUkuHeM4kqQLtNJwL+BHSeaTHOz6dlbVaYDucUfXvwt4etnXLnR9/58kB5PMJZlbXFxcXfWSpKFW+sc63lNVp5LsAB5M8vgrjM2Qvjqno+owcBhgdnb2nNclSau3ojP3qjrVPZ4B7gOuBJ5Z2m7pHs90wxeAPcu+fDdwaq0KliSd33nDPcm2JK9feg58CHgEOAoc6IYdAO7vnh8F/rK7auZq4IWl7RtJ0vpYybbMTuC+JEvjv1VVDyQ5DtyT5CbgKeCGbvwPgI8AJ4A/AJ9Y86olSa/ovOFeVU8Clw3p/zVwzZD+Am5ek+okSaviHaqS1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQef9A9kY3c+j7fZcgSRuOZ+6S1CDDXZIaZLhLUoMMd0lq0ETCPcmHkzyR5ESSQ5M4hiRptDW/WibJFuCrwAeBBeB4kqNV9fO1PpY0aV6Npc1qEmfuVwInqurJqnoJ+DawfwLHkSSNMInr3HcBTy9rLwBXvXxQkoPAwa75uyRPTKCWzWQ78OxKBua2CVey8ax4bqbMROalkfW1adbMmPP9llEvTCLcM6SvzumoOgwcnsDxN6Ukc1U123cdG5FzM5zzMppzM5ltmQVgz7L2buDUBI4jSRphEuF+HNiXZG+SVwE3AkcncBxJ0ghrvi1TVWeTfBL4IbAFuLOqHl3r4zTILarRnJvhnJfRpn5uUnXOdrgkaZPzDlVJapDhLkkNMtzXWZI9SX6c5LEkjya5peu/OMmDSX7RPb6x71r7kmRLkoeTfK9r703yUDc3d3dv1E+dJBcluTfJ4936ebfrZiDJZ7qfp0eS3JXk1dO+bgz39XcW+GxVvR24Grg5yTuAQ8CxqtoHHOva0+oW4LFl7duAL3Zz8xxwUy9V9e/LwANV9TbgMgZzNPXrJsku4FPAbFW9k8GFHDcy5evGcF9nVXW6qn7WPX+RwQ/oLgYf0XCkG3YEuL6fCvuVZDdwHXBH1w7wAeDebshUzk2SNwDvBb4GUFUvVdXzuG6WbAVek2Qr8FrgNFO+bgz3HiWZAS4HHgJ2VtVpGPwCAHb0V1mvvgR8Dvhj134T8HxVne3aCwx+GU6btwKLwNe7Las7kmzDdUNV/Qr4AvAUg1B/AZhnyteN4d6TJK8DvgN8uqp+23c9G0GSjwJnqmp+efeQodN4/e5W4Arg9qq6HPg9U7gFM0z3PsN+YC/wZmAbcO2QoVO1bjbEde7bt2+vmZmZvsuQpE1lfn7+2aq6ZNhrk/jgsAs2MzPD3Nxc32VI0qaS5JejXnNbRpIatCHO3CWpT33+xa2Tt143ke/rmbskNchwl6QGGe6S1KDz7rknuRNYuv74nV3fxcDdwAxwEvhYVT3X3U34ZeAjwB+Av1q6G1PShelrH3hSe8BaXys5c/8G8OGX9Y36PItrgX3dv4PA7WtTpiTpQpw33KvqJ8BvXtY96vMs9gPfrIGfAhcluXStipUkrcxq99xHfZ7FLuDpZeNGfp5DkoNJ5pLMLS4urrIMSdIwa/2G6oo/B6SqDlfVbFXNXnLJ0LtnJUmrtNpwf2Zpu6V7PNP1LwB7lo3bDZxafXmSpNVY7R2qR4EDwK3d4/3L+j+Z5NvAVcALS9s3LfJqBkkb1UouhbwLeB+wPckC8HkGoX5PkpsYfIbyDd3wHzC4DPIEg0shPzGBmiVJ53HecK+qj4946ZohYwu4edyiJEnj8Q5VSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNWu0fyAYgyUngReDfgLNVNZvkYuBuYAY4CXysqp4br0xJ0oVYizP391fVu6pqtmsfAo5V1T7gWNeWJK2jSWzL7AeOdM+PANdP4BiSpFcwbrgX8KMk80kOdn07q+o0QPe4Y9gXJjmYZC7J3OLi4phlSJKWG2vPHXhPVZ1KsgN4MMnjK/3CqjoMHAaYnZ2tMeuQJC0z1pl7VZ3qHs8A9wFXAs8kuRSgezwzbpGSpAuz6nBPsi3J65eeAx8CHgGOAge6YQeA+8ctUpJ0YcbZltkJ3Jdk6ft8q6oeSHIcuCfJTcBTwA3jlylJuhCrDveqehK4bEj/r4FrxilKkjQe71CVpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0Lh/ial3M4e+33cJkrTheOYuSQ0y3CWpQYa7JDXIcJekBk0k3JN8OMkTSU4kOTSJY0iSRlvzq2WSbAG+CnwQWACOJzlaVT9f62NJk+bVWNqsJnHmfiVwoqqerKqXgG8D+ydwHEnSCJO4zn0X8PSy9gJw1csHJTkIHOyav0vyxARq2Uy2A8+uZGBum3AlG8+K52bKTGReGllfm2bNjDnfbxn1wiTCPUP66pyOqsPA4Qkcf1NKMldVs33XsRE5N8M5L6M5N5PZllkA9ixr7wZOTeA4kqQRJhHux4F9SfYmeRVwI3B0AseRJI2w5tsyVXU2ySeBHwJbgDur6tG1Pk6D3KIazbkZznkZbernJlXnbIdLkjY571CVpAYZ7pLUIMN9nSXZk+THSR5L8miSW7r+i5M8mOQX3eMb+661L0m2JHk4yfe69t4kD3Vzc3f3Rv3USXJRknuTPN6tn3e7bgaSfKb7eXokyV1JXj3t68ZwX39ngc9W1duBq4Gbk7wDOAQcq6p9wLGuPa1uAR5b1r4N+GI3N88BN/VSVf++DDxQVW8DLmMwR1O/bpLsAj4FzFbVOxlcyHEjU75uDPd1VlWnq+pn3fMXGfyA7mLwEQ1HumFHgOv7qbBfSXYD1wF3dO0AHwDu7YZM5dwkeQPwXuBrAFX1UlU9j+tmyVbgNUm2Aq8FTjPl68Zw71GSGeBy4CFgZ1WdhsEvAGBHf5X16kvA54A/du03Ac9X1dmuvcDgl+G0eSuwCHy927K6I8k2XDdU1a+ALwBPMQj1F4B5pnzdGO49SfI64DvAp6vqt33XsxEk+Shwpqrml3cPGTqN1+9uBa4Abq+qy4HfM4VbMMN07zPsB/YCbwa2AdcOGTpV62ZDXOe+ffv2mpmZ6bsMSdpU5ufnn62qS4a9NokPDrtgMzMzzM3N9V2GJG0qSX456jW3ZSSpQRvizF2S+tTnX9w6eet1E/m+nrlLUoMMd0lq0HnDPcmdSc4keWRZ39BbnjPwlSQnkvxTkismWbwkabiV7Ll/A/h74JvL+pZueb41yaGu/T8YXFu6r/t3FXA7Q/5+qqTz62sfeFJ7wFpf5z1zr6qfAL95WfeoW573A9+sgZ8CFyW5dK2KlSStzGr33Efd8rwLeHrZuJG3/CY5mGQuydzi4uIqy5AkDbPWb6iu+FbxqjpcVbNVNXvJJUNvsJIkrdJqw/2Zpe2W7vFM178A7Fk2bjdwavXlSZJWY7XhfhQ40D0/ANy/rP8vu6tmrgZeWNq+kSStn/NeLZPkLuB9wPYkC8DngVuBe5LcxOBjNm/ohv8A+AhwAvgD8IkJ1LxheDWDpI3qvOFeVR8f8dI1Q8YWcPO4RUmSxuMdqpLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGnTeP7P3SpKcBF4E/g04W1WzSS4G7gZmgJPAx6rqufHKlCRdiLU4c39/Vb2rqma79iHgWFXtA451bUnSOprEtsx+4Ej3/Ahw/QSOIUl6BeOGewE/SjKf5GDXt7OqTgN0jzuGfWGSg0nmkswtLi6OWYYkabmx9tyB91TVqSQ7gAeTPL7SL6yqw8BhgNnZ2RqzDknSMmOduVfVqe7xDHAfcCXwTJJLAbrHM+MWKUm6MKsO9yTbkrx+6TnwIeAR4ChwoBt2ALh/3CIlSRdmnG2ZncB9SZa+z7eq6oEkx4F7ktwEPAXcMH6ZkqQLsepwr6ongcuG9P8auGacoiRJ4/EOVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAaN+5eYejdz6Pt9lyBJG45n7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDZpIuCf5cJInkpxIcmgSx5Akjbbml0Im2QJ8FfggsAAcT3K0qn6+1seSJs1LbbVZTeLM/UrgRFU9WVUvAd8G9k/gOJKkESZxE9Mu4Oll7QXgqpcPSnIQONg1f5fkiQnUsplsB55dycDcNuFKNp4Vz82Umci8NLK+Ns2aGXO+3zLqhUmEe4b01TkdVYeBwxM4/qaUZK6qZvuuYyNyboZzXkZzbiazLbMA7FnW3g2cmsBxJEkjTCLcjwP7kuxN8irgRuDoBI4jSRphzbdlqupskk8CPwS2AHdW1aNrfZwGuUU1mnMznPMy2tTPTarO2Q6XJG1y3qEqSQ0y3CWpQYb7OkuyJ8mPkzyW5NEkt3T9Fyd5MMkvusc39l1rX5JsSfJwku917b1JHurm5u7ujfqpk+SiJPcmebxbP+923Qwk+Uz38/RIkruSvHra143hvv7OAp+tqrcDVwM3J3kHcAg4VlX7gGNde1rdAjy2rH0b8MVubp4Dbuqlqv59GXigqt4GXMZgjqZ+3STZBXwKmK2qdzK4kONGpnzdGO7rrKpOV9XPuucvMvgB3cXgIxqOdMOOANf3U2G/kuwGrgPu6NoBPgDc2w2ZyrlJ8gbgvcDXAKrqpap6HtfNkq3Aa5JsBV4LnGbK143h3qMkM8DlwEPAzqo6DYNfAMCO/irr1ZeAzwF/7NpvAp6vqrNde4HBL8Np81ZgEfh6t2V1R5JtuG6oql8BXwCeYhDqLwDzTPm6Mdx7kuR1wHeAT1fVb/uuZyNI8lHgTFXNL+8eMnQar9/dClwB3F5VlwO/Zwq3YIbp3mfYD+wF3gxsA64dMnSq1o3h3oMkf8Ig2P9XVX23634myaXd65cCZ/qqr0fvAf5LkpMMPk30AwzO5C/q/ncbpvfjLBaAhap6qGvfyyDsXTfwn4F/qarFqvpX4LvAf2LK143hvs66PeSvAY9V1d8te+kocKB7fgC4f71r61tV/U1V7a6qGQZviP1DVf034MfAf+2GTevc/B/g6SR/2nVdA/wc1w0MtmOuTvLa7udraW6met14h+o6S/JnwD8C/8y/7yv/Twb77vcA/5HBYr2hqn7TS5EbQJL3Af+9qj6a5K0MzuQvBh4G/qKq/m+f9fUhybsYvNH8KuBJ4BMMTtCmft0k+VvgzxlcjfYw8NcM9tindt0Y7pLUILdlJKlBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0P8DAiYiu18Co/QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[440. 433. 407. 440. 464. 436.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed)\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "text = \"NÂ° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "text_file.write(text)\n",
    "text_file.close()\n",
    "print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model with default parameters\n"
     ]
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "if trainWithPreviousModel:\n",
    "    \n",
    "    # loadgin model\n",
    "    model = torch.load(pathToSaveModel + \".txt\").to(device = cuda_device)\n",
    "    \n",
    "    print(\"loading saved model\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # defining model\n",
    "    model = EncoderClassifier(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes, passband = passband)\n",
    "\n",
    "    # mdel to GPU\n",
    "    model = model.to(device = cuda_device)\n",
    "    \n",
    "    print(\"creating model with default parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 5\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 5\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 5\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    3 / 5\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    4 / 5\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizera\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "\n",
    "#         # testing tensor size \n",
    "#         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "#         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        \n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "    \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "        \n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # save f1 scores\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "new error\n",
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new error\n",
      "new error\n",
      "new error\n",
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(trainLoader, nameLabel = \"Train\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, nameLabel = \"Validation\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/f1Scores.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"NÂ° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"NÂ° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores)\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {âtrueâ, âpredâ, âallâ}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
