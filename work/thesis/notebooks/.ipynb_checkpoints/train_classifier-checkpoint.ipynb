{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = False\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = True\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 99\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# training\n",
    "epochs = 4\n",
    "\n",
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 1000\n",
    "\n",
    "# train with previous model\n",
    "trainWithPreviousModel = False\n",
    "\n",
    "# include delta errors\n",
    "includeDeltaErrors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed)\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[407. 456. 398. 454. 468. 437.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed)\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "text = \"NÂ° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "text_file.write(text)\n",
    "text_file.close()\n",
    "print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model with default parameters\n"
     ]
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "if trainWithPreviousModel:\n",
    "    \n",
    "    # loadgin model\n",
    "    model = torch.load(pathToSaveModel + \".txt\").to(device = cuda_device)\n",
    "    \n",
    "    print(\"loading saved model\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # defining model\n",
    "    model = EncoderClassifier(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes, passband = passband, includeDeltaErrors = includeDeltaErrors)\n",
    "\n",
    "    # mdel to GPU\n",
    "    model = model.to(device = cuda_device)\n",
    "    \n",
    "    print(\"creating model with default parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 4\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([60, 6, 4, 71])\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 4\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([60, 6, 4, 71])\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 4\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([60, 6, 4, 71])\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    3 / 4\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([128, 6, 4, 71])\n",
      "torch.Size([60, 6, 4, 71])\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizera\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "\n",
    "#         # testing tensor size \n",
    "#         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "#         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data, includeDeltaErrors)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "    \n",
    "        outputs = model.forward(data, includeDeltaErrors)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "    \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "        \n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # save f1 scores\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(trainLoader, nameLabel = \"Train\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath, includeDeltaErrors = includeDeltaErrors)\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, nameLabel = \"Validation\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath, includeDeltaErrors = includeDeltaErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/f1Scores.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"NÂ° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"NÂ° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores)\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {âtrueâ, âpredâ, âallâ}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
