{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = True\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = True\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 99\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# training\n",
    "epochs = 10\n",
    "\n",
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 1000\n",
    "\n",
    "# train with previous model\n",
    "trainWithPreviousModel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed)\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[440. 455. 423. 444. 422. 436.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed)\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "text = \"NÂ° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "text_file.write(text)\n",
    "text_file.close()\n",
    "print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "if trainWithPreviousModel:\n",
    "    \n",
    "    # loadgin model\n",
    "    model = torch.load(pathToSaveModel).to(device = cuda_device)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # defining model\n",
    "    model = EncoderClassifier(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes, passband = passband)\n",
    "\n",
    "    # mdel to GPU\n",
    "    model = model.to(device = cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 10\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 10\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 10\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    3 / 10\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    4 / 10\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    5 / 10\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    6 / 10\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    7 / 10\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    8 / 10\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    9 / 10\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAADQCAYAAAD4dzNkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU9fX4/9fJRgIhhFXRAEFWsSJqRHFFRAuoaN1ww426tLVqXeuvLv1obWut1dbtK251rQtuqCgiYhWLCIqCimhAhCD7nkD28/tj7ix3MpNMkrmzkPP0MY/c93vufc+ZyOTMvfe9iKpijDHGmPSSkewAjDHGGNN8lsCNMcaYNGQJ3BhjjElDlsCNMcaYNGQJ3BhjjElDlsCNMcaYNORpAheRMSKyRERKReT3EZ5vJyIvOM/PFZFip76riMwSkXIRuT/smBwRmSwi34nItyJyqlN/gYisF5EvnMcvvXxvxhhjTDJledWwiGQCDwDHAmXAPBGZqqrfhOw2Cdisqv1F5EzgTmACUAncDPzMeYT6A7BOVQeKSAbQJeS5F1T1cm/ekTHGGJM6vDwDHw6UquoyVa0GngdOCtvnJOBJZ3sKcIyIiKpWqOpsfIk83EXAXwBUtV5VN3gTvjHGGJO6PDsDB/YEVoaUy4CDo+2jqrUishXoCkRMyiJS6GzeLiIjgaXA5aq61qk/VUSOBL4DfqeqKyO0cQlwCUCHDh0OHDx4cAvemjGp7bPPPtugqt2THUcidevWTYuLi5MdhjFxF+3z7GUClwh14fO2xrJPqCygCPhYVa8WkauBvwMTgTeA/6hqlYhchu/MflSDxlUnA5MBSkpKdP78+U2+EWPSjYj8mOwYEq24uBj7PJtdUbTPs5eX0MuAXiHlIuCnaPuISBbQCdjUSJsbgR3Aq075JeAAAFXdqKpVTv0jwIGtCd4YY4xJZV4m8HnAABHpKyI5wJnA1LB9pgLnO9unAe9rI6urOM+9AYx0qo4BvgEQkZ4hu44HFrf2DRhjjDGpyrNL6M497cuB6UAm8Liqfi0itwHzVXUq8BjwtIiU4jvzPtN/vIgsBwqAHBE5GTjO6cF+g3PMvcB64ELnkCtEZDxQ67R1gVfvzRhjjEk2L++Bo6rTgGlhdbeEbFcCp0c5tjhK/Y/AkRHqbwRubEW4aWlb1TZqa2rpkt+l6Z1N2lFVquqqKK8up6K6gvLqcrIyshjUbVCyQzNtUL3W8+s3f83ArgO5+tCrkx1Om+dpAjeRbavaxsylM/lo5Ud8t/E7Vm5dyfn7nd/gA5F5Wyb1Wh9Tm70KerHidytcdfJ/kfoIuonz320jb+MPR/0hUL+jZgeD7x9MTkYOOVk55GXlkZedR4fsDnTM6Uh+Tj6d8zrTObcz3dt35/z9z6d9dvuYYt1SuYWv1n1F6aZSlm1aRkVNBXf//G7XPrf/93b+MecfVNdXU1tfS119HaqK/7/Q+HMyc6i8yT3i8E8f/ol/zf0XOZk55GblBuLPz86nY7uOFLQroDC3kC55XRjUbRBn73u26/g15WtYs30NNfU1VNdVU1dfF9iuqa+hpq6G2vpaaupqKO5czOG9D3cdP3XJVBatXURdfR377rYvFTUVriQcKNdUcPqQ0zlh4Amu40954RRm/jCT8uryBv8GDu11KB9f9HFMv2tj4unC1y/kqS+fAuCOj+5g4w0bkxxR22YJvBGxJMDAvgj1t7r/0Dbn+Fs+uKVBAo81eQPkZeXFvG8of0Kc/5O79+7KrStZua3BKLyoenTowan7nBoo3/HhHdw066aYjw9P4O8te48tVVuaPE5RquuqG9S/v+x91u9YH9NrZ2VkNUjgE16awIcrPozp+MFdB7P4cneXi+tnXM+SjUtiOn5AlwENEvjO2p1sq9oWcf+K6oqY2jUm3p5Z+Exge1NlY/2NTSJYAk8RNfU1rTq+Q06HVh3fvb17iOFP28MHDDSuR4cervK6inWtiqdrXteY9xVp+EWpvKY85uMzIvTlzMzIjPn4ehp+0cqQ2PuHRkrI+Tn5ge2czBzyc/LpkN2B/Jx89uq8V8xtGxMvSzcsbXBSsXzLcooLi5MTkLEEnipyMnIa1LXPak91fTVZkkW7rHbk5+TTJbcLRQVFDOw2kEOLDmXMgDHkSm7ENk8eeDKbqzazrWobFdUV7KzdSVVtle8ScH0NdfV11NXXUU89x/Y/1nVslmQhiOtydWP6dO7jKm+t3BrjO/epra0lKyv4z/H4gccz84eZ5GTl0D6rPR2yO1CQW0CX3C70yO9Bz/ye9CnsQ01dDVnS8J/xhH0msLNmJztrd1JZW9ng0ne91lOv9ShKYW5hg+M7tesUSMKCBL4k+LdDf+7Zcc8Gx+/dbW/WVqwlQzIYUTSCju06BhJw4GeO7+d+u+3X4PjJJ0zmkRMfoUN2B7Izs5v1uzTGC2OeG9Og7rI3L+Odc99JQjQGQBoZtbXLa2oil6unX82itYvIkAwyJZOMjAwyMzLJkiwyJIOsjCyyMrLIlExGFo/kgv0vcB3/4KcPUra1jKxM337tMtrRu7A3xw86noJ2BR6/u+TaUbODuWVzWVu+ljUVa6ipq6Ff537s02Mf+hX2cyVrE38i8pmqliQ7jkSyiZm8FemWYF5WHjv+sCMJ0bQt0T7P9le0Ef/4+T9adfyvh/86TpGkn/bZ7Tm679HJDsMYEwdvf/92xPqdtTsTHIkJZeuBG2OMadR5r54X9bn7PrkvgZGYUJbAjTHGNGrDzuD6Uh1zOiIhy1jcNeeuZIRksARujDGmEX/96K+u8p3H3OnquFm2rSzRIRmHJXBjjDFR3f7h7a7yr4b/imsOvSZQVpTlW5YnOCoDlsCNMcY0YkdtsJf57vm7A3DVIVe59rn0jUsTGpPxsQRujDEmovNecXdee/HUFwPbobM/frTio4TFZIIsgRtjjIno+a+fD2wLwhHFRwTKR/QObttwsuSwBG6MMaaBHTU7XFM8D+k+xPX8wyc+7Crf+8m9CYnLBFkCN8YY08CxT7mnV55xzgxXubiw2DWc7O7/uRckMt6zBG6MMaaBOWVzAtsZkkHPTj0b7FNUUBTYXrV9VULiMkGWwI0xxrgs2bDEtZDRcXsdF3G/60ZcF9i24WSJZwncGGOMy9hnx7rKUydMjbjfbw/5rat88dSLPYvJNGQJ3BhjjMsPW34IbOdk5JCdHX1J29DhZLNXzPY0LuNmCdwYY0zAa4tfc5V/fVDjqyoe2efIwHZlXaUnMZnILIEbY4wJmDR1kqt8z5h7Gt3/0RMedZXvmm2LmySKJXBjTKuIyBgRWSIipSLy+wjPXy0i34jIQhGZKSJ9nPo+IvKZiHwhIl+LyGUhxxwoIoucNv8lIhLervHGpspNge2CnIIm9y8qLHINJ7v3UxsPniiWwI0xLSYimcADwFhgCHCWiAwJ220BUKKqQ4EpwN+c+tXAoao6DDgY+L2I7OE89xBwCTDAeYzx9I0YAG774DZX+Z6fN3727deroFdge/X21XGNyURnCdwY0xrDgVJVXaaq1cDzwEmhO6jqLFX1r4jxCVDk1FerapVT3w7n75GI9AQKVHWOqirwFHCy92/F/PVj99KhFx1wUUzHXX/Y9YFtRSndWBrXuExklsCNMa2xJ7AypFzm1EUzCXjbXxCRXiKy0GnjTlX9yTk+dJHpqG2KyCUiMl9E5q9fv76Fb8EA1NTUuOY0D13zuym/Gf4bV/mSNy+JW1wmOkvgxpjWiHRvWiPUISLnAiVAoJeTqq50Lq33B84Xkd2a06aqTlbVElUt6d69e7ODN0ETX5voKr864dVmHR86nGzOyjmN7GnixRK4MaY1yoBeIeUi4KfwnURkNPAHYHzIZfMA58z7a+AIp82ikKcjtmni6+XFLwe2BeGgPQ9q1vEj+4wMbNtwssTwNIHH0Du1nYi84Dw/V0SKnfquIjJLRMpF5P6wY3JEZLKIfCci34rIqY21ZYzx1DxggIj0FZEc4EzANW2XiOwPPIwvea8LqS8SkTxnuzNwGLBEVVcD20XkEKf3+XnA64l5O23T1h1bqdXaQHm/3fZrdhuTT5jsKv/1o79G2dPEi2cJPMbeqZOAzaraH7gHuNOprwRuBq6N0PQfgHWqOtBp979NtGWM8Yiq1gKXA9OBxcCLqvq1iNwmIuOd3e4C8oGXnCFj/gS/NzBXRL7E9zn+u6oucp77FfAoUAosJeS+eSrYWbOT4546jvXbdo377sc+E7by2HkzouwZXVFhERkhKeW+T+9rdVwt9cPmH7j9v7ezsWJj0mJIhCwP2w70TgUQEX/v1G9C9jkJ+KOzPQW4X0REVSuA2SLSP0K7FwGDAVS1HtjQRFsR750ZY+JDVacB08LqbgnZHh3luBnA0CjPzQd+Fscw46r9n9sD0OOeHrx42oucvs/pSY6odeavnh/YzpRMurXv1qJ2ijoVsWLrCgBWlydvONnIf49kxbYV3PrBrTw2/jEu3P/CpMXiJS8vocfSOzWwj/NNfivQNVqDIlLobN4uIp+LyEtOp5eY27Jeq8aY1ij4i3tyk19O/WWSIomPL1Z/4Vp57PgBx7e4rRsPuzGwrShLNixpVWwt8e7Sd1mxbUUghie/fDLhMSSKlwk8lp6kMfc2dWTh69DysaoeAMwB/t6ctqzXqjGmpa546wq2V2931W2r3pakaOLjpBdcw/aZctqUFrd12UGXucqXvnlpi9tqqfNePc9Vnr1iNjuqd0TZO715mcBj6Z0a2EdEsoBOwCai2wjsAPzjG14CDmhhW8YYE7MtlVu4b37y7ut6xX/JGyA3K7fRlcdi0T6rfWB7btncVrXVXJ+WfcrairWuujqt44p3rkhoHIniZQJvsneqUz7f2T4NeL+xe9bOc28AI52qYwjeU29WW8YY0xxd7uwS9bkJL05IYCTx88KiF1zlqw6+qtVtjuo7KrBdWVdJbW1tI3vH1xlTzohY//SXT1NdW52wOBLFswQeY+/Ux4CuIlIKXA0EhpqJyHLgH8AFIlIW0oP9BuCPzuxNE4FrmmrLGGNaY+iDQ133icO9suSVBEYTP5dNc1/y/svov7S6zUfGP+Iq3/m/xAwI+m7Dd/y49cdA+dCiQwPb1fXV3Pj+jZEOS2uejgNX1WmqOlBV+6nqHU7dLao61dmuVNXTVbW/qg7391h3nitW1S6qmq+qRar6jVP/o6oeqapDVfUYVV3RVFvGGNNSb3//NovWL3LVLbh0AdkZwUvNtfWJO8uMpy2VWwLbhe0KG9kzdrvn7+4aTvbAvAfi0m5Twu/lz5g4w5XEH5r3EPX19QmJJVFsJjZjjGnEuOfGucqj+45m2O7DOHfoua762T/OTmRYrXbT+ze5yvePuz/Kns3Xu7B3YHtN+Zq4tRvNmvI1fLvh20D5kD0PoX1OeyafGJxcZmftTu746A7PY0kkS+DGGBNF/p/zXeUsyQpMcvL4SY+7njv1xVMTFlc83D3nblf5nKHnxK3tm44IfjlIxHCyE547wVWeeqavu9U+PfZxzSr39zl/Z1diCdwYYyK45I1LqKipcNVtv357lL1h3Y51UZ9LNTU1NVTWBucr713Qu5G9m2/SAZNc5Uve8G51sq07t/LZ6s8C5Z91/xnd84NDhB8+4eHA9raqbdz/afyuNCSbJXBjjAmzpXILj3zu7oz1z+P+SW5urquuOUtuppIzXnb31n79zPhPNd8+O2Q42SrvhpP94oVfuMpTz3IPdjq46GAGdBkQKP/ff//Ps1gSzRK4McaECR8ytnuH3bliRMOxxG+e+aarfNoLp3kaV7y88d0bgW1BGNZzWNxfY3Tf4Ay6VXVVngwnq66rZtaPswLlvTrvRd/OfRvs98C4YEe6DTs28OyiZ+MeSzJYAjfGmBBDHhjSYMjY6msjz+s9bA934nttyWuexRUvG3ZsoE7rAuUDeh7QyN4t9/CJD7vKf/m49UPUwp3xkvtKwqtnRF7D/Nh+x9KrIDiv2A0zboh7LMlgCdwYYxyvL36dxRsWu+oWX7o4yt4+ocPJQhNjqjruqeNc5ZnnzvTkdcKHkz0478G4tl9XV+e6krBH/h4M3T3i2jgA/P24YAe2VdtX8eaSN6Pumy4sgRtjjOPkF092lcf2G8vg3Qc3eswFwy5wlWf9MCvyjinii7VfBLYzJZNO7Tt59lp9CvsEtsOnOG2ti9+4mHoNjut+9pTGL4ufsc8Z9GjfI1C+anrrZ51LNkvgxhgDdLijg6ucLdlMO3dalL2DQscaA5w55cy4xhVP81bNc90e+MXgXzSyd+vdclRgVVkU5et1X8et7acWPhXY7prXlZF9RzZ5zG1H3xbYXrp5KbNXpNfY/XCWwI0xbd5Fr1/Ejlr3ilXbrm/ZKmOpPJzslBdPcZWf+8Vznr5e+NWJX731q7i0e+30a123KyafMLmRvYMuLbmUwtzgjHO/fuvXcYknWSyBG2PatDVb1vDEF0+46h4Y+0CDIWONCR9HXVVVFZfY4q1sW1lgOy8rr9Urj8WiQ3bwysanqz6NS5v3fRpcFa5jTkdOGXJKI3u73XBYsAPbonWLWLh2YVxiSgZL4MaYNm2Pf+7hLufvwa+HN+/M7O1z33aVz3w19S6jP7ngSVf5+hHXJ+R1j93r2MB2PIaT3Tn7TqrrgyuL3X3c3Y3s3dD1h17vGqPu5SQzXrMEboxpswbdN6jBkLFV16xqdjtDug9xlUN7R6eKK6a7x7H/cdQfE/K6j5zgnhDnjtmtm488dCKWvKw8Lj7w4mYdn5GRweUHXR4oz101lx82/9CqmJLFErgxpk2a8tUUvtv0navuhytb/oc8JzMnsJ2Kw8m2VQXv6XfO7Zyw1+2W340MCaaah+Y/1OK2Hv38UXbW7gyUbz7y5ha1c8cxd7j+f/1y6i9bHFMyWQI3xrRJp798uqs8ftB4iguLW9zeJQe4L8Wm0nCya6df6yqHnxV7rbhTcWB7XUXLO/ldM/2awHZORg43HtGyNb6zMrK4cNiFgfKs5bMSsmpavFkCN8a0OXl/ynOVczJyWj0f+H3j7nOVJ7w0oVXtxdP989wLeJy6T2JXTrv5qOCZsqIsXNP8jmOvLn6VbdXBqwiXD7+8kb2bdu+Ye8nKyArEdNmbl7WqvWSwBG6MaVMmvjKRyrpKV13VzfHvNb5+5/q4t9kSNTU1VNUF31/fwoZzhXutwXCyac0fTnbxG8F73ZmSyd0/b17ntXC5WbmcPiR4FeaN795gW2XLhg4miyVwY0ybsWbLGp5Z9IyrbvLxsY0hjkVxQbGrnArDycJnl/OvlZ1oocPJ5v80v1nHfrj8Qzbu3Bgon7vvuXGJ6cHjHwzcn6/Xen4z7TdxaTdRLIEbY9qM8CFjvQp6cXFJ83oxN+atc99ylc945YwoeybO9KXTA9uC8LPdfpaUOI7bKzgHe3VddbOGk539ytmBbUF4bPxjcYmpMLeQsf3HBsrPf/28a530VGcJ3BiDiLQXkZtF5BGnPEBETkh2XPHU/5/9XUPGBGHF71bE9TXCh5O99f1bUfZMjNVbV7t6xB+858FJiyV8trRb/3trTMctXLuQVduDQ/tOHHgimZmZcYvrkRMfQRAAautruebda5o4InVYAjfGADwBVAEjnHIZ8KfkhRNf/17wb5ZuWeqqW3blMk9eK5WGkx33nHvlsXfOfidJkTQcTvbo54/GdNwpL7hnWXvpjJfiGlfPjj05qs9RgfJjnz9GbX381y73giVwYwxAP1X9G1ADoKo7wTktaYKIjBGRJSJSKiK/j/D81SLyjYgsFJGZItLHqR8mInNE5GvnuQkhx/xbRH4QkS+cx7DwdpvjwqkXusqn7X1aq4aMNeZXJe4OWtO/nx5lT+99te6rwHZ2RranK4/FIrQD3fodTXfy+2HzDyzdHPzidVTvo1xfkOLl0fHBLxNVdVXcOiu2qwPJZgncGANQLSJ54LvGLCL98J2RN0pEMoEHgLHAEOAsERkSttsCoERVhwJTgL859TuA81R1H2AMcK+IFIYcd52qDnMeX9BCuX9yz2neLrNd3M/iQt075l5X+dxX49PhqrneLX3XVR4/cHxS4gh161HBxKgon//0eaP7n/T8Sa5ya4f6RdOvSz9KepYEyv+c+0/q6+sbOSI1WAI3xgDcCrwD9BKRZ4GZQCyTZQ8HSlV1mapWA88Drr+6qjpLVf1LfX0CFDn136nq9872T8A6oHs83ozfvxf82zWECqDypsR2Utqwc0NCX8/vxP+c6Co/ffLTSYkj1MT9JrrKl78dfSz3+vL1LFq3KFA+oOcBdMrz7grCIycGJ7epqKng7jmtG6aWCJbAjWnjRESAb4FTgAuA/+A7Y/4ghsP3BFaGlMucumgmAW+HV4rIcCAHCL1RfYdzaf0eEWkXJfZLRGS+iMxfv77hJdkL9r+AHu17BMpPjH+iwT5eCJ15DBI/nGzhmoWuBT/aZ7Unr11eI0ckTn52fmD7s9WfRd0v/Ox76gRvh78N6znM1QnxL7P/4unrxYMlcGPaOFVV4DVV3aiqb6nqm6oa62ljpPvkGqEOETkXKAHuCqvvCTwNXKiq/uuWNwKDgYOALsANRKCqk1W1RFVLunePfPK+9rq1/PXovzK853Au2P+Cpt9RHLx3znuu8qkvJ3bmsxGPjXCV50yak9DXb8zP+/08sB1tOFl5dTlzVgVjHtR1EHt2aux7YXw8NC44T/vmys0xd7RLFk8TeAydW9qJyAvO83NFpNip7yois0SkXETuDzvmA6dNf+eWHk79BSKyPqQ+PWenNyY5PhGRg1pwXBnQK6RcBPwUvpOIjAb+AIxX1aqQ+gLgLeAmVf3EX6+qq9WnCl8P+eEtiC3ghiNvYO4lc1vTRLP0697PVX6nNHG9v9eUr2FH7Y5AOSczh6G7D03Y6zfl4RMedpVv+eCWBvuc9uJprrJX977DHVl8JHsV7hUo3/T+TQl53ZbyLIHH2LllErBZVfsD9wB3OvWVwM3AtUR2TkjnltCZ8V8IqU/tr07GpJajgTkistS5bL1IRGKZsHoeMEBE+opIDnAm4LrWKSL7Aw/jS97rQupzgFeBp1T1pbBjejo/BTgZ+Io00y4zeNU/kcPJhjzg/jP79tkN7lgkVdcOXd3DyRa4/1TX1dXx7tJgB7zeBb0Z1G1QwuK7Z8w9ge21FWt5+ZuXE/bazdVkAheRTBG5q6n9Imiyc4tT9q8yPwU4RkREVStUdTa+RG6M8d5YoB8wCjgROMH52ShVrQUuB6YDi4EXVfVrEblNRPzdnu8C8oGXnKtj/gR/BnAkcEGE4WLPisgiYBHQjTQck35ZiXtxjLeWeD+pS3l1OZsrNwfKWRlZjNprlOev21yhZ7kbdrjv1pz9ytmuCXdeOt27EQORjB80nj3ygzP2pfLELk0mcFWtAw50vgk3RyydWwL7OH8ItgJdY2j7CefDfnNYXKc6Zw9TRKRXpAOb6vRiTFukqj8ChfiS9olAoVMXy7HTVHWgqvZT1TucultUdaqzPVpVdwu5OjbeqX9GVbND6gPDxVR1lKruq6o/U9VzVbXci/ftpfDhZOe9fp7nrznoPveZ6uMnPu75a7bEbSNvC2yHDierq6tjyuIpged6dOjB8KJW3T1pkb+MDnZg+3Hrj8xcNjPhMcQi1kvoC4DXRWSiiJzifzRxTCydW2LuABPiHFXdFzjCefjHJbwBFDtjTd8jeGbvbjyGTi/GtDUiciXwLNDDeTwjIr9NblS7lk07N3nafnV1NT+VB7sfZJDBxGETGzkiec4aepar7F9E5Lfv/JZ6DY6/fuKkxIwaCHfefufRNS94Lnn5tNYtXeqVWBN4F2Ajwctr/ktsjYmlc0tgHxHJAjoBjf4rV9VVzs/twHM4nVucHrT+zjGPAAc2EZ8xJmgScLBz5nwLcAgQv1U+2qi+ndxLd3o5nGzfh/d1le889s4oe6aG/JzgcLLP1/jOwB/5PDgWuzC3kHEDxiU8Lr+bjwyuYf7txm+Zt2pe0mKJJqYErqoXRnhc1MRhTXZuccrnO9unAe87Q1oiEpEsEenmbGfj+xLxlVPuGbLreHz344wxsREgtKdVHTFOpWqim3HODFd5/IvezYb23abvXOVrD43WBzg1jO0XXAWsuq6am96/yTUH+QPjHkhGWAG/Hf5bOuZ0DJQvffPSJEYTWUwJXESKRORVEVknImtF5GURKWrsmBg7tzwGdBWRUuBqIDDUTESWA//A18GlzOnB3g6Y7vSO/QJYhe9sG+AKZ07lL4Er8E1IYYyJzRPAXBH5o4j8Ed+MafFZs7ENCx9ONvMHb+6lHvyIe5Wxqw6+ypPXiafJ492rk/35oz8Htjtkd+Dsfc8OPyShMjIyuHrE1YHygjUL+HbDt0mMqCFp5IQ3uJPIDHyXq/1z8Z2L7170sR7G5rmSkhKdP795C8sbkw5E5DNVLWl6T9cxBwCH4zvz/lBVF3gSnEdS9fOc+6dc13SuemvTf3ObS/7PfbHEi9fwQtZtWRGH2N3z83u46pDkfwmpr6+nw186BNYIP7zX4Xx00UcJjyPa5znWe+DdVfUJVa11Hv8mznMWG2OSR0QOAb5X1X+p6j+BUhFJ3uLRu5Arh1/pKr/6zatxbf/4Z453lScMmRBlz9QTOpzMr11mu5RI3uA7C7/swOBwwNkrZ1O2rSyJEbnFmsA3iMi5zpjwTGdKxI1eBmaMSaiHgNChWhVOnWmlO49zdyab9MakuLY/bek0V/n505+Pa/teuv3o2xvUXXfodUmIJLo7R99JdkZ2oHzx1NTp2xlrAr8I36QLa4DV+DqcNdWJzRiTPiS0A6kzJ3lWEuPZZYVOtNJak15zfxkYVZx6k7Y0ZsK+7qsFmZLJ7aMaJvVkysnK4Zyh5wTK7y57l4rqiiRGFBTTTGzAqao6XlW7q2oPVT051kkejDFpYZmIXCEi2c7jSmBZsoPaVYRfKo7XcLLHv3RP1DLz/NSccKQxoavFha4GlkruG3tfYPrXeq3nyS8jTjOScLHOxBY+BaoxZtdyGXAovpEdZcDBwCVJjWgX8u7Z77rKJ77Q5Cy1TbpppnuhjaE9UmfBkuZ47czXGAuhLHcAABZbSURBVNR1EBP3ncgnv/yk6QOSID8nn+F7BmeEW1+RGrN4xnqJ7GNnVbAX8N0bA0BVP/ckKmNMQjmLjJyZ7Dh2VeHDyd5f/n6r2/zz7D+7yvMmpd5EI7EY0WsE316eWsOzIrny4Cv5pMz3BePt0re5deStSY4o9gR+qPPztpA6xTczmzEmzYnI3/AtGLITeAfYD7hKVZ9JamC7kNzMXCrrfMORWrs62UPzHnIt+NGnUx9ycnJa1aZp3HH9jiNDMqjXej5d9SkbdmygW/tuSY0plnvgGcBDqnp02MOStzG7juNUdRu+2Q3LgIFAanUHTnNXDL/CVW7NcLLwubm/+/V3UfY08dIlrwuHFB0C+BZgmV46PckRxXYPvB7fjGrGmF2Xf5zMOOA/qurtyhttULyGk722+DXqCS740aN9Dzv7TpCx/YPTv75dmvx11mMdRjZDRK4VkV4i0sX/8DQyY0wivSEi3wIlwEwR6Q5UJjmmXVpLh5OdMeUMV3nxr2zZh0QJTeDTl06nrr51t0JaqznjwH8DfAh85jxSb85CY0yLqOrvgRFAiarWADuw0SdxN6DLAFe5ucPJ5qycQ019TaDcMacjXfLtXCpR9u+5P7t12A2ADTs2MP+n5KbBWFcj6xvh0XAOPGNM2lLVzc6wUVS1QlXXJDumXc3757t7n4/7T/OWyxz1lLvr0YJL02q6+rSXIRmM6T8mUE72ZfRGE7iIXB+yfXrYc39ueIQxxphoigrcizh+sOKDmI8t3VQaWFQDIDcrl35d+jVyhPFCKt0Hb+oMPHRc6I1hz43BGGNMs+Rm5ga267W+kT3dDnj4AFf5owsSvyqWCQ4nA5i3al5SJ3VpKoFLlO1IZWPMLkREBic7hl3RdYe5R+e9+NWLTR6zqXwT26u3B8rZGdmU7Nms1WJNnHTO68yIohGAM5xsafKGkzWVwDXKdqSyMWbX8m7Tu5jmuu3o21zlS9+8tMljBj/o/i714mlNJ33jnVS5jN7UTGz7icg2fGfbec42Tjk3+mHGmHQgIv+K9hRQmMhY2qotVVsafb66upr1O4OXaTPI4OS9T/Y6LNOIcQPGcdMs31z000t9w8kyMzITHkejZ+CqmqmqBaraUVWznG1/ObuxY40xaeFC4CuCw0NDh4lWJzGuXdqgroNc5caGkw18cKCr/P+O/3+exGRiN2z3YeyevzsAG3duZN5PyZmHPtZx4MaYXdM84CtVfTL8AWxv6mDTMu+d956rPOa5yH2Cq6ur+XFrcOVmQbi45GJPYzNNExH3cLLvk3MZ3RK4MW3bacAXkZ5Q1b4JjqXNCB9O9uHKDyPud9BjB7nKNx15U8T9TOKN6x8cw5+s++CWwI1p2/JVdUeyg2iLYhlOtnDdQlc5vAOcSZ5j+x1Lpvjue8/7aR7rKtYlPAZL4Ma0ba/5N0Tk5WQG0tbceLh7ao0XFr3gKo/890hX+eJhduk8lRTmFjKi14hAORmrk1kCN6ZtC53PoUXTI4vIGBFZIiKlIvL7CM9fLSLfiMhCEZkpIn2c+mEiMkdEvnaemxByTF8RmSsi34vICyKyyy23dcvIW1zl8OFk//3xv67y5JMmex6TaZ5kX0a3BG5M29bYXA9NEpFM4AFgLDAEOEtEhoTttgDfIilDgSnA35z6HcB5qroPvpkd7xUR/9C1O4F7VHUAsBlo2dqbaWRr9dbA9ukvumau5oT+JyQ6HBODsQOSuzqZJXBj2rb9RGSbiGwHhjrb20Rke8i8D40ZDpSq6jJVrQaeJ2wVM1WdFXKf/ROgyKn/TlW/d7Z/AtYB3UVEgFH4kj3Ak8AuOfB5cDf3BC3+4WRTFk9x1b9xzhsJi8nEbr/d9qNnfk8ANu3cxKerPk3o61sCN6YNa2Kuh4IYmtgTWBlSLnPqopkENLjWKCLDgRxgKdAV2KKqtU21KSKXiMh8EZm/fn3y5qRuqQ8nunufH/vssVw57UpX3SF7HpLIkEwziEhSZ2WzBG6MaY1IayJEvBQvIucCJcBdYfU9gaeBC1W1vjltqupkVS1R1ZLu3bs3K/BU0L3AHfPHZR/zr3nuyfHm/HJOIkMyzRR6GX3a99MS+tqeJvAYOre0czqolDodVoqd+q4iMktEykXk/rBjPnDa/MJ59GisLWOMp8qAXiHlIuCn8J1EZDTwB2C8qlaF1BcAbwE3qeonTvUGoFBE/FM9R2xzV5GXlRfYDh9OFj5jm0k9o/caHRhO9tnqz1hbvjZhr+1ZAo+xc8skYLOq9gfuwddxBaASuBm4Nkrz56jqMOfhH3wXrS1jjHfmAQOcXuM5+JYgnhq6g4jsDzyML3mvC6nPAV4FnlLVl/z1qqrALHyTzACcD7zu6btIot8f1uDcJmDhJQujPmdSQ2FuIYf2OjRQTuTqZF6egTfZucUpP+lsTwGOERFR1QpVnY0vkccqYlstD98Y0xTnPvXlwHRgMfCiqn4tIreJyHhnt7uAfOAl56qZP8GfARwJXBByRW2Y89wNwNUiUorvnvhjiXpPiRY+nMxvj457kJOzy42e2yWNG5Cc4WRNrUbWGpE6txwcbR9VrRWRrfg+rBuaaPsJEakDXgb+5Hxjj6ktEbkEuASgd+/eLXhbxphQqjoNmBZWd0vI9ugoxz0DPBPluWX4TgLarCWXL0l2CCZGY/uP5caZvol5ppdOp7a+lqwML9Orj5dn4LF0RIm5s0qIc1R1X+AI5zGxOW2le6cXY8yuZ+9ue7vKnXM7k5+Tn6RoTHMN3W0oe3TcA4DNlZsTNpzMywQeS+eWwD5Oh5VOwKbGGlXVVc7P7cBzBL+lN7stY4xJBf+d6J517flTn09SJKYlGgwnS9DqZF4m8CY7tzjl853t04D3ncvhEYlIloh0c7azgRPwrWXc7LaMMSZVdC/ozuFFh5OTkcNlB17GMXsdk+yQTDOFJvBppYkZTubZRXrnPrS/c0sm8Li/cwswX1Wn4uuY8rTTUWUTviQPgIgsBwqAHBE5GTgO+BGY7iTvTOA94BHnkKhtGWNMqvto0kfJDsG0wui9RpOVkUVtfS2fr/6cNeVr2D1/d09f09O77DF0bqkETg8/znmuOEqzB0bZP2pbxhhjjJc65XbisF6HBRahmV46nfOHnd/EUa1jM7EZY4wxcZDoy+iWwI0xxpg4CJ1W9d2l71JbX9vI3q1nCdwYY4yJg3177MueHX3r7myp3MLcsrmevp4lcGOMMSYOwoeTeb24iSVwY4wxJk5CL6N7Pa2qJXBjjDEmTvzDyQAWrFnAmvI1nr2WJXBjjDEmTgraFXB478MD5XdK3/HstSyBG2OMMXGUqPvglsCNMcaYOApdXnTGshmeDSezBG6MMcbE0T7d96GooAjwDSf7pOwTT17HErgxxhgTR4kaTmYJ3BhjjImz0MvoXg0nswRujDHGxNkxfY8hOyMbgC/WfMFP23+K+2tYAjfGGGPirGO7jp4PJ7MEbowxxnjA68volsCNMcYYD4R2ZJuxdAY1dTVxbd8SuDHGGOOBId2H0KugFwBbq7Yyp2xOXNu3BG6MMcZ4IHw42dvfx/cyuiVwY4wxxiNe3ge3BG6MMcZ4ZFTfUYHhZF+u/ZJV21bFrW1L4MYYY4xHOrbryBF9jgiU4zmczBK4McYY46Fx/b25jG4J3BjTKiIyRkSWiEipiPw+wvNXi8g3IrJQRGaKSJ+Q594RkS0i8mbYMf8WkR9E5AvnMSwR78UYL4wdEDKcbFn8hpNZAjfGtJiIZAIPAGOBIcBZIjIkbLcFQImqDgWmAH8Lee4uYGKU5q9T1WHO44s4h25MwuzdbW96d+oNwLaqbfxv5f/i0q4lcGNMawwHSlV1mapWA88DJ4XuoKqzVHWHU/wEKAp5biawPVHBGpMMIuLJZXRL4MaY1tgTWBlSLnPqopkExPrX6w7nsvs9ItIu0g4icomIzBeR+evXr4+xWWMSL/Qyelok8BjujbUTkRec5+eKSLFT31VEZolIuYjcH6XtqSLyVUj5jyKyKuSe2bhIxxlj4koi1GnEHUXOBUrwXTZvyo3AYOAgoAtwQ6SdVHWyqpaoakn37t1ji9iYJBjVdxQ5mTkALFy7kLJtZa1u07MEHuO9sUnAZlXtD9wD3OnUVwI3A9dGafsUoDzCU/eE3DPzZgV1Y0yoMqBXSLkIaLBuooiMBv4AjFfVqqYaVdXV6lMFPIHvUr0xaSs/J58j+xwZKMdjOJmXZ+BN3htzyk8621OAY0REVLVCVWfjS+QuIpIPXA38ybvQjTExmgcMEJG+IpIDnAlMDd1BRPYHHsaXvNfF0qiI9HR+CnAy8FXjRxiT+lzTqsbhMrqXCTyWe2OBfVS1FtgKdG2i3duBu4EdEZ673Lln9riIdI50sN0zMyZ+nM/t5cB0YDHwoqp+LSK3ich4Z7e7gHzgJef2ViDBi8hHwEv4vryXicjPnaeeFZFFwCKgG/aF3ewCwlcnq66rblV7Wa0NqBGx3BuL+f4ZgDMWtL+q/s5/vzzEQ/iSuxJM8hc1aFx1MjAZoKSkJOprGWNi49yumhZWd0vI9uhGjj0iSv2ouAVoTIoY3G0wxYXFLN+ynO3V2/nfyv8xsnhki9vz8gw8lntjgX1EJAvoBGxqpM0RwIEishyYDQwUkQ8AVHWtqtapaj3wCHbPzBhjTAqJ9+pkXibwJu+NOeXzne3TgPdVNepZsao+pKp7qGoxcDjwnaqOhOA9M8cvsHtmxhhjUkxoAp9W2rq+1p5dQlfVWhHx3xvLBB733xsD5qvqVOAx4GkRKcV35n2m/3jnLLsAyBGRk4HjVPWbRl7yb84ldgWWA5d68LaMMcaYFvMPJ6uuq+ardV+xcutKenXq1fSBEXh5DzyWe2OVwOlRji1uou3lwM9CytGmYzTGGGNSQoecDhzV5yhmLJsB+IaTXXzgxS1qy2ZiM8YYYxIoXsPJPD0DT1tr1sDvfgc9e0JxMfTvD0OG+LZN21BfD+Xlvsf27VBR4XuUl8OOHQ0flZWwc6fvUVkJVVXBn6qw//4wYgR07Qpduvh+duoEmZnJfqfGmAQbN2AcV797NeBbnay6rjowS1tzWAKP5MEH4fnnkx1F8ogzui8jI7gtkUb8Ef25aMe1a+eu8/dZjNZ3MbQ+0j6qkJvrS7h1db6f/oeq7xG6HctreuGttxrWiUDnzr6E7k/qkX6G1xUU+P7fGGPS0sCuA+lb2JcftvxAeXU5H6/4mKP7Ht3sdiyBR7JqVbIjSC5/Yquri3/blQ0m12u9ior4t5kIqrBpk+/RHBkZvmT+4INwesQuJMaYFOYfTvbg/AcB32V0S+DxUt262XHMLkbE9/BfkcjI8F369v/MyvL9zM72bWdl+bazsyEnx5eoO3XybW/c6EvYGzfC1q0ti6e+HjZs8LVvjElL4waMCyTwad9P42/H/q3ZbVgCj+Tpp32PUJWVsHw5LFkC338PK1bA6tW+P8Zbtvjuje7c6bvnWVUFtbW+h//yrf8nuJOBPxH4k4E/IfgTQLt2vkvEeXnQvj3k50PHjr5Lr507Q48evmO3bg3es/VvV1S478vW1Pi+nFRX+7br691xhj7AF4dIw0vNsVzWjnZ5OvwSuv/3Efozkmj7ZGf7fgf+ZOn/nYU+/L+/3Fzf77B9e185P9/36NDB9zv1P7p29f1uvb5MXVsLmzcHE3roz0h1/p/bneWzuzY167AxJlUd3fdo2mW2o07r6N6hOztrdpKXndesNiyBxyo3FwYP9j2MiYesLOje3fdojupqX+IvLPQmLmOM59pnt+e9895j6G5DKWhX0KI2LIEbk25ycmC33ZIdhTGmlQ7vfXirjreurMYYY0wasgRujDHGpCFL4MYYY0wasgRujDHGpCFpZPXOXZ6IrAd+bGSXbsCGBIXTGhZn/KRDjNB0nH1UtZnd29PbLvJ5TocYweKMp1hijPh5btMJvCkiMl9VS5IdR1MszvhJhxghfeJMJenwO0uHGMHijKfWxGiX0I0xxpg0ZAncGGOMSUOWwBs3OdkBxMjijJ90iBHSJ85Ukg6/s3SIESzOeGpxjHYP3BhjjElDdgZujDHGpCFL4MYYY0wasgQehYiMEZElIlIqIr9PdjyRiEgvEZklIotF5GsRuTLZMUUjIpkiskBE3kx2LNGISKGITBGRb53f6YhkxxRORH7n/L/+SkT+IyK5yY4p1dlnOb7ssxw/rf08WwKPQEQygQeAscAQ4CwRGZLcqCKqBa5R1b2BQ4DfpGicAFcCi5MdRBP+CbyjqoOB/UixeEVkT+AKoERVfwZkAmcmN6rUZp9lT9hnOQ7i8Xm2BB7ZcKBUVZepajXwPHBSkmNqQFVXq+rnzvZ2fP9I90xuVA2JSBFwPPBosmOJRkQKgCOBxwBUtVpVtyQ3qoiygDwRyQLaAz8lOZ5UZ5/lOLLPcty16vNsCTyyPYGVIeUyUvDDFEpEioH9gbnJjSSie4HrgfpkB9KIvYD1wBPO5cFHRaRDsoMKpaqrgL8DK4DVwFZVfTe5UaU8+yzHl32W4yQen2dL4JFJhLqUHW8nIvnAy8BVqrot2fGEEpETgHWq+lmyY2lCFnAA8JCq7g9UACl1v1REOuM7e+wL7AF0EJFzkxtVyrPPcpzYZzm+4vF5tgQeWRnQK6RcRIpeqhSRbHwf+GdV9ZVkxxPBYcB4EVmO7/LlKBF5JrkhRVQGlKmq/6xnCr4/AqlkNPCDqq5X1RrgFeDQJMeU6uyzHD/2WY6vVn+eLYFHNg8YICJ9RSQHX8eCqUmOqQEREXz3eRar6j+SHU8kqnqjqhapajG+3+P7qppyZ42qugZYKSKDnKpjgG+SGFIkK4BDRKS98//+GFKwc06Ksc9ynNhnOe5a/XnO8iSsNKeqtSJyOTAdX8/Ax1X16ySHFclhwERgkYh84dT9f6o6LYkxpbPfAs86f+iXARcmOR4XVZ0rIlOAz/H1Wl5AekwVmTT2WW6zUvqzDPH5PNtUqsYYY0waskvoxhhjTBqyBG6MMcakIUvgxhhjTBqyBG6MMcakIUvgxhhjTBqyBG6aRUTqROSLkEfcZjgSkWIR+Spe7RljGmef5/Rm48BNc+1U1WHJDsIYExf2eU5jdgZu4kJElovInSLyqfPo79T3EZGZIrLQ+dnbqd9NRF4VkS+dh38KwUwRecRZI/ddEclL2psypo2yz3N6sARumisv7JLbhJDntqnqcOB+fKsW4Ww/papDgWeBfzn1/wL+q6r74Zun2D871gDgAVXdB9gCnOrx+zGmLbPPcxqzmdhMs4hIuarmR6hfDoxS1WXOogxrVLWriGwAeqpqjVO/WlW7ich6oEhVq0LaKAZmqOoAp3wDkK2qf/L+nRnT9tjnOb3ZGbiJJ42yHW2fSKpCtuuwfhrGJIt9nlOcJXATTxNCfs5xtv+Hb+UigHOA2c72TOBXACKSKSIFiQrSGBMT+zynOPs2ZJorL2S1JIB3VNU/9KSdiMzF98XwLKfuCuBxEbkOWE9wVaArgckiMgnfN/NfAas9j94YE8o+z2nM7oGbuHDumZWo6oZkx2KMaR37PKcHu4RujDHGpCE7AzfGGGPSkJ2BG2OMMWnIErgxxhiThiyBG2OMMWnIErgxxhiThiyBG2OMMWno/wcNSyL9nqRtiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizera\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "\n",
    "#         # testing tensor size \n",
    "#         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "#         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        \n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "    \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "        \n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # save f1 scores\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(trainLoader, nameLabel = \"Train\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, nameLabel = \"Validation\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/f1Scores.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"NÂ° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"NÂ° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores)\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {âtrueâ, âpredâ, âallâ}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
