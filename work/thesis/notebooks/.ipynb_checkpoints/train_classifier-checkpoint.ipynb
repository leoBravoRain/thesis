{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = True\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = False\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 9\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# training\n",
    "epochs = 15000\n",
    "\n",
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 15000\n",
    "\n",
    "# train with previous model\n",
    "trainWithPreviousModel = False\n",
    "\n",
    "# include delta errors\n",
    "includeDeltaErrors = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp 10 + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0 + include delta errors + max by class 15000\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"exp \" + number_experiment + \" + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed) + \" + \" + (\"include delta errors\" if includeDeltaErrors else \"without delta errors\") + \" + max by class \" + str(max_elements_per_class)\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass\" + str(int(max_elements_per_class/1000)) + \"k\"\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets, lightCurvesIds = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# saving ids\n",
    "saveLightCurvesIdsBeforeBalancing(trainIdx, valIdx, testIdx, folder_path, lightCurvesIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_before_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[417. 450. 434. 432. 452. 435.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.ar# return 0# return 0ange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# save ids of dataset to use (train, test and validation)\n",
    "saveLightCurvesIdsAfterBalancing(trainLoader, train_size, testLoader, test_size, validationLoader, validation_size, path = folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_after_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment parameters file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "if trainingOnGuanaco or trainWithJustPython:\n",
    "    text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "    text = \"N° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "    text_file.write(text)\n",
    "    text_file.close()\n",
    "    print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model with default parameters\n"
     ]
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "if trainWithPreviousModel:\n",
    "    \n",
    "    # loadgin model\n",
    "    model = torch.load(pathToSaveModel + \".txt\").to(device = cuda_device)\n",
    "    \n",
    "    print(\"loading saved model\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # defining model\n",
    "    model = EncoderClassifier(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes, passband = passband, includeDeltaErrors = includeDeltaErrors)\n",
    "\n",
    "    # mdel to GPU\n",
    "    model = model.to(device = cuda_device)\n",
    "    \n",
    "    print(\"creating model with default parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 10\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 10\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 10\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    3 / 10\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    4 / 10\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    5 / 10\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    6 / 10\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    7 / 10\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    8 / 10\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    9 / 10\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizera\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "\n",
    "#         # testing tensor size \n",
    "#         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "#         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data, includeDeltaErrors)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "    \n",
    "#         print(np.any(torch.isnan(outputs).numpy()))\n",
    "        \n",
    "#         # data validation\n",
    "#         if np.any(torch.isnan(outputs).cpu().numpy()) or np.any(torch.isinf(outputs).cpu().numpy()):\n",
    "            \n",
    "#             print(\"invalid input detected at iteration \", nepoch)\n",
    "            \n",
    "#             print(\"data: \", data)\n",
    "            \n",
    "#             print(\"outputs \", outputs)\n",
    "            \n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "    \n",
    "        outputs = model.forward(data, includeDeltaErrors)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "\n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # save f1 scores\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(torch.isnan(outputs).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(trainLoader, nameLabel = \"Train\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath, includeDeltaErrors = includeDeltaErrors)\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, nameLabel = \"Validation\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath, includeDeltaErrors = includeDeltaErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/10/seed0/maxClass15k/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "# losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "losses = pd.read_csv(folder_path + \"/training_losses.csv\")\n",
    "# f1 scores\n",
    "# f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass15k\" + \"/f1Scores.csv\")\n",
    "f1Scores = pd.read_csv(folder_path + \"/f1Scores.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"N° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"N° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores)\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed0/maxClass15k/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {‘true’, ‘pred’, ‘all’}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv(tmpLocal + expPath  + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv(tmpLocal + expPath + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed0/maxClass15k/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed0/maxClass15k/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
