{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = False\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = True\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 99\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# training\n",
    "epochs = 3\n",
    "\n",
    "# cuda device\n",
    "cuda_device = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed)\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticc_torch-master/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticc_torch-master/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticc_torch-master/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[428. 436. 450. 441. 427. 438.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed)\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "text = \"N° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "text_file.write(text)\n",
    "text_file.close()\n",
    "print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "\n",
    "# defining model\n",
    "model = EncoderClassifier(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes, passband = passband)\n",
    "\n",
    "# mdel to GPU\n",
    "model = model.cuda(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 3\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 3\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 3\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizera\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].cuda(cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).cuda(cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "\n",
    "#         # testing tensor size \n",
    "#         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "#         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).cuda(cuda_device))\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].cuda(cuda_device)\n",
    "        \n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).cuda(cuda_device)\n",
    "        \n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).cuda(cuda_device))\n",
    "    \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "        \n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # save f1 scores\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores\n",
      "saving clasification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(trainLoader, nameLabel = \"Train\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, nameLabel = \"Validation\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/99/seed0/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/f1Scores.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"N° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"N° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores)\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/99/seed0/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixTrain.csv', header = None) \n",
    "cmValidation = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixValidation.csv', header = None) \n",
    "\n",
    "print(\"Training\")\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/99/seed0/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/99/seed0/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
