{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = False\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = True\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 99\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# training\n",
    "epochs = 10\n",
    "\n",
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed)\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[414. 419. 436. 445. 432. 474.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed)\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "text = \"NÂ° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "text_file.write(text)\n",
    "text_file.close()\n",
    "print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "\n",
    "# defining model\n",
    "model = EncoderClassifier(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes, passband = passband)\n",
    "\n",
    "# mdel to GPU\n",
    "model = model.to(device = cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(pathToSaveModel))\n",
    "# model = torch.load(pathToSaveModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 10\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 10\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 10\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    3 / 10\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    4 / 10\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    5 / 10\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    6 / 10\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    7 / 10\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    8 / 10\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    9 / 10\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizera\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "\n",
    "#         # testing tensor size \n",
    "#         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "#         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        \n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "    \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "        \n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # save f1 scores\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(trainLoader, nameLabel = \"Train\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, nameLabel = \"Validation\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/f1Scores.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"NÂ° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"NÂ° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores)\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {âtrueâ, âpredâ, âallâ}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
