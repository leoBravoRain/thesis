{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = True\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = False\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 14\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# training\n",
    "epochs = 100000\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 15000\n",
    "\n",
    "# train with previous model\n",
    "trainWithPreviousModel = False\n",
    "\n",
    "# include delta errors\n",
    "includeDeltaErrors = True\n",
    "\n",
    "# band\n",
    "# passband = [5]\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "# include ohter feautures\n",
    "includeOtherFeatures = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "batch_training_size = 128\n",
    "\n",
    "# early stopping \n",
    "threshold_early_stop = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp 99 + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0 + include delta errors + max by class 15000 +  other features\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"exp \" + number_experiment + \" + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed) + \" + \" + (\"include delta errors\" if includeDeltaErrors else \"without delta errors\") + \" + max by class \" + str(max_elements_per_class) + \" + \" + (\"\" if includeOtherFeatures else \"not\") + \" other features\"\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass\" + str(int(max_elements_per_class/1000)) + \"k\"\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets, lightCurvesIds = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# saving ids\n",
    "saveLightCurvesIdsBeforeBalancing(trainIdx, valIdx, testIdx, folder_path, lightCurvesIds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_before_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "        seed = seed\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx,\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx,\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[444. 420. 439. 474. 400. 443.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.ar# return 0# return 0ange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# save ids of dataset to use (train, test and validation)\n",
    "saveLightCurvesIdsAfterBalancing(trainLoader, train_size, testLoader, test_size, validationLoader, validation_size, path = folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_after_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment parameters file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "if trainingOnGuanaco or trainWithJustPython:\n",
    "    text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "    text = \"N° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "    text_file.write(text)\n",
    "    text_file.close()\n",
    "    print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model with default parameters\n"
     ]
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "if trainWithPreviousModel:\n",
    "    \n",
    "    # loadgin model\n",
    "    model = torch.load(pathToSaveModel + \".txt\").to(device = cuda_device)\n",
    "    \n",
    "    print(\"loading saved model\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # defining model\n",
    "    model = EncoderClassifier(\n",
    "        latent_dim = latentDim, \n",
    "        hidden_dim = hiddenDim, \n",
    "        input_dim = inputDim, \n",
    "        num_classes = num_classes, \n",
    "        passband = passband, \n",
    "        includeDeltaErrors = includeDeltaErrors,\n",
    "        includeOtherFeatures = includeOtherFeatures,\n",
    "    )\n",
    "\n",
    "    # mdel to GPU\n",
    "    model = model.to(device = cuda_device)\n",
    "    \n",
    "    print(\"creating model with default parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=780, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 3\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 3\n",
      "saving losses\n",
      "saving f1 scores\n",
      "early stopping counter:  1\n",
      "epoch:    2 / 3\n",
      "saving losses\n",
      "saving f1 scores\n",
      "early stopping counter:  2\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizeraa\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "# prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = threshold_early_stop\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "            \n",
    "        # add other features\n",
    "        # [batch size, features]\n",
    "#         if includeOtherFeatures:\n",
    "        if includeOtherFeatures:\n",
    "            \n",
    "            otherFeatures = getOtherFeatures(data_[0]).to(device = cuda_device)\n",
    "                \n",
    "#             print(np.any(torch.isnan(otherFeatures).cpu().numpy()))\n",
    "            \n",
    "            if np.any(torch.isnan(otherFeatures).cpu().numpy()):\n",
    "                \n",
    "                print(f\"other features with nan values in epoch {nepoch}\")\n",
    "            \n",
    "            \n",
    "            # get model output\n",
    "            outputs = model.forward(data, includeDeltaErrors, otherFeatures)\n",
    "            \n",
    "            \n",
    "            # #         # testing tensor size \n",
    "# #         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "# #         print(\"test ok\")\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # get model output\n",
    "            outputs = model.forward(data, includeDeltaErrors)\n",
    "\n",
    "        if np.any(torch.isnan(outputs).cpu().numpy()):\n",
    "                \n",
    "                print(f\"outpues with nan values in epoch {nepoch}\")\n",
    "                \n",
    "#         print(ouput)\n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "    \n",
    "#         print(np.any(torch.isnan(outputs).numpy()))\n",
    "        \n",
    "#         # data validation\n",
    "#         if np.any(torch.isnan(outputs).cpu().numpy()) or np.any(torch.isinf(outputs).cpu().numpy()):\n",
    "            \n",
    "#             print(\"invalid input detected at iteration \", nepoch)\n",
    "            \n",
    "#             print(\"data: \", data)\n",
    "            \n",
    "#             print(\"outputs \", outputs)\n",
    "            \n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "            \n",
    "        if np.any(torch.isnan(loss).cpu().numpy()):\n",
    "                \n",
    "                print(f\"loss with nan values in epoch {nepoch}\")\n",
    "                \n",
    "#         print(loss)\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "    \n",
    "        if includeOtherFeatures:\n",
    "            \n",
    "            otherFeatures = getOtherFeatures(data_[0]).to(device = cuda_device)\n",
    "        \n",
    "# #         # testing tensor size \n",
    "# #         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "# #         print(\"test ok\")\n",
    "        \n",
    "            # get model output\n",
    "            outputs = model.forward(data, includeDeltaErrors, otherFeatures)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        else:\n",
    "        \n",
    "            # get model output\n",
    "            outputs = model.forward(data, includeDeltaErrors)\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "\n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    #### save losses ####\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ### save f1 scores ####\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    # If minimum global validation error does not decrease in X epochs, so stop training\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the min valid error\n",
    "    if test_loss[nepoch] > minTestLossGlobalSoFar:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "        \n",
    "    # if it is smaller\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop >= threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n\".format(nepoch, count_early_stop)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n",
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(\n",
    "    trainLoader, \n",
    "    nameLabel = \"Train\", \n",
    "    passband = passband, \n",
    "    model = model, \n",
    "    staticLabels = only_these_labels, \n",
    "    number_experiment = number_experiment, \n",
    "    expPath = expPath, \n",
    "    includeDeltaErrors = includeDeltaErrors, \n",
    "    includeOtherFeatures = includeOtherFeatures\n",
    ")\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, \n",
    "                                    nameLabel = \"Validation\", \n",
    "                                    passband = passband, \n",
    "                                    model = model, \n",
    "                                    staticLabels = only_these_labels, \n",
    "                                    number_experiment = number_experiment, \n",
    "                                    expPath = expPath, \n",
    "                                    includeDeltaErrors = includeDeltaErrors, \n",
    "                                    includeOtherFeatures = includeOtherFeatures\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/99/seed0/maxClass15k/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "# losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "losses = pd.read_csv(folder_path + \"/training_losses.csv\")\n",
    "# f1 scores\n",
    "# f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass15k\" + \"/f1Scores.csv\")\n",
    "f1Scores = pd.read_csv(folder_path + \"/f1Scores.csv\")\n",
    "\n",
    "print(folder_path)\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "maxPlot = 100\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"N° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:maxPlot, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:maxPlot, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"N° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores.iloc[:maxPlot])\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/14/seed0/maxClass15k/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {‘true’, ‘pred’, ‘all’}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv(folder_path  + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv(folder_path + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(folder_path)\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/99/seed0/maxClass15k/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/99/seed0/maxClass15k/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
