{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import imblearn\n",
    "import pickle\n",
    "from joblib import load, dump\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download features\n",
    "# !scp -r -P 22334 -i ~/.ssh/id_rsa guanaco.inf.uach.cl:/home/shared/astro/PLAsTiCC/fats_featurs.tar.gz .\n",
    "# !tar xzvf fats_features.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ids/seed4/maxClass15k/dataset_ids_before_balancing.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5984fc0c9b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ids/seed{seed}/maxClass15k/dataset_ids_before_balancing.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlc_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ids/seed4/maxClass15k/dataset_ids_before_balancing.pkl'"
     ]
    }
   ],
   "source": [
    "# Select seed, load ids and features\n",
    "\n",
    "seed = 4\n",
    "with open(f\"ids/seed{seed}/maxClass15k/dataset_ids_before_balancing.pkl\", \"rb\") as f:\n",
    "    lc_ids = pickle.load(f)\n",
    "\n",
    "features = {}\n",
    "for subset in ['train', 'validation', 'test']:\n",
    "    print(subset)\n",
    "    tmp = []\n",
    "    \n",
    "#     tmp2 = lc_ids[subset][:10]\n",
    "    \n",
    "#     for lc_id in tmp2:\n",
    "    for lc_id in lc_ids[subset]:\n",
    "#         print(lc_id)\n",
    "#         print(\"aoisdj\")\n",
    "#         lc_id = lc_id[:2]\n",
    "        with open(\"features/fats\"+str(int(lc_id))+\".pkl\", \"rb\") as f:\n",
    "            tmp.append(load(f))\n",
    "    features[subset] = pd.concat(tmp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[\"test\"].fillna(-1000).values.shape)\n",
    "\n",
    "print(lc_ids['labels_test'].astype('int').shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train balanced RF\n",
    "# from sklearn.metrics import f1_score, classification_report\n",
    "# from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "rf = BalancedRandomForestClassifier(n_estimators=500, criterion='entropy', replacement=True,\n",
    "                                    max_depth=10, class_weight='balanced', n_jobs=8) \n",
    "                \n",
    "\n",
    "rf.fit(\n",
    "    features['train'].fillna(-1000).values, \n",
    "    lc_ids['labels_train'].astype('int'),\n",
    ") \n",
    "\n",
    "# save RF trained model\n",
    "dump(rf, '../../experiments/comparingModels/seed' + str(seed) + '/RF/trainedRF.joblib') \n",
    "print(\"RF model saved\")\n",
    "\n",
    "# preds = rf.predict(features['validation'].fillna(-1000).values)\n",
    "# print(classification_report(preds, lc_ids['labels_validation'].astype('int')))\n",
    "# # print(rf.features)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load file\n",
    "rf = load('../../experiments/comparingModels/seed' + str(seed) + '/RF/trainedRF.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get test model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert lc_ids[\"test\"].shape == lc_ids[\"labels_test\"].shape == preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result on data set\n",
    "trainPreds = rf.predict(features['train'].fillna(-1000).values)\n",
    "validPreds = rf.predict(features['validation'].fillna(-1000).values)\n",
    "testPreds = rf.predict(features['test'].fillna(-1000).values)\n",
    "\n",
    "# print(trainPreds)\n",
    "# print(validPreds)\n",
    "# print(testPreds)\n",
    "\n",
    "# save results\n",
    "results = {\n",
    "    \n",
    "    # train\n",
    "    \"trainIds\": lc_ids[\"train\"],\n",
    "    \"trainLabels\": lc_ids[\"labels_train\"],\n",
    "    \"trainPredictions\": trainPreds,\n",
    "    \n",
    "    # valid\n",
    "    \"validIds\": lc_ids[\"validation\"],\n",
    "    \"validLabels\": lc_ids[\"labels_validation\"],\n",
    "    \"validPredictions\": validPreds,\n",
    "    \n",
    "    # test\n",
    "    \"testIds\": lc_ids[\"test\"],\n",
    "    \"testLabels\": lc_ids[\"labels_test\"],\n",
    "    \"testPredictions\": testPreds,\n",
    "}\n",
    "\n",
    "# save object\n",
    "a_file = open(\"../../experiments/comparingModels/seed\" + str(seed) + \"/RF/predictionsRF.pkl\", \"wb\")\n",
    "pickle.dump(results, a_file)\n",
    "a_file.close()\n",
    "\n",
    "# # print(preds)\n",
    "# print(classification_report(preds, lc_ids['labels_test'][:10].astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "# a_file = open(\"../../experiments/comparingModels/\" + \"/testPredictionsRF.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output[\"testPredictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Features sorted by importance\n",
    "# features['train'].columns.values[np.argsort(rf.feature_importances_)[::-1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
