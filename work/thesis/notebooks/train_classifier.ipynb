{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = True\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = False\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 99\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# training\n",
    "epochs = 10\n",
    "\n",
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 1000\n",
    "\n",
    "# train with previous model\n",
    "trainWithPreviousModel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed)\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[428. 445. 393. 457. 460. 437.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed)\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "text = \"N° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "text_file.write(text)\n",
    "text_file.close()\n",
    "print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved model\n"
     ]
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "if trainWithPreviousModel:\n",
    "    \n",
    "    # loadgin model\n",
    "    model = torch.load(pathToSaveModel + \".txt\").to(device = cuda_device)\n",
    "    \n",
    "    print(\"loading saved model\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # defining model\n",
    "    model = EncoderClassifier(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes, passband = passband)\n",
    "\n",
    "    # mdel to GPU\n",
    "    model = model.to(device = cuda_device)\n",
    "    \n",
    "    print(\"creating model with default parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 10\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 10\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 10\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    3 / 10\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    4 / 10\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    5 / 10\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    6 / 10\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    7 / 10\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    8 / 10\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    9 / 10\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizera\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "\n",
    "#         # testing tensor size \n",
    "#         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "#         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        \n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "    \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "        \n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # save f1 scores\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(trainLoader, nameLabel = \"Train\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, nameLabel = \"Validation\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/f1Scores.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"N° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"N° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores)\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {‘true’, ‘pred’, ‘all’}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
