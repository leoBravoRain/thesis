{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = False\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = True\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 14\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# training\n",
    "epochs = 100000\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 15000\n",
    "\n",
    "# train with previous model\n",
    "trainWithPreviousModel = False\n",
    "\n",
    "# include delta errors\n",
    "includeDeltaErrors = True\n",
    "\n",
    "# band\n",
    "# passband = [5]\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "# include ohter feautures\n",
    "includeOtherFeatures = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "batch_training_size = 128\n",
    "\n",
    "# early stopping \n",
    "threshold_early_stop = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp 99 + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0 + include delta errors + max by class 15000 +  other features\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"exp \" + number_experiment + \" + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed) + \" + \" + (\"include delta errors\" if includeDeltaErrors else \"without delta errors\") + \" + max by class \" + str(max_elements_per_class) + \" + \" + (\"\" if includeOtherFeatures else \"not\") + \" other features\"\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass\" + str(int(max_elements_per_class/1000)) + \"k\"\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets, lightCurvesIds = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# saving ids\n",
    "saveLightCurvesIdsBeforeBalancing(trainIdx, valIdx, testIdx, folder_path, lightCurvesIds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_before_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "        seed = seed\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx,\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx,\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[444. 420. 439. 474. 400. 443.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.ar# return 0# return 0ange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# save ids of dataset to use (train, test and validation)\n",
    "saveLightCurvesIdsAfterBalancing(trainLoader, train_size, testLoader, test_size, validationLoader, validation_size, path = folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_after_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment parameters file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "if trainingOnGuanaco or trainWithJustPython:\n",
    "    text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "    text = \"N° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "    text_file.write(text)\n",
    "    text_file.close()\n",
    "    print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model with default parameters\n"
     ]
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "if trainWithPreviousModel:\n",
    "    \n",
    "    # loadgin model\n",
    "    model = torch.load(pathToSaveModel + \".txt\").to(device = cuda_device)\n",
    "    \n",
    "    print(\"loading saved model\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # defining model\n",
    "    model = EncoderClassifier(\n",
    "        latent_dim = latentDim, \n",
    "        hidden_dim = hiddenDim, \n",
    "        input_dim = inputDim, \n",
    "        num_classes = num_classes, \n",
    "        passband = passband, \n",
    "        includeDeltaErrors = includeDeltaErrors,\n",
    "        includeOtherFeatures = includeOtherFeatures,\n",
    "    )\n",
    "\n",
    "    # mdel to GPU\n",
    "    model = model.to(device = cuda_device)\n",
    "    \n",
    "    print(\"creating model with default parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=780, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # optimizeraa\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# # loss function\n",
    "# lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# # loss\n",
    "# train_loss = np.zeros((epochs,))\n",
    "# test_loss = np.zeros((epochs,))\n",
    "\n",
    "# # f1 scores\n",
    "# f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# # min global test loss \n",
    "# minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # # loss plot\n",
    "# # if it is not cluster\n",
    "# if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "#     # add f1 and loss plots\n",
    "#     fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "#     # # fig, ax = plt.subplots()\n",
    "    \n",
    "#     # error\n",
    "#     ax[0].set_xlabel(\"Epoch\")\n",
    "#     ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "#     # f1 score\n",
    "#     ax[1].set_xlabel(\"Epoch\")\n",
    "#     ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# # early stopping\n",
    "# # prior_test_error = 0\n",
    "# count_early_stop = 0\n",
    "# threshold_early_stop = threshold_early_stop\n",
    "\n",
    "\n",
    "# print(\"starting the training\")\n",
    "\n",
    "\n",
    "# # epoch\n",
    "# for nepoch in range(epochs):\n",
    "        \n",
    "#     print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "#     ######## Train ###########\n",
    "#     epoch_train_loss = 0\n",
    "    \n",
    "#     for data_ in trainLoader:\n",
    "        \n",
    "#         data = data_[0]\n",
    "#         labels = data_[1].to(device = cuda_device)\n",
    "# #         labels = data_[1]\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "            \n",
    "#         # this take the deltas (time and magnitude)\n",
    "#         data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "# #         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "            \n",
    "#         # add other features\n",
    "#         # [batch size, features]\n",
    "# #         if includeOtherFeatures:\n",
    "#         if includeOtherFeatures:\n",
    "            \n",
    "#             otherFeatures = getOtherFeatures(data_[0]).to(device = cuda_device)\n",
    "                \n",
    "# #             print(np.any(torch.isnan(otherFeatures).cpu().numpy()))\n",
    "            \n",
    "#             if np.any(torch.isnan(otherFeatures).cpu().numpy()):\n",
    "                \n",
    "#                 print(f\"other features with nan values in epoch {nepoch}\")\n",
    "            \n",
    "            \n",
    "#             # get model output\n",
    "#             outputs = model.forward(data, includeDeltaErrors, otherFeatures)\n",
    "            \n",
    "            \n",
    "#             # #         # testing tensor size \n",
    "# # #         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "# # #         print(\"test ok\")\n",
    "        \n",
    "#         else:\n",
    "            \n",
    "#             # get model output\n",
    "#             outputs = model.forward(data, includeDeltaErrors)\n",
    "\n",
    "        \n",
    "# #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing if means and iq are correct\n",
    "\n",
    "# channels = [0, 1, 2, 3, 4, 5]\n",
    "# indexs = np.random.choice(len(data_[2]), 2)\n",
    "\n",
    "# # print(indexs)\n",
    "\n",
    "# fig, ax = plt.subplots(\n",
    "#     len(indexs), \n",
    "#     len(channels),\n",
    "#     figsize = (12, 2*len(indexs)),\n",
    "#     tight_layout = True,\n",
    "# )\n",
    "\n",
    "# for index in np.arange(len(indexs)):\n",
    "    \n",
    "#     for channel in channels:\n",
    "    \n",
    "#         mask = data_[0][indexs[index], channel, 3, :]\n",
    "\n",
    "#         mask = mask.type(torch.BoolTensor)\n",
    "    \n",
    "# #         print(f\"index: {indexs[index]}\")\n",
    "        \n",
    "#         # print(\"data shape\")\n",
    "#         # print(data_[0].shape)\n",
    "\n",
    "#         # datashape: [ 128, 6, 4, 72 ]\n",
    "#         ax[index][channel].scatter(\n",
    "#             data_[0][indexs[index], channel, 0, mask], \n",
    "#             data_[0][indexs[index], channel, 1, mask],\n",
    "#         )\n",
    "\n",
    "#         # print(\"values:\")\n",
    "#         # print(otherFeatures[index, 0])\n",
    "\n",
    "\n",
    "#         # manual mean\n",
    "#         manualMean = torch.mean(data_[0][indexs[index], channel, 1, mask])\n",
    "\n",
    "# #         ax[index][channel].hlines(\n",
    "# #             manualMean, \n",
    "# #             xmin = data_[0][indexs[index], channel, 0, mask][0], \n",
    "# #             xmax = data_[0][indexs[index], channel, 0, mask][-1],\n",
    "# #             color = \"r\"\n",
    "# #         )\n",
    "        \n",
    "#         # analyze features\n",
    "#         ax[index][channel].hlines(\n",
    "#             otherFeatures[indexs[index], channel].item(), \n",
    "#             xmin = data_[0][indexs[index], channel, 0, mask][0], \n",
    "#             xmax = data_[0][indexs[index], channel, 0, mask][-1],\n",
    "#             color = \"r\"\n",
    "#         )\n",
    "        \n",
    "#         # test mean\n",
    "#         assert manualMean.item() == otherFeatures[indexs[index], channel].item()\n",
    "#         print(\"mean test ok\")\n",
    "\n",
    "        \n",
    "#         iqManual =  torch.kthvalue(data_[0][indexs[index], channel, 1, mask], int(0.75*data_[0][indexs[index], channel, 1, mask].shape[0]))[0] - torch.kthvalue(data_[0][indexs[index], channel, 1, mask], int(0.25*data_[0][indexs[index], channel, 1, mask].shape[0]))[0]\n",
    "\n",
    "#         assert iqManual.item() == otherFeatures[indexs[index], 6 + channel].item()\n",
    "#         print(\"iq test ok\")\n",
    "        \n",
    "        \n",
    "# #         print(manualMean.item())\n",
    "# #         print(otherFeatures[indexs[index], channel].item())\n",
    "# #         print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 5\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 5\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "saving losses\n",
      "saving f1 scores\n",
      "early stopping counter:  1\n",
      "epoch:    2 / 5\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "saving losses\n",
      "saving f1 scores\n",
      "early stopping counter:  2\n",
      "epoch:    3 / 5\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "saving losses\n",
      "saving f1 scores\n",
      "early stopping counter:  3\n",
      "epoch:    4 / 5\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizeraa\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "# prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = threshold_early_stop\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "            \n",
    "        # add other features\n",
    "        # [batch size, features]\n",
    "#         if includeOtherFeatures:\n",
    "        if includeOtherFeatures:\n",
    "            \n",
    "            otherFeatures = getOtherFeatures(data_[0]).to(device = cuda_device)\n",
    "                \n",
    "#             print(np.any(torch.isnan(otherFeatures).cpu().numpy()))\n",
    "            \n",
    "            if np.any(torch.isnan(otherFeatures).cpu().numpy()):\n",
    "                \n",
    "                print(f\"other features with nan values in epoch {nepoch}\")\n",
    "            \n",
    "            \n",
    "            # get model output\n",
    "            outputs = model.forward(data, includeDeltaErrors, otherFeatures)\n",
    "            \n",
    "            \n",
    "            # #         # testing tensor size \n",
    "# #         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "# #         print(\"test ok\")\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # get model output\n",
    "            outputs = model.forward(data, includeDeltaErrors)\n",
    "\n",
    "        if np.any(torch.isnan(outputs).cpu().numpy()):\n",
    "                \n",
    "                print(f\"outpues with nan values in epoch {nepoch}\")\n",
    "                \n",
    "#         print(ouput)\n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "    \n",
    "#         print(np.any(torch.isnan(outputs).numpy()))\n",
    "        \n",
    "#         # data validation\n",
    "#         if np.any(torch.isnan(outputs).cpu().numpy()) or np.any(torch.isinf(outputs).cpu().numpy()):\n",
    "            \n",
    "#             print(\"invalid input detected at iteration \", nepoch)\n",
    "            \n",
    "#             print(\"data: \", data)\n",
    "            \n",
    "#             print(\"outputs \", outputs)\n",
    "            \n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "            \n",
    "        if np.any(torch.isnan(loss).cpu().numpy()):\n",
    "                \n",
    "                print(f\"loss with nan values in epoch {nepoch}\")\n",
    "                \n",
    "#         print(loss)\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "    \n",
    "        if includeOtherFeatures:\n",
    "            \n",
    "            otherFeatures = getOtherFeatures(data_[0]).to(device = cuda_device)\n",
    "        \n",
    "# #         # testing tensor size \n",
    "# #         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "# #         print(\"test ok\")\n",
    "        \n",
    "            # get model output\n",
    "            outputs = model.forward(data, includeDeltaErrors, otherFeatures)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        else:\n",
    "        \n",
    "            # get model output\n",
    "            outputs = model.forward(data, includeDeltaErrors)\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "\n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    #### save losses ####\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ### save f1 scores ####\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    # If minimum global validation error does not decrease in X epochs, so stop training\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the min valid error\n",
    "    if test_loss[nepoch] > minTestLossGlobalSoFar:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "        \n",
    "    # if it is smaller\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop >= threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n\".format(nepoch, count_early_stop)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "lc smaller than 3. IQ value filled with 0\n",
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(\n",
    "    trainLoader, \n",
    "    nameLabel = \"Train\", \n",
    "    passband = passband, \n",
    "    model = model, \n",
    "    staticLabels = only_these_labels, \n",
    "    number_experiment = number_experiment, \n",
    "    expPath = expPath, \n",
    "    includeDeltaErrors = includeDeltaErrors, \n",
    "    includeOtherFeatures = includeOtherFeatures\n",
    ")\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, \n",
    "                                    nameLabel = \"Validation\", \n",
    "                                    passband = passband, \n",
    "                                    model = model, \n",
    "                                    staticLabels = only_these_labels, \n",
    "                                    number_experiment = number_experiment, \n",
    "                                    expPath = expPath, \n",
    "                                    includeDeltaErrors = includeDeltaErrors, \n",
    "                                    includeOtherFeatures = includeOtherFeatures\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/99/seed0/maxClass15k/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "# losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "losses = pd.read_csv(folder_path + \"/training_losses.csv\")\n",
    "# f1 scores\n",
    "# f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass15k\" + \"/f1Scores.csv\")\n",
    "f1Scores = pd.read_csv(folder_path + \"/f1Scores.csv\")\n",
    "\n",
    "print(folder_path)\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "maxPlot = 100\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"N° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:maxPlot, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:maxPlot, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"N° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores.iloc[:maxPlot])\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/14/seed0/maxClass15k/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {‘true’, ‘pred’, ‘all’}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv(folder_path  + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv(folder_path + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(folder_path)\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/99/seed0/maxClass15k/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/99/seed0/maxClass15k/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
