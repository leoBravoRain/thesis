{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = True\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = False\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 9\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# training\n",
    "epochs = 10000\n",
    "\n",
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 15000\n",
    "\n",
    "# train with previous model\n",
    "trainWithPreviousModel = False\n",
    "\n",
    "# include delta errors\n",
    "includeDeltaErrors = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp 99 + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0 + without delta errors + max by class 15000\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"exp \" + number_experiment + \" + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed) + \" + \" + (\"include delta errors\" if includeDeltaErrors else \"without delta errors\") + \" + max by class \" + str(max_elements_per_class)\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory /home/leo/Desktop/thesis/work/thesis/experiments/99/seed0/maxClass15k \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass\" + str(int(max_elements_per_class/1000)) + \"k\"\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets, lightCurvesIds = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# saving ids\n",
    "saveLightCurvesIdsBeforeBalancing(trainIdx, valIdx, testIdx, folder_path, lightCurvesIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_before_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[438. 446. 458. 436. 424. 418.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.ar# return 0# return 0ange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# save ids of dataset to use (train, test and validation)\n",
    "saveLightCurvesIdsAfterBalancing(trainLoader, train_size, testLoader, test_size, validationLoader, validation_size, path = folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.15000000e+02 1.84351210e+07 3.04707000e+05 6.46035410e+07\n",
      " 1.01983865e+08 7.13067330e+07 6.09113770e+07 9.37849190e+07\n",
      " 1.18422000e+05 6.70893270e+07 7.34029680e+07 2.35641120e+07\n",
      " 2.45129000e+05 7.00022810e+07 1.68000000e+02 2.16819040e+07\n",
      " 3.03867400e+06 7.39584320e+07 3.26167000e+05 2.67144050e+07\n",
      " 8.57806800e+07 2.00513400e+07 8.13126180e+07 1.46743000e+05\n",
      " 1.24598677e+08 2.93084150e+07 2.89752000e+05 1.15136821e+08\n",
      " 8.92998280e+07 3.32580000e+04 1.11633916e+08 2.53577000e+05\n",
      " 1.71720000e+04 6.73912950e+07 4.06493920e+07 4.59914970e+07\n",
      " 4.92076100e+07 1.03817167e+08 7.07024020e+07 7.44407180e+07\n",
      " 8.04210000e+04 8.84596940e+07 3.38438900e+07 9.03990000e+04\n",
      " 9.44634650e+07 1.30219752e+08 1.11290000e+05 4.72358820e+07\n",
      " 1.22716000e+05 9.12266650e+07 1.44695000e+05 2.79000000e+03\n",
      " 4.42773460e+07 3.04991000e+05 9.90819900e+06 3.29394000e+05\n",
      " 4.98169030e+07 1.68500000e+04 5.17401290e+07 1.04068719e+08\n",
      " 8.21964740e+07 9.19308310e+07 1.05090870e+07 1.08193740e+07\n",
      " 6.88570030e+07 2.35259300e+06 6.58690000e+04 7.87223470e+07\n",
      " 2.50572000e+05 4.42600000e+04 1.22937949e+08 6.67300060e+07\n",
      " 7.71128500e+06 3.09784180e+07 1.01441464e+08 6.48500000e+04\n",
      " 3.04846000e+05 6.03745320e+07 4.22582590e+07 6.30761300e+06\n",
      " 1.15535088e+08 7.09010000e+04 8.72995950e+07 7.33675090e+07\n",
      " 4.48360000e+04 3.65853130e+07 5.33892620e+07 2.83910000e+04\n",
      " 3.12787000e+05 2.45318400e+07 2.75639000e+05 1.03943330e+08\n",
      " 1.81598000e+05 5.64047340e+07 3.38035000e+05 5.75610000e+04\n",
      " 8.05697900e+06 2.66762000e+05 6.26371270e+07 1.83631000e+05\n",
      " 2.05278000e+05 2.20304350e+07 8.54663490e+07 2.43870590e+07\n",
      " 6.27874180e+07 6.66170320e+07 2.95570970e+07 2.66861140e+07\n",
      " 1.83985000e+05 1.03364815e+08 1.72461000e+05 7.82930820e+07\n",
      " 9.66205530e+07 9.36205860e+07 2.54842000e+05 3.68379700e+06\n",
      " 1.19388820e+08 7.11887600e+07 4.48157720e+07 6.74869560e+07\n",
      " 1.11327134e+08 6.04729680e+07 5.59317380e+07 1.20966302e+08\n",
      " 1.45390000e+04 6.34804680e+07 1.05128080e+08 5.98897550e+07\n",
      " 4.97820000e+04 2.53972000e+05 4.13793400e+06 1.23484109e+08\n",
      " 1.04515954e+08 3.54637500e+07 3.12964000e+05 2.23553440e+07\n",
      " 2.02601000e+05 7.71494210e+07 3.31115090e+07 2.48490000e+04\n",
      " 2.12084000e+05 1.29637000e+05 4.96201690e+07 2.76083000e+05\n",
      " 7.02158830e+07 1.18343993e+08 8.47580000e+04 8.99118130e+07\n",
      " 3.31624000e+05 7.42561780e+07 2.94167280e+07 2.81823000e+05\n",
      " 2.93610090e+07 2.30393980e+07 2.33751160e+07 1.12163086e+08\n",
      " 7.75034410e+07 1.03034798e+08 2.92867000e+05 8.23249330e+07\n",
      " 1.06438996e+08 7.82919710e+07 1.17565211e+08 8.90027070e+07\n",
      " 7.30019000e+06 1.77873450e+07 7.22560000e+04 1.03633000e+05\n",
      " 1.19171430e+07 8.45813220e+07 8.69344780e+07 2.30769000e+05\n",
      " 1.28814583e+08 6.64333070e+07 1.79200720e+07 2.52924000e+05\n",
      " 1.16375549e+08 9.82318650e+07 1.76662000e+05 2.80857000e+05\n",
      " 1.21853930e+07 4.69580000e+04 4.51150000e+04 1.52682000e+05\n",
      " 1.21429195e+08 1.19423000e+05 4.93288170e+07 1.24361000e+05\n",
      " 1.33773000e+05 2.11120000e+05 5.98119520e+07 7.72541790e+07\n",
      " 2.66380000e+04 1.29045287e+08 2.60709000e+05 8.93300000e+03\n",
      " 2.16921910e+07 8.71759590e+07 1.60737000e+05 6.36035200e+06\n",
      " 1.90040000e+05 4.56702800e+06 7.70330020e+07 6.57254610e+07\n",
      " 6.63250000e+04 1.29705825e+08 1.01244973e+08 1.30408188e+08\n",
      " 9.49353280e+07 3.42430000e+04 2.62664590e+07 6.11010000e+04\n",
      " 9.12640000e+04 7.50930830e+07 9.13350000e+04 2.79617000e+05\n",
      " 8.82280190e+07 1.09968805e+08 1.21961940e+07 7.41830000e+04\n",
      " 6.24907710e+07 2.02345390e+07 2.48112000e+05 2.90111710e+07\n",
      " 1.12989415e+08 1.15337100e+06 2.68082950e+07 1.17649911e+08\n",
      " 2.15351000e+05 1.52640000e+05 2.60830000e+04 3.23956000e+05\n",
      " 2.19728000e+05 1.65233000e+05 4.07187280e+07 1.11594831e+08\n",
      " 4.96260030e+07 3.11713840e+07 4.03084390e+07 4.84598740e+07\n",
      " 1.03504440e+08 4.79587570e+07 4.23615010e+07 1.20820188e+08\n",
      " 1.03995649e+08 9.40289320e+07 7.01434310e+07 4.75097670e+07\n",
      " 2.39112000e+05 7.51277500e+06 1.71234000e+05 4.04468080e+07\n",
      " 2.71240000e+04 8.25498870e+07 1.16382337e+08 1.17016000e+05\n",
      " 5.36555070e+07 2.52920000e+05 2.54509000e+05 8.55899640e+07\n",
      " 4.04263580e+07 4.10900000e+03 2.92529850e+07 9.50499150e+07\n",
      " 1.62418720e+07 1.23884873e+08 8.24010000e+04 2.25416000e+05\n",
      " 6.68125460e+07 5.82370000e+06 1.05200000e+04 1.50266000e+05\n",
      " 2.56560400e+07 1.01633495e+08 5.23201600e+07 1.83622000e+05\n",
      " 2.63348000e+05 4.72841820e+07 2.87470000e+04 5.24379920e+07\n",
      " 1.00848667e+08 2.96570000e+05 8.77520750e+07 1.95279900e+06\n",
      " 4.84260000e+04 1.11771139e+08 1.10803113e+08 2.45853000e+05\n",
      " 7.44524300e+07 3.05690000e+05 1.51458000e+05 3.41216700e+06\n",
      " 1.26970000e+05 6.91141840e+07 9.55080000e+04 2.54340000e+04\n",
      " 3.82440000e+04 4.56273770e+07 7.60020000e+04 1.15969914e+08\n",
      " 1.56386000e+05 8.42241940e+07 7.55091000e+06 3.16379000e+05\n",
      " 1.04412911e+08 7.18900000e+04 5.00895860e+07 1.60111000e+05\n",
      " 8.30819460e+07 7.78412830e+07 2.59643000e+05 1.27145862e+08\n",
      " 1.27843563e+08 5.78136490e+07 1.04208000e+05 1.02464956e+08\n",
      " 1.30386135e+08 2.03320120e+07 3.13228050e+07 3.43463760e+07\n",
      " 6.90735950e+07 3.18410000e+05 2.15038000e+05 4.10790950e+07\n",
      " 1.83824000e+05 1.75848000e+05 1.40024000e+05 1.77149000e+05]\n"
     ]
    }
   ],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_after_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment parameters file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "if trainingOnGuanaco or trainWithJustPython:\n",
    "    text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "    text = \"N° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "    text_file.write(text)\n",
    "    text_file.close()\n",
    "    print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model with default parameters\n"
     ]
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "if trainWithPreviousModel:\n",
    "    \n",
    "    # loadgin model\n",
    "    model = torch.load(pathToSaveModel + \".txt\").to(device = cuda_device)\n",
    "    \n",
    "    print(\"loading saved model\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # defining model\n",
    "    model = EncoderClassifier(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes, passband = passband, includeDeltaErrors = includeDeltaErrors)\n",
    "\n",
    "    # mdel to GPU\n",
    "    model = model.to(device = cuda_device)\n",
    "    \n",
    "    print(\"creating model with default parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=512, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 3\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 3\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 3\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizera\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "\n",
    "#         # testing tensor size \n",
    "#         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "#         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data, includeDeltaErrors)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "    \n",
    "        outputs = model.forward(data, includeDeltaErrors)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "    \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "        \n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # save f1 scores\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(trainLoader, nameLabel = \"Train\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath, includeDeltaErrors = includeDeltaErrors)\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, nameLabel = \"Validation\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath, includeDeltaErrors = includeDeltaErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed0/maxClass15k/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "# losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "losses = pd.read_csv(tmpLocal + expPath + \"/training_losses.csv\")\n",
    "# f1 scores\n",
    "# f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass15k\" + \"/f1Scores.csv\")\n",
    "f1Scores = pd.read_csv(tmpLocal + expPath + \"/f1Scores.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"N° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"N° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores)\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed0/maxClass15k/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {‘true’, ‘pred’, ‘all’}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv(tmpLocal + expPath  + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv(tmpLocal + expPath + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed0/maxClass15k/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed0/maxClass15k/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
