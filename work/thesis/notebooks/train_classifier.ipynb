{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = True\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = False\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 9\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# training\n",
    "epochs = 10000\n",
    "\n",
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 15000\n",
    "\n",
    "# train with previous model\n",
    "trainWithPreviousModel = False\n",
    "\n",
    "# include delta errors\n",
    "includeDeltaErrors = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp 9 encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0 + without delta errors + max by class 15000\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"exp \" + number_experiment + \" encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed) + \" + \" + (\"include delta errors\" if includeDeltaErrors else \"without delta errors\") + \" + max by class \" + str(max_elements_per_class)\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass\" + str(int(max_elements_per_class/1000)) + \"k\"\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[419. 456. 412. 428. 442. 463.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment parameters file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "if trainingOnGuanaco or trainWithJustPython:\n",
    "    text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "    text = \"NÂ° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "    text_file.write(text)\n",
    "    text_file.close()\n",
    "    print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model with default parameters\n"
     ]
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "if trainWithPreviousModel:\n",
    "    \n",
    "    # loadgin model\n",
    "    model = torch.load(pathToSaveModel + \".txt\").to(device = cuda_device)\n",
    "    \n",
    "    print(\"loading saved model\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # defining model\n",
    "    model = EncoderClassifier(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes, passband = passband, includeDeltaErrors = includeDeltaErrors)\n",
    "\n",
    "    # mdel to GPU\n",
    "    model = model.to(device = cuda_device)\n",
    "    \n",
    "    print(\"creating model with default parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=512, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 3\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 3\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 3\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizera\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "\n",
    "#         # testing tensor size \n",
    "#         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "#         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data, includeDeltaErrors)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "    \n",
    "        outputs = model.forward(data, includeDeltaErrors)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "    \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "        \n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # save f1 scores\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(trainLoader, nameLabel = \"Train\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath, includeDeltaErrors = includeDeltaErrors)\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, nameLabel = \"Validation\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath, includeDeltaErrors = includeDeltaErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed0/maxClass15k/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "# losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "losses = pd.read_csv(tmpLocal + expPath + \"/training_losses.csv\")\n",
    "# f1 scores\n",
    "# f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass15k\" + \"/f1Scores.csv\")\n",
    "f1Scores = pd.read_csv(tmpLocal + expPath + \"/f1Scores.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"NÂ° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"NÂ° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores)\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed0/maxClass15k/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {âtrueâ, âpredâ, âallâ}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv(tmpLocal + expPath  + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv(tmpLocal + expPath + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed0/maxClass15k/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed0/maxClass15k/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
