{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = True\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = False\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 99\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# training\n",
    "epochs = 10\n",
    "\n",
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 1\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed)\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[437. 437. 443. 437. 458. 408.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed)\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment parameters file created\n"
     ]
    }
   ],
   "source": [
    "# store varibales on file\n",
    "text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "text = \"NÂ° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "text_file.write(text)\n",
    "text_file.close()\n",
    "print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "\n",
    "# defining model\n",
    "model = EncoderClassifier(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes, passband = passband)\n",
    "\n",
    "# mdel to GPU\n",
    "model = model.to(device = cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, 'E'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-46117762f896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexpPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/bestScoresModelTraining.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \"functionality.\")\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'E'."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../\" + expPath + \"/bestScoresModelTraining.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 3\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 3\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 3\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "training has finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizera\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "\n",
    "#         # testing tensor size \n",
    "#         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "#         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "        data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        \n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "    \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "        \n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # save f1 scores\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores with normalize: true\n",
      "saving confusion matrix scores with normalize: pred\n",
      "saving confusion matrix scores with normalize: all\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(trainLoader, nameLabel = \"Train\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, nameLabel = \"Validation\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Exit from code, because we are in cluster or running locally. Training has finished.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Exit from code, because we are in cluster or running locally. Training has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/f1Scores.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"NÂ° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"NÂ° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores)\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed1/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {âtrueâ, âpredâ, âallâ}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv('../experiments/' + number_experiment + \"/seed\" + str(seed) + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed1/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
