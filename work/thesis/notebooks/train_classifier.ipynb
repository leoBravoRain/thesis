{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebook is to train the encoder as a classifier with the idea of validate the encoder architecture first and then use this to train the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco:\n",
    "# 1) comment the %matplotlib magic in next block and any magic (something like %code)\n",
    "# 2) Change to True the trainingOnGuanaco vairbale\n",
    "# 3) set epoch with an appropiate number\n",
    "# 4) add comment to experiemnts\n",
    "# 5) Add this file as python file \n",
    "# 6) Change launchJobOnGuanaco file to run this file but with python format\n",
    "trainingOnGuanaco = False\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = False\n",
    "\n",
    "# seed to generate same datasets\n",
    "seed = 0\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 99\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# training\n",
    "epochs = 100\n",
    "\n",
    "# cuda device\n",
    "cuda_device = 0\n",
    "cuda_device = \"cuda:\" + str(cuda_device)\n",
    "\n",
    "# max elements by class\n",
    "max_elements_per_class = 15000\n",
    "\n",
    "# train with previous model\n",
    "trainWithPreviousModel = False\n",
    "\n",
    "# include delta errors\n",
    "includeDeltaErrors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "\n",
    "# periodic\n",
    "# only_these_labels = [16, 92, 53]\n",
    "\n",
    "# periodic + variable\n",
    "only_these_labels = [16, 92, 53, 88, 65, 6]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp 99 + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + 6 channels + seed 0 + include delta errors + max by class 15000\n"
     ]
    }
   ],
   "source": [
    "# add general comment about experiment \n",
    "# comment = \"encoder as clasifier with periodic + variable (with class balancing) + 1 conv layer more\"\n",
    "comment = \"exp \" + number_experiment + \" + encoder as clasifier with periodic + variable + class balancing + 1 conv layer more + \" + str(len(passband)) + \" channels + seed \" + str(seed) + \" + \" + (\"include delta errors\" if includeDeltaErrors else \"without delta errors\") + \" + max by class \" + str(max_elements_per_class)\n",
    "\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# local imports\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "sys.path.append('../models')\n",
    "# from classifier import EncoderClassifier, \n",
    "from classifierPrototype import EncoderClassifier\n",
    "\n",
    "sys.path.append(\"./aux/\")\n",
    "from auxFunctions import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "tmpGuanaco = \"/home/lbravo/thesis/thesis/work/thesis/\"\n",
    "tmpLocal = \"/home/leo/Desktop/thesis/work/thesis/\"\n",
    "\n",
    "expPath = \"experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass\" + str(int(max_elements_per_class/1000)) + \"k\"\n",
    "\n",
    "folder_path = (tmpGuanaco + expPath) if trainingOnGuanaco else (tmpLocal + expPath)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    except OSError as error:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "        print(error)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = (tmpGuanaco + expPath + \"/model\") if trainingOnGuanaco else (tmpLocal + expPath + \"/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 2 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticData/plasticc_test_set_batch1.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels, max_elements_per_class = max_elements_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset test ok\n"
     ]
    }
   ],
   "source": [
    "assert torch_dataset_lazy.__len__() != 494096, \"dataset should be smaller\"\n",
    "print(\"dataset test ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# light curves ids: 3276\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "# get light curves ids, targets\n",
    "ids, targets, lightCurvesIds = getLightCurvesIds(torch_dataset_lazy)\n",
    "\n",
    "# test array shapes\n",
    "# assert len(targets) == torch_dataset_lazy.__len__()\n",
    "# print(ids, len(ids), targets, len(targets))\n",
    "# get light curves targets\n",
    "print(\"# light curves ids: \" + str(len(ids)))\n",
    "\n",
    "# split training\n",
    "trainIdx, tmpIdx = train_test_split(\n",
    "    ids,\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = targets,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "tmpIdx = tmpIdx.astype(int)\n",
    "\n",
    "# split val, test\n",
    "valIdx, testIdx = train_test_split(\n",
    "    tmpIdx,\n",
    "#     targets,\n",
    "    test_size = 0.5,\n",
    "    shuffle = True,\n",
    "    stratify = targets[tmpIdx],\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "# float to int\n",
    "trainIdx = trainIdx.astype(int)\n",
    "valIdx = valIdx.astype(int)\n",
    "testIdx = testIdx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# saving ids\n",
    "saveLightCurvesIdsBeforeBalancing(trainIdx, valIdx, testIdx, folder_path, lightCurvesIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_before_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,  93.,   0.,   0.,   0.,   4., 104.,   0.,   0., 111.]),\n",
       " array([ 6. , 14.6, 23.2, 31.8, 40.4, 49. , 57.6, 66.2, 74.8, 83.4, 92. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # analize classes distributino\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "ax[0].hist(targets[trainIdx])\n",
    "ax[1].hist(targets[valIdx])\n",
    "ax[2].hist(targets[testIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2620\n",
      "validation size:  328\n",
      "test size: 328\n",
      "sum:  3276\n"
     ]
    }
   ],
   "source": [
    "# # Spliting the data\n",
    "\n",
    "# # print(torch_dataset_lazy.__len__())\n",
    "\n",
    "totalSize = torch_dataset_lazy.__len__()\n",
    "\n",
    "# totalSize = totalSize\n",
    "# # print(totalSize)\n",
    "\n",
    "# selecting train splitting\n",
    "# train_size = int(0.8 * totalSize)\n",
    "train_size = trainIdx.shape[0]\n",
    "#print(train_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# validation_size = math.floor((totalSize - train_size)/3)\n",
    "validation_size = valIdx.shape[0]\n",
    "# #print(validation_size)\n",
    "\n",
    "# # getting test splitting\n",
    "# test_size = totalSize - train_size - validation_size\n",
    "test_size = testIdx.shape[0]\n",
    "# #print(test_size)\n",
    "\n",
    "# # spliting the torch dataset\n",
    "# trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(\n",
    "#     torch_dataset_lazy, \n",
    "#     [train_size, validation_size, test_size],\n",
    "    \n",
    "#     # set seed\n",
    "#     generator = torch.Generator().manual_seed(seed)\n",
    "# )\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "totTmp = train_size+ validation_size + test_size\n",
    "print(\"sum: \", totTmp)\n",
    "assert torch_dataset_lazy.__len__() == totTmp, \"dataset partition should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initila distribution\n",
      "[ 157  927   36 1042  733  381]\n"
     ]
    }
   ],
   "source": [
    "print(\"initila distribution\")\n",
    "# initialClassesDistribution = countClasses(trainDataset, only_these_labels)\n",
    "initialClassesDistribution = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "print(initialClassesDistribution)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.arange(len(only_these_labels)), height = initialClassesDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# training loader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    torch_dataset_lazy, \n",
    "    batch_size = batch_training_size, \n",
    "    # to balance classes\n",
    "    sampler=ImbalancedDatasetSampler(\n",
    "        torch_dataset_lazy, \n",
    "        indices = trainIdx,\n",
    "#         indices = [0, 1, 2]\n",
    "    ),\n",
    "    # each worker retrieve data from disk, so the data will be ready to be processed by main process. The main process should get the data from disk, so if workers > 0, the workers will get the data (not the main process)\n",
    "    num_workers = 4,\n",
    "    \n",
    "    # https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "    # the dataloader loads the data in pinned memory (instead of pageable memory), avoiding one process (to transfer data from pageable memory to pinned memory, work done by CUDA driver)\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "    batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        valIdx\n",
    "    ),\n",
    ")\n",
    "\n",
    "# # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "#     validationDataset, \n",
    "    torch_dataset_lazy,\n",
    "#     batch_size= batch_training_size,  \n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    sampler = torch.utils.data.SubsetRandomSampler(\n",
    "        testIdx\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced distribution\n",
      "[432. 417. 413. 460. 468. 430.]\n"
     ]
    }
   ],
   "source": [
    "print(\"balanced distribution\")\n",
    "balancedClassesDistribution = countClasses(trainLoader, only_these_labels)\n",
    "\n",
    "print(balancedClassesDistribution)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x = np.ar# return 0# return 0ange(6), height = balancedClassesDistribution)\n",
    "# ax.bar(x = only_these_labels, height = temp2, width = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light curves ids saved on a file\n"
     ]
    }
   ],
   "source": [
    "# save ids of dataset to use (train, test and validation)\n",
    "saveLightCurvesIdsAfterBalancing(trainLoader, train_size, testLoader, test_size, validationLoader, validation_size, path = folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ids dictionary\n",
    "# a_file = open(folder_path + \"/dataset_ids_after_balancing.pkl\", \"rb\")\n",
    "# output = pickle.load(a_file)\n",
    "# print(output[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment parameters file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store varibales on file\n",
    "if trainingOnGuanaco or trainWithJustPython:\n",
    "    text_file = open(\"../\" + expPath + \"/experimentParameters.txt\" , \"w\")\n",
    "    text = \"NÂ° experiment: {7}\\n General comment: {13}\\n Classes: {0}\\n train_size: {9}\\n validation_size: {10}\\n test_size: {11}\\n total dataset size: {12}\\n Epochs: {8}\\n Latent dimension: {1}\\n Hidden dimension: {2}\\n Input dimension: {3}\\n Passband: {4}\\n Learning rate: {5}\\n Batch training size: {6}\\n initial train classes distribution: {14}\\nbalanced train class distribution: {15}\".format(only_these_labels, latentDim, hiddenDim, inputDim, passband, learning_rate, batch_training_size, number_experiment, epochs, train_size, validation_size, test_size, train_size + validation_size + test_size, comment, initialClassesDistribution, balancedClassesDistribution)\n",
    "    text_file.write(text)\n",
    "    text_file.close()\n",
    "    print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model with default parameters\n"
     ]
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "# passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "if trainWithPreviousModel:\n",
    "    \n",
    "    # loadgin model\n",
    "    model = torch.load(pathToSaveModel + \".txt\").to(device = cuda_device)\n",
    "    \n",
    "    print(\"loading saved model\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # defining model\n",
    "    model = EncoderClassifier(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes, passband = passband, includeDeltaErrors = includeDeltaErrors)\n",
    "\n",
    "    # mdel to GPU\n",
    "    model = model.to(device = cuda_device)\n",
    "    \n",
    "    print(\"creating model with default parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderClassifier(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(6, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv3): PartialConv(\n",
      "    (input_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=6, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 100\n",
      "training\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  1.799015998840332\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  3.5935068130493164\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  5.388279557228088\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  7.17830765247345\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  8.971843838691711\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  10.768799424171448\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  12.558684825897217\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  14.352168440818787\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  16.147653102874756\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  17.94193124771118\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  19.730733036994934\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  21.524197936058044\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  23.316507816314697\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  25.10882270336151\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  26.900073409080505\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  28.69239592552185\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  30.48375701904297\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  32.28001534938812\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  34.07261562347412\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  35.86611497402191\n",
      "invalid input detected at iteration  0\n",
      "loss:  tensor(1.7927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  37.65886425971985\n",
      "0.014373612312870172\n",
      "validation\n",
      "loss:  tensor(1.7799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  1.7798928022384644\n",
      "loss:  tensor(1.7808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  3.560653805732727\n",
      "loss:  tensor(1.7812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  5.341893792152405\n",
      "test loss epoch:  0.01628626156144026\n",
      "f1 score epoch 0.04513888888888889\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    1 / 100\n",
      "training\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  1.7949155569076538\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  3.5885568857192993\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  5.377084016799927\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  7.170512437820435\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  8.96240520477295\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  10.753201842308044\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  12.55117130279541\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  14.339261651039124\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  16.13855004310608\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  17.92623519897461\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  19.717543721199036\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  21.506642937660217\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  23.30158269405365\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  25.095037698745728\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  26.887693405151367\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  28.686144471168518\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  30.47755455970764\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  32.27099823951721\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  34.059773206710815\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  35.848297357559204\n",
      "invalid input detected at iteration  1\n",
      "loss:  tensor(1.7890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  37.637346267700195\n",
      "0.014365399338816868\n",
      "validation\n",
      "loss:  tensor(1.7806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  1.7805989980697632\n",
      "loss:  tensor(1.7811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  3.5617252588272095\n",
      "loss:  tensor(1.7789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  5.34058678150177\n",
      "test loss epoch:  0.01628227677287125\n",
      "f1 score epoch 0.17708333333333334\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    2 / 100\n",
      "training\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  1.796265721321106\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  3.5897159576416016\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  5.380763649940491\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  7.178579211235046\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  8.973013877868652\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  10.76437520980835\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  12.555866718292236\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  14.346672654151917\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  16.14044988155365\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  17.932178616523743\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  19.728060007095337\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  21.5189471244812\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  23.305863976478577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  25.09838116168976\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  26.888702750205994\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  28.676236987113953\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  30.46647584438324\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  32.25663197040558\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  34.05018854141235\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  35.83746314048767\n",
      "invalid input detected at iteration  2\n",
      "loss:  tensor(1.7921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  37.62952744960785\n",
      "0.014362415057102233\n",
      "validation\n",
      "loss:  tensor(1.7801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  1.7800503969192505\n",
      "loss:  tensor(1.7799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  3.559987187385559\n",
      "loss:  tensor(1.7828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  5.342772006988525\n",
      "test loss epoch:  0.016288939045696723\n",
      "f1 score epoch 0.08159722222222222\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    3 / 100\n",
      "training\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  1.7885326147079468\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  3.578347325325012\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  5.367937088012695\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  7.160436511039734\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  8.948869228363037\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  10.741235256195068\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  12.531141877174377\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  14.326950073242188\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  16.11872136592865\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  17.909205317497253\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  19.705912470817566\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  21.495275020599365\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  23.28909206390381\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  25.08417248725891\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  26.875892400741577\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  28.668014883995056\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  30.4609397649765\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  32.250847697257996\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  34.03884494304657\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  35.83293557167053\n",
      "invalid input detected at iteration  3\n",
      "loss:  tensor(1.7884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  37.621293902397156\n",
      "0.014359272481830975\n",
      "validation\n",
      "loss:  tensor(1.7799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  1.779942512512207\n",
      "loss:  tensor(1.7800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  3.559950590133667\n",
      "loss:  tensor(1.7826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  5.342557311058044\n",
      "test loss epoch:  0.016288284484933063\n",
      "f1 score epoch 0.1267361111111111\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    4 / 100\n",
      "training\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  1.7923517227172852\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  3.5844807624816895\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  5.3814650774002075\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  7.174860000610352\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  8.968561291694641\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  10.75836730003357\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  12.55312991142273\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  14.343840718269348\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  16.13378643989563\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  17.922607421875\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.8016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  19.7241690158844\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  21.513232469558716\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  23.30962038040161\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  25.099101066589355\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  26.89043366909027\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  28.68279504776001\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  30.474162697792053\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  32.265385031700134\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  34.05861043930054\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  35.85466194152832\n",
      "invalid input detected at iteration  4\n",
      "loss:  tensor(1.7907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  37.64531707763672\n",
      "0.014368441632685771\n",
      "validation\n",
      "loss:  tensor(1.7822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  1.78224778175354\n",
      "loss:  tensor(1.7786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  3.5608294010162354\n",
      "loss:  tensor(1.7811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  5.341900587081909\n",
      "test loss epoch:  0.016286282277688746\n",
      "f1 score epoch 0.22366898148148148\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    5 / 100\n",
      "training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  1.7983028888702393\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  3.5848798751831055\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  5.373755931854248\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  7.164578318595886\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  8.956841826438904\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  10.744697570800781\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  12.540169358253479\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  14.330860376358032\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  16.122222900390625\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  17.913918495178223\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  19.703823685646057\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  21.49542009830475\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  23.28509271144867\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  25.07433533668518\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  26.859707236289978\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  28.64978516101837\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  30.442694664001465\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  32.2392543554306\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  34.03416872024536\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  35.82619094848633\n",
      "invalid input detected at iteration  5\n",
      "loss:  tensor(1.7834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  37.609638810157776\n",
      "0.014354823973342663\n",
      "validation\n",
      "loss:  tensor(1.7797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  1.7797473669052124\n",
      "loss:  tensor(1.7811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  3.5608471632003784\n",
      "loss:  tensor(1.7794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  5.340232014656067\n",
      "test loss epoch:  0.01628119516663435\n",
      "f1 score epoch 0.2277199074074074\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    6 / 100\n",
      "training\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  1.788177251815796\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  3.579043984413147\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  5.371336221694946\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  7.160934090614319\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  8.952338099479675\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  10.742331266403198\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  12.533020973205566\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  14.321955919265747\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  16.11997950077057\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  17.91053795814514\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  19.70455491542816\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  21.49398124217987\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  23.279251098632812\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  25.070542693138123\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  26.86461067199707\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  28.659548163414\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  30.447449564933777\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  32.23669195175171\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  34.02400016784668\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  35.81905174255371\n",
      "invalid input detected at iteration  6\n",
      "loss:  tensor(1.7840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  37.60302817821503\n",
      "0.014352300831379781\n",
      "validation\n",
      "loss:  tensor(1.7793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  1.779348611831665\n",
      "loss:  tensor(1.7803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  3.559681534767151\n",
      "loss:  tensor(1.7818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch test loss:  5.341458439826965\n",
      "test loss epoch:  0.016284934267765137\n",
      "f1 score epoch 0.2175925925925926\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "saving f1 scores\n",
      "epoch:    7 / 100\n",
      "training\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  1.793172001838684\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  3.5841506719589233\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  5.375314474105835\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  7.168570637702942\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  8.960331082344055\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  10.747596979141235\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  12.538081288337708\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  14.332570552825928\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  16.12246012687683\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  17.91651475429535\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  19.709404349327087\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  21.500939965248108\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  23.295745015144348\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7899, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch train loss:  25.08562445640564\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  26.87686312198639\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  28.668689250946045\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  30.46090030670166\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  32.24783647060394\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  34.038151144981384\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  35.82780158519745\n",
      "invalid input detected at iteration  7\n",
      "loss:  tensor(1.7920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch train loss:  37.619771003723145\n",
      "0.014358691222795093\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7feb35c2c050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/anaconda3/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 85943, 85944, 85945) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7ee7ab5c9163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# minibatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidationLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 85943, 85944, 85945) exited unexpectedly"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# optimizera\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.5)\n",
    "\n",
    "# loss function\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# f1 scores\n",
    "f1Scores = np.zeros((epochs, ))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "# if it is not cluster\n",
    "if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "    \n",
    "    # add f1 and loss plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (7, 3), tight_layout = True)\n",
    "    # # fig, ax = plt.subplots()\n",
    "    \n",
    "    # error\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Error\")\n",
    "    \n",
    "    \n",
    "    # f1 score\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"F1 score\")\n",
    "    \n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "\n",
    "# epoch\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    ######## Train ###########\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    print(\"training\")\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "#         labels = data_[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # this take the deltas (time and magnitude)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "\n",
    "#         # testing tensor size \n",
    "#         assert data.shape == torch.Size([batch_training_size, len(passband), 4, 71]), \"Shape should be [minibatch size, channels, 4, 71]\"\n",
    "#         print(\"test ok\")\n",
    "        \n",
    "        # get model output\n",
    "        outputs = model.forward(data, includeDeltaErrors)\n",
    "        \n",
    "#         # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "    \n",
    "#         print(np.any(torch.isnan(outputs).numpy()))\n",
    "        \n",
    "        # data validation\n",
    "        if np.any(torch.isnan(outputs).cpu().numpy()) or np.any(torch.isinf(outputs).cpu().numpy()):\n",
    "            \n",
    "            print(\"invalid input detected at iteration \", nepoch)\n",
    "            \n",
    "            \n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        print(\"loss: \", loss)\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add loss value (of the currrent minibatch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "        print(\"epoch train loss: \", epoch_train_loss)\n",
    "\n",
    "    # get epoch loss value\n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    print(train_loss[nepoch])\n",
    "    \n",
    "    \n",
    "    ##### Validation ########\n",
    "    \n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    # check f1 score in each minibatch\n",
    "    f1Score = 0\n",
    "    \n",
    "    batchCounter = 0\n",
    "    \n",
    "    print(\"validation\")\n",
    "    \n",
    "    # minibatches\n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        labels = data_[1].to(device = cuda_device)\n",
    "        \n",
    "#         data = generateDeltas(data, passband).type(torch.FloatTensor).to(device = cuda_device)\n",
    "        data = generateDeltas(data, passband, includeDeltaErrors).type(torch.FloatTensor).to(device = cuda_device)\n",
    "    \n",
    "        outputs = model.forward(data, includeDeltaErrors)\n",
    "        \n",
    "#           # testing output shape size\n",
    "#         assert outputs.shape == torch.Size([batch_training_size, len(only_these_labels)]), \"Shape should be [minibatch, classes]\"\n",
    "#         print(\"test ok\")\n",
    "\n",
    "        # loss function\n",
    "        loss = lossFunction(outputs, mapLabels(labels, only_these_labels).to(device = cuda_device))\n",
    "        \n",
    "        print(\"loss: \", loss)\n",
    "        \n",
    "        #  store minibatch loss value\n",
    "        epoch_test_loss += loss.item()\n",
    "        \n",
    "        print(\"epoch test loss: \", epoch_test_loss)\n",
    "        # f1 score\n",
    "        f1Score += f1_score(mapLabels(labels, only_these_labels).cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy(), average = \"micro\")\n",
    "        \n",
    "        # batch counter\n",
    "        batchCounter += 1\n",
    "    \n",
    "    # get epoch test loss value\n",
    "    test_loss[nepoch] = epoch_test_loss / validation_size\n",
    "    \n",
    "    print(\"test loss epoch: \", test_loss[nepoch])\n",
    "    \n",
    "    # get epoch f1 score\n",
    "    f1Scores[nepoch] = f1Score / batchCounter\n",
    "    \n",
    "    print(\"f1 score epoch\", f1Scores[nepoch])\n",
    "    \n",
    "    # plot loss values\n",
    "    # if it's not cluster\n",
    "    if (not trainingOnGuanaco) or (not trainWithJustPython):\n",
    "\n",
    "        # loss values\n",
    "        ax[0].plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "        ax[0].plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # f1 score values\n",
    "        ax[1].plot(f1Scores[0: nepoch], linewidth = 3, c = \"green\")\n",
    "        \n",
    "        # plot\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"../\" + expPath + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if test_loss[nepoch] < minTestLossGlobalSoFar:\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = test_loss[nepoch]\n",
    "        \n",
    "        # save model\n",
    "        saveBestModel(model, pathToSaveModel, number_experiment, nepoch, minTestLossGlobalSoFar, expPath)\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"../\" + expPath + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # save f1 scores\n",
    "    print(\"saving f1 scores\")\n",
    "    np.savetxt(\"../\" + expPath + \"/f1Scores.csv\", f1Scores, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    \n",
    "# final message\n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(torch.isnan(outputs).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get metrics on trainig dataset\n",
    "getConfusionAndClassificationReport(trainLoader, nameLabel = \"Train\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath, includeDeltaErrors = includeDeltaErrors)\n",
    "\n",
    "\n",
    "# get metrics on validation dataset\n",
    "getConfusionAndClassificationReport(validationLoader, nameLabel = \"Validation\", passband = passband, model = model, staticLabels = only_these_labels, number_experiment = number_experiment, expPath = expPath, includeDeltaErrors = includeDeltaErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop execution if it's on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if  trainingOnGuanaco or trainWithJustPython:\n",
    "\n",
    "    sys.exit(\"Exit from code, because we are in cluster or running locally. Training has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/10/seed0/maxClass15k/experimentParameters.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses array\n",
    "# losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/seed\" + str(seed) + \"/training_losses.csv\")\n",
    "losses = pd.read_csv(folder_path + \"/training_losses.csv\")\n",
    "# f1 scores\n",
    "# f1Scores = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/seed\" + str(seed) + \"/maxClass15k\" + \"/f1Scores.csv\")\n",
    "f1Scores = pd.read_csv(folder_path + \"/f1Scores.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4), tight_layout = True)\n",
    "\n",
    "# loss\n",
    "ax[0].set_xlabel(\"NÂ° epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax[0].plot(losses.iloc[:, 1], label = \"validation\")\n",
    "ax[0].legend()\n",
    "\n",
    "# f1 scores\n",
    "ax[1].set_xlabel(\"NÂ° epoch\")\n",
    "ax[1].set_ylabel(\"F1 score\")\n",
    "ax[1].plot(f1Scores)\n",
    "\n",
    "# best model\n",
    "# values copied from the txt file\n",
    "# bestModelEpoch = 785\n",
    "# bestModelError = 0.00434128265165168\n",
    "# ax[0].scatter(bestModelEpoch, bestModelError, c = \"r\", linewidths = 10)\n",
    "# ax[1].scatter(bestModelEpoch, f1Scores.iloc[bestModelEpoch], c = \"r\", linewidths = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../experiments/9/seed0/maxClass15k/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "# select normalization\n",
    "# norm = {âtrueâ, âpredâ, âallâ}\n",
    "normalization = \"true\"\n",
    "\n",
    "# get confusion matrix\n",
    "cmTrain = pd.read_csv(tmpLocal + expPath  + '/confusionMatrixTrain_norm_' + normalization + '.csv', header = None) \n",
    "cmValidation = pd.read_csv(tmpLocal + expPath + '/confusionMatrixValidation_norm_' + normalization + '.csv', header = None) \n",
    "\n",
    "print(\"Training\")\n",
    "print(\"Normalization: \" + normalization)\n",
    "sn.heatmap(cmTrain, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation\")\n",
    "sn.heatmap(cmValidation, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed0/maxClass15k/clasificationReportTrain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "!cat ../experiments/9/seed0/maxClass15k/clasificationReportValidation.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
