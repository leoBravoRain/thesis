{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove this notebook. It was only for getting confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco, so comment the %matplotlib magic in next block\n",
    "trainingOnGuanaco = True\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = False\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 5\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# add general comment about experiment \n",
    "comment = \"training encoder as classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "only_these_labels = [16, 92, 53]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# training\n",
    "epochs = 2000\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = 5\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticc_torch-master/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 3 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticc_torch-master/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticc_torch-master/plasticc_test_set_batch1.csv\n",
      "Loading /home/leo/Downloads/plasticc_torch-master/plasticc_test_set_batch2.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 25030\n",
      "validation size:  3129\n",
      "test size: 3129\n",
      "sum:  31288\n"
     ]
    }
   ],
   "source": [
    "# Spliting the data\n",
    "\n",
    "# print(torch_dataset_lazy.__len__())\n",
    "\n",
    "# selecting train splitting\n",
    "train_size = int(0.8 * torch_dataset_lazy.__len__())\n",
    "#print(train_size)\n",
    "\n",
    "# getting test splitting\n",
    "validation_size = math.floor((torch_dataset_lazy.__len__() - train_size)/2)\n",
    "#print(validation_size)\n",
    "\n",
    "# getting test splitting\n",
    "test_size = torch_dataset_lazy.__len__() - train_size - validation_size\n",
    "#print(test_size)\n",
    "\n",
    "# spliting the torch dataset\n",
    "trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(torch_dataset_lazy, [train_size, validation_size, test_size])\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "print(\"sum: \", train_size+ validation_size + test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# # train loader\n",
    "trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size= batch_training_size, shuffle=True, num_workers = 4)\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(validationDataset, batch_size= batch_training_size, shuffle=True, num_workers = 4)\n",
    "\n",
    "# # test loader\n",
    "testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "# trainLoader = torch.utils.data.DataLoader(torch_dataset_lazy, batch_size=256, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define autoencoder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementacion adaptada a 1D de https://github.com/naoto0804/pytorch-inpainting-with-partial-conv\n",
    "\n",
    "class PartialConv(nn.Module):\n",
    "    def __init__(self, in_channels_C,in_channels_M, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.input_conv = nn.Conv1d(in_channels_C, out_channels, kernel_size,\n",
    "                                    stride, padding, dilation, groups, bias)\n",
    "        self.mask_conv = nn.Conv1d(in_channels_M, out_channels, kernel_size,\n",
    "                                   stride, padding, dilation, groups, False)\n",
    "        # self.input_conv.apply(weights_init('kaiming'))\n",
    "\n",
    "        torch.nn.init.constant_(self.mask_conv.weight, 1.0)\n",
    "\n",
    "        # mask is not updated\n",
    "        for param in self.mask_conv.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self,input, mask):\n",
    "        # http://masc.cs.gmu.edu/wiki/partialconv\n",
    "        # C(X) = W^T * X + b, C(0) = b, D(M) = 1 * M + 0 = sum(M)\n",
    "        # W^T* (M .* X) / sum(M) + b = [C(M .* X) â€“ C(0)] / D(M) + C(0)\n",
    "        #print(input.shape, mask.shape)\n",
    "        output = self.input_conv(input * mask)\n",
    "        if self.input_conv.bias is not None:\n",
    "            output_bias = self.input_conv.bias.view(1, -1, 1).expand_as(output)\n",
    "        else:\n",
    "            output_bias = torch.zeros_like(output)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_mask = self.mask_conv(mask)\n",
    "\n",
    "        no_update_holes = output_mask == 0\n",
    "        mask_sum = output_mask.masked_fill_(no_update_holes, 1.0)\n",
    "\n",
    "        output_pre = (output - output_bias) / mask_sum + output_bias\n",
    "        output = output_pre.masked_fill_(no_update_holes, 0.0)\n",
    "\n",
    "        new_mask = torch.ones_like(output)\n",
    "        new_mask = new_mask.masked_fill_(no_update_holes, 0.0)\n",
    "\n",
    "        return output, new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building classifier\n",
    "\n",
    "# encoder\n",
    "class Encoder(torch.nn.Module):\n",
    "    \n",
    "\n",
    "    # init method\n",
    "    def __init__(self, latent_dim, hidden_dim, input_dim, num_classes):\n",
    "    \n",
    "    \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # 1 Convolution layer\n",
    "        # Conv1d(input channel, output channel, kernel size)\n",
    "#         self.conv1 = torch.nn.Conv1d(1,64,3)\n",
    "#         self.conv1 = torch.nn.Conv1d(1,64,3, stride = 2)\n",
    "        \n",
    "        # partial convolution\n",
    "        self.pconv1 = PartialConv(in_channels_C = 1,in_channels_M = 1, out_channels = 64, kernel_size = 3, stride=2, padding=0, dilation=1, bias=True)\n",
    "        \n",
    "        # 2 Convolution layer\n",
    "        # Conv1d(input channel, output channel, kernel size)\n",
    "#         self.conv2 = torch.nn.Conv1d(64, 32, 3)\n",
    "#         self.conv2 = torch.nn.Conv1d(64, 32, 3, stride = 2)\n",
    "        \n",
    "        # partial convolution\n",
    "        self.pconv2 = PartialConv(in_channels_C = 64,in_channels_M = 64, out_channels = 32, kernel_size = 3, stride=2, padding=0, dilation=1, bias=True)\n",
    "        \n",
    "        \n",
    "        # linear layer\n",
    "#         self.hidden1 = torch.nn.Linear(2144*2, hidden_dim)\n",
    "#         self.hidden1 = torch.nn.Linear(1088, hidden_dim)\n",
    "        self.hidden1 = torch.nn.Linear(1632, hidden_dim)\n",
    "        \n",
    "#         self.hidden2 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # output layer\n",
    "        self.outputLayer = torch.nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "        # activation function\n",
    "        self.activationConv = torch.nn.ReLU() #max(0, x)\n",
    "#         self.activationConv = torch.nn.Tanh()\n",
    "    \n",
    "        # this works well.(comparing with relu)\n",
    "        self.activationLinear = torch.nn.Tanh()\n",
    "\n",
    "        # this is getting nan values\n",
    "#         self.activationLinear = torch.nn.ReLU()\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # input shape: [batch_size, channels, sequence_length]\n",
    "        # print(\"input shape: {0}\".format(x.shape))\n",
    "#         print(\"input to encoder: \")\n",
    "#         print(x.shape)\n",
    "        \n",
    "        # convolution 1\n",
    "        # x -> conv -> act -> ouput\n",
    "        # shape should be: [batch_size, number of ouput channels (64), length of output from convolution]\n",
    "        \n",
    "        #conv to time\n",
    "        # normal convolution\n",
    "#         outputTimeConv = self.activationConv(self.conv1Time(x[:, 0, :].unsqueeze(1)))\n",
    "#         outputTimeConv = self.activationConv(self.conv1(x[:, 0, :].unsqueeze(1)))\n",
    "        # partial conv\n",
    "        # output, newMask = pconv1(data, mask)\n",
    "        outputTimeConv, maskTime = self.pconv1(x[:, 0, :].unsqueeze(1), x[:, 3, :].unsqueeze(1))\n",
    "        # activation function\n",
    "        outputTimeConv = self.activationConv(outputTimeConv)\n",
    "        \n",
    "        \n",
    "        # conv to magnitude\n",
    "#         outputMagConv = self.activationConv(self.conv1Mag(x[:, 1, :].unsqueeze(1)))\n",
    "#         outputMagConv = self.activationConv(self.conv1(x[:, 1, :].unsqueeze(1)))\n",
    "        \n",
    "        # partial conv\n",
    "        # output, newMask = pconv1(data, mask)\n",
    "        outputMagConv, maskMag = self.pconv1(x[:, 1, :].unsqueeze(1), x[:, 3, :].unsqueeze(1))\n",
    "        # activation function\n",
    "        outputMagConv = self.activationConv(outputMagConv)\n",
    "        \n",
    "        \n",
    "        # conv to mag error\n",
    "#         outputMagErrorConv = self.activationConv(self.conv1(x[:, 2, :].unsqueeze(1)))\n",
    "        \n",
    "        # partial conv\n",
    "        # output, newMask = pconv1(data, mask)\n",
    "        outputMagErrorConv, maskError = self.pconv1(x[:, 2, :].unsqueeze(1), x[:, 3, :].unsqueeze(1))\n",
    "        # activation function\n",
    "        outputMagErrorConv = self.activationConv(outputMagErrorConv)\n",
    "        \n",
    "#         print(\"output conv1 shape: {0}\".format(outputMagConv.shape))\n",
    "#         print(\"output conv1 shape: {0}\".format(outputTimeConv.shape))\n",
    "        \n",
    "        # convolution 2\n",
    "#         # shape should be: [batch_size, number of ouput channels (32), length of output from convolution]\n",
    "        \n",
    "        \n",
    "        # conv to time\n",
    "#         outputTimeConv = self.activationConv(self.conv2(outputTimeConv))\n",
    "        \n",
    "        # partial conv\n",
    "        outputTimeConv, maskTime = self.pconv2(outputTimeConv, maskTime)\n",
    "        outputTimeConv = self.activationConv(outputTimeConv)\n",
    "        \n",
    "        \n",
    "        # conv to flux\n",
    "#         outputMagConv = self.activationConv(self.conv2(outputMagConv))\n",
    "        # part conv\n",
    "        outputMagConv, maskMag = self.pconv2(outputMagConv, maskMag)\n",
    "        outputMagConv = self.activationConv(outputMagConv)\n",
    "        \n",
    "        # conv to mag error\n",
    "#         outputMagErrorConv = self.activationConv(self.conv2(outputMagErrorConv))\n",
    "        # partial conv\n",
    "        outputMagErrorConv, maskError = self.pconv2(outputMagErrorConv, maskError)\n",
    "        outputMagErrorConv = self.activationConv(outputMagErrorConv)\n",
    "        \n",
    "#         print(\"output conv2 shape: {0}\".format(outputTimeConv.shape))\n",
    "#         print(\"output conv2 shape: {0}\".format(outputMagConv.shape))\n",
    "        \n",
    "        # flatten ouput\n",
    "        # shape should be: [batch_size, -1]\n",
    "        outputMagConv = outputMagConv.view(outputMagConv.shape[0], -1)\n",
    "        \n",
    "        outputTimeConv = outputTimeConv.view(outputTimeConv.shape[0], -1)\n",
    "        \n",
    "        outputMagErrorConv = outputMagErrorConv.view(outputMagErrorConv.shape[0], -1)\n",
    "        \n",
    "#         print(\"output reshape: \", outputMagConv.shape)\n",
    "#         print(\"output reshape: \", outputTimeConv.shape)\n",
    "                \n",
    "        # concatenate 3 towers\n",
    "#         output = torch.cat((outputMagConv, outputTimeConv), 1)\n",
    "        output = torch.cat((outputTimeConv, outputMagConv, outputMagErrorConv), 1)\n",
    "#         print(\"concatenate output shape: \", output.shape)\n",
    "        \n",
    "        # x -> hidden1 -> activation\n",
    "#         print(\"before linear layer: {0}\".format(output.shape))\n",
    "        output = self.activationLinear(self.hidden1(output))\n",
    "        # Should be an activiation function here?\n",
    "#         output = (self.hidden1(output))\n",
    "        \n",
    "        output = self.outputLayer(output)\n",
    "        \n",
    "        # this should return the classification\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (pconv1): PartialConv(\n",
       "    (input_conv): Conv1d(1, 64, kernel_size=(3,), stride=(2,))\n",
       "    (mask_conv): Conv1d(1, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
       "  )\n",
       "  (pconv2): PartialConv(\n",
       "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
       "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
       "  )\n",
       "  (hidden1): Linear(in_features=1632, out_features=100, bias=True)\n",
       "  (outputLayer): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (activationConv): ReLU()\n",
       "  (activationLinear): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "\n",
    "# defining model\n",
    "model = Encoder(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes)\n",
    "\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(1, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(1, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=1632, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=3, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it builds a mask for the deltas. It compares the next with the previous one element.\n",
    "# original mask: [1,1, 0, 0]\n",
    "# delta mask: [1, 0, 0]\n",
    "# The same results is got with original_mask[:, 1:]\n",
    "def generate_delta_mask(mask):\n",
    "    \n",
    "    # generate delta mask\n",
    "#     mask_delta = mask[:, 1:].type(torch.BoolTensor) & mask[:, :-1].type(torch.BoolTensor)\n",
    "    mask_delta = mask[:, 1:]\n",
    "    \n",
    "    return mask_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate delta time and flux\n",
    "# data = [batchSize, channels, [time, flux, err, mask], light curve]\n",
    "def generateDeltas(data, passBand):\n",
    "    \n",
    "    # work with delta time and magnitude\n",
    "    \n",
    "#     print(\"generate deltas input shape: {0}\".format(data.shape) )\n",
    "    # delta time\n",
    "    tmpDeltaTime = data[:, passBand, 0, 1:] - data[:, passBand, 0, :-1]\n",
    "\n",
    "#     print(\"generate deltas time shape: {0}\".format(tmpDeltaTime.shape) )\n",
    "\n",
    "#     # delta magnitude\n",
    "    tmpDeltaMagnitude = data[:, passBand, 1, 1:] - data[:, passBand, 1, :-1]\n",
    "#     print(\"generate deltas flux shape: {0}\".format(tmpDeltaMagnitude.shape))\n",
    "    \n",
    "    # delta errors\n",
    "    tmpDeltaMagError = data[:, passBand, 2, 1:] - data[:, passBand, 2, :-1]\n",
    "    \n",
    "    # delta mask\n",
    "    tmpMask = generate_delta_mask(data[:, passBand, 3,:])\n",
    "    \n",
    "    # concatenate tensors\n",
    "    dataToUse = torch.cat((tmpDeltaTime.unsqueeze(1), tmpDeltaMagnitude.unsqueeze(1), tmpDeltaMagError.unsqueeze(1), tmpMask.unsqueeze(1)), 1)\n",
    "#     print(\"data to use shape: {0}\".format(dataToUse.shape))\n",
    "    \n",
    "    # normalize data\n",
    "    # this was commented because it considerate that delta is already a normalization\n",
    "#     dataToUse = normalizeLightCurve(dataToUse)\n",
    "    \n",
    "    # returning data\n",
    "    return dataToUse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping the labels to classes 0 to C-1\n",
    "\n",
    "def mapLabels(labels):\n",
    "\n",
    "    for i in range(len(only_these_labels)):\n",
    "        \n",
    "        labels[labels == only_these_labels[i]] = i \n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(pathToSaveModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get y true and labels\n",
    "\n",
    "predictions = np.zeros(shape = (0,))\n",
    "labels_ = np.zeros(shape = (0,))\n",
    "\n",
    "# minibatches\n",
    "for data_ in validationLoader:\n",
    "        \n",
    "    data = data_[0].cuda()\n",
    "    labels = data_[1].cuda()\n",
    "\n",
    "    data = generateDeltas(data, passband).type(torch.FloatTensor).cuda()\n",
    "\n",
    "    outputs = model.forward(data)\n",
    "    \n",
    "    prediction = torch.argmax(outputs, 1).cpu().numpy()\n",
    "\n",
    "    label = mapLabels(labels).cpu().numpy()\n",
    "    \n",
    "    predictions = np.append(predictions, prediction)\n",
    "    labels_ = np.append(labels_, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving confusion matrix scores\n",
      "saving clasification report\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(labels_, predictions)\n",
    "\n",
    "print(\"saving confusion matrix scores\")\n",
    "np.savetxt(\"experiments/\" + number_experiment + \"/confusionMatrix.csv\", cm, delimiter=\",\")\n",
    "\n",
    "\n",
    "# np.savetxt(\"experiments/\" + number_experiment + \"/clasificationReport.txt\", classification_report(labels_, predictions))\n",
    "\n",
    "# classification_report(labels_, predictions)\n",
    "\n",
    "print(\"saving clasification report\")\n",
    "text_file = open(\"experiments/\" + number_experiment + \"/clasificationReport.txt\", \"w\")\n",
    "text = classification_report(labels_, predictions)\n",
    "text_file.write(text)\n",
    "text_file.close()\n",
    "# print(\"experiment parameters file created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
