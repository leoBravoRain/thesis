{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE A COPY BEFORE PULLING RESULTS FROM GUANACO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "trainingOnGuanaco = False\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 2\n",
    "number_experiment = str(number_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "# only_these_labels = [16, 92, 53]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "only_these_labels = [16, 53]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 200\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "# training\n",
    "epochs = 1000\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = 5\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "\n",
    "# pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticc_torch/\"\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticc_torch-master/\"\n",
    "# path to file in guanaco\n",
    "# pathToFile = \"/home/shared/astro/PLAsTiCC/\"\n",
    "\n",
    "# path to file in local \n",
    "# pathToFile = \"/home/leo/Downloads/plasticc_torch/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 3 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticc_torch-master/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticc_torch-master/plasticc_test_set_batch1.csv\n",
      "Loading /home/leo/Downloads/plasticc_torch-master/plasticc_test_set_batch2.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting one light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc_data, lc_label, lc_plasticc_id = torch_dataset_lazy.__getitem__(123)\n",
    "# display(lc_plasticc_id, lc_label)\n",
    "# 6 bands: u g r i z Y\n",
    "# 4 sequences: mjd, flux, error, mask\n",
    "# 72 samples\n",
    "# display(lc_data.shape, lc_data.dtype)\n",
    "# print(lc_data.detach().numpy()[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_light_curve(torch_dataset_lazy, index_in_dataset=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 8691\n",
      "validation size:  1086\n",
      "test size: 1087\n",
      "sum:  10864\n"
     ]
    }
   ],
   "source": [
    "# Spliting the data\n",
    "\n",
    "# print(torch_dataset_lazy.__len__())\n",
    "\n",
    "# selecting train splitting\n",
    "train_size = int(0.8 * torch_dataset_lazy.__len__())\n",
    "#print(train_size)\n",
    "\n",
    "# getting test splitting\n",
    "validation_size = math.floor((torch_dataset_lazy.__len__() - train_size)/2)\n",
    "#print(validation_size)\n",
    "\n",
    "# getting test splitting\n",
    "test_size = torch_dataset_lazy.__len__() - train_size - validation_size\n",
    "#print(test_size)\n",
    "\n",
    "# spliting the torch dataset\n",
    "trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(torch_dataset_lazy, [train_size, validation_size, test_size])\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "print(\"sum: \", train_size+ validation_size + test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# # train loader\n",
    "trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size= batch_training_size, shuffle=True, num_workers = 4)\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(validationDataset, batch_size= batch_training_size, shuffle=True, num_workers = 4)\n",
    "\n",
    "# # test loader\n",
    "testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "# trainLoader = torch.utils.data.DataLoader(torch_dataset_lazy, batch_size=256, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "folder_path = (\"/home/lbravo/thesis/work/thesis/experiments/\" + number_experiment) if trainingOnGuanaco else (\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.mkdir(folder_path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = \"/home/lbravo/thesis/work/thesis/experiments/\" + number_experiment + \"/model\" if trainingOnGuanaco else \"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check data loader shape\n",
    "# text_file = open(\"experiments/\" + number_experiment + \"/datasetDescription.txt\", \"w\")\n",
    "\n",
    "# # training\n",
    "# text_file.write(\"#### TRAINING ####\")\n",
    "# text_file.write(\"\\nminibatches trainig: \"+ str(len(list(trainLoader))))\n",
    "# text_file.write(\"\\nminibatch trainig size: \" + str(list(trainLoader)[0][0].shape))\n",
    "\n",
    "\n",
    "# # testing\n",
    "# text_file.write(\"\\n#### TESTING ####\")\n",
    "# text_file.write(\"\\nminibatches test: \"+ str(len(list(testLoader))))\n",
    "# text_file.write(\"\\nminibatch trainig size: \" + str(list(testLoader)[0][0].shape))\n",
    "\n",
    "# text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define autoencoder structure\n",
    "To start with the work, It is going to build a very basic Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buiding autoencoder\n",
    "\n",
    "# Assuming this has a normal distrubtion in the latent part\n",
    "\n",
    "# encoder\n",
    "class Encoder(torch.nn.Module):\n",
    "    \n",
    "    # init method\n",
    "    def __init__(self, latent_dim, hidden_dim, input_dim):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # 1 Convolution layer\n",
    "        # Conv1d(input channel, output channel, kernel size)\n",
    "        self.conv1 = torch.nn.Conv1d(1,64,3)\n",
    "        \n",
    "        # this is to consider time and magnitude\n",
    "        # we should use shared weights?\n",
    "#         self.conv1Time = torch.nn.Conv1d(1, 64, 3)\n",
    "#         self.conv1Mag = torch.nn.Conv1d(1, 64, 3)\n",
    "        \n",
    "        # 2 Convolution layer\n",
    "        # Conv1d(input channel, output channel, kernel size)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 32, 3)\n",
    "        \n",
    "        # time and magnitude conv\n",
    "#         self.conv2Time = torch.nn.Conv1d(64, 32, 3)\n",
    "#         self.conv2Mag = torch.nn.Conv1d(64, 32, 3)\n",
    "        \n",
    "        # linear layer\n",
    "        self.hidden1 = torch.nn.Linear(2144*2, hidden_dim)\n",
    "        \n",
    "#         self.hidden2 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # mu\n",
    "        self.mu = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # sigma\n",
    "        self.logVar = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # activation function\n",
    "#         self.activationConv = torch.nn.ReLU() #max(0, x)\n",
    "        self.activationConv = torch.nn.Tanh() #max(0, x)\n",
    "    \n",
    "#         self.activationLinear = torch.nn.Tanh()\n",
    "        self.activationLinear = torch.nn.ReLU()\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # input shape: [batch_size, channels, sequence_length]\n",
    "        # print(\"input shape: {0}\".format(x.shape))\n",
    "        \n",
    "        \n",
    "        # convolution 1\n",
    "        # x -> conv -> act -> ouput\n",
    "        # shape should be: [batch_size, number of ouput channels (64), length of output from convolution]\n",
    "        \n",
    "        #conv to time\n",
    "#         outputTimeConv = self.activationConv(self.conv1Time(x[:, 0, :].unsqueeze(1)))\n",
    "        outputTimeConv = self.activationConv(self.conv1(x[:, 0, :].unsqueeze(1)))\n",
    "    \n",
    "        # conv to magnitude\n",
    "#         outputMagConv = self.activationConv(self.conv1Mag(x[:, 1, :].unsqueeze(1)))\n",
    "        outputMagConv = self.activationConv(self.conv1(x[:, 1, :].unsqueeze(1)))\n",
    "        \n",
    "#         print(\"output conv1 shape: {0}\".format(outputMagConv.shape))\n",
    "#         print(\"output conv1 shape: {0}\".format(outputTimeConv.shape))\n",
    "        \n",
    "        # convolution 2\n",
    "#         # shape should be: [batch_size, number of ouput channels (32), length of output from convolution]\n",
    "        \n",
    "        # conv to time\n",
    "        outputTimeConv = self.activationConv(self.conv2(outputTimeConv))\n",
    "    \n",
    "        # conv to flux\n",
    "        outputMagConv = self.activationConv(self.conv2(outputMagConv))\n",
    "        \n",
    "#         print(\"output conv2 shape: {0}\".format(outputTimeConv.shape))\n",
    "#         print(\"output conv2 shape: {0}\".format(outputMagConv.shape))\n",
    "        \n",
    "        # flatten ouput\n",
    "        # shape should be: [batch_size, -1]\n",
    "        outputMagConv = outputMagConv.view(outputMagConv.shape[0], -1)\n",
    "        outputTimeConv = outputTimeConv.view(outputTimeConv.shape[0], -1)\n",
    "        \n",
    "#         print(\"output reshape: \", outputMagConv.shape)\n",
    "#         print(\"output reshape: \", outputTimeConv.shape)\n",
    "                \n",
    "        # concatenate 2 towers\n",
    "        output = torch.cat((outputMagConv, outputTimeConv), 1)\n",
    "#         print(\"concatenate output shape: \", output.shape)\n",
    "        \n",
    "        # x -> hidden1 -> activation\n",
    "        output = self.activationLinear(self.hidden1(output))\n",
    "        \n",
    "#         second hidden layer\n",
    "#         output = self.activationLinear(self.hidden2(output))\n",
    "#         output = self.activationLinear(self.hidden2(output))\n",
    "    \n",
    "#         output = self.hidden1(output)\n",
    "#         print(\"hidden1 output shape: {0}\".format(output.shape))\n",
    "        \n",
    "        # get mu\n",
    "        # sin tangenteh!!!\n",
    "        mu = self.mu(output)\n",
    "#         print(\"mu shape: {0}\".format(mu.shape))\n",
    "        \n",
    "        # get sigma\n",
    "        logVar = self.logVar(output)\n",
    "#         print(\"sigma shape: {0}\".format(logVar.shape))\n",
    "        \n",
    "        # returning values\n",
    "        return mu, logVar\n",
    "\n",
    "    \n",
    "# decoder    \n",
    "class Decoder(torch.nn.Module):\n",
    "    \n",
    "    # define layers\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # linear layer\n",
    "        self.hidden1 = torch.nn.Linear(latent_dim, 2144*2)\n",
    "        \n",
    "        # 1 ConvolutionTrans layer\n",
    "        self.convTrans1 = torch.nn.ConvTranspose1d(32, 64, 3)\n",
    "        \n",
    "        # 2 ConvolutionTrans layer\n",
    "        self.convTrans2 = torch.nn.ConvTranspose1d(64, 1, 3)\n",
    "\n",
    "        # activation function\n",
    "        self.activationConv = torch.nn.ReLU() #max(0, x)\n",
    "#         self.activationConv = torch.nn.Tanh() #max(0, x)\n",
    "    \n",
    "        self.activationLinear = torch.nn.Tanh()\n",
    "#         self.activationLinear = torch.nn.ReLU()\n",
    "        \n",
    "    # forward method\n",
    "    def forward(self, z):\n",
    "        \n",
    "#         print(\"input dimension decoder: {0}\".format(z.shape))\n",
    "        \n",
    "        # linear (from latent to hidden dimension)\n",
    "        # z -> linaer layer -> activation -> output\n",
    "        output = self.activationLinear(self.hidden1(z))\n",
    "#         print(\"output hidden1: {0}\".format(output.shape))\n",
    "        \n",
    "        # split data (into time and flux)\n",
    "        outputTimeDeconv, outputMagDeconv = torch.split(output, 2144, dim=2)\n",
    "            \n",
    "        # reshape each tower (time and magnitude)\n",
    "        outputTimeDeconv = outputTimeDeconv.view(outputTimeDeconv.shape[0], 32, -1)\n",
    "        outputMagDeconv = outputMagDeconv.view(outputMagDeconv.shape[0], 32, -1)\n",
    "        \n",
    "#         print(\"output reshape: {0}\".format(outputTimeDeconv.shape))\n",
    "#         print(\"output reshape: {0}\".format(outputMagDeconv.shape))\n",
    "        \n",
    "        # 1 convolution\n",
    "        outputTimeDeconv = self.activationConv(self.convTrans1(outputTimeDeconv))\n",
    "        outputMagDeconv = self.activationConv(self.convTrans1(outputMagDeconv))\n",
    "#         print(\"ouput convTrans1: {0}\".format(outputTimeDeconv.shape))\n",
    "#         print(\"ouput convTrans1: {0}\".format(outputMagDeconv.shape))\n",
    "        \n",
    "        # 2 convolution\n",
    "        outputTimeDeconv = self.convTrans2(outputTimeDeconv)\n",
    "        outputMagDeconv = self.convTrans2(outputMagDeconv)\n",
    "        \n",
    "#         print(\"ouput convTrans2: {0}\".format(outputTimeDeconv.shape))\n",
    "#         print(\"ouput convTrans2: {0}\".format(outputMagDeconv.shape))\n",
    "        \n",
    "        # concatenate arrays in order to get the data with 2 channels\n",
    "        output = torch.cat((outputTimeDeconv, outputMagDeconv), 1)\n",
    "#         print(\"concatenate in channels: {0}\".format(output.shape))\n",
    "\n",
    "        # output\n",
    "        return output\n",
    "\n",
    "# building the autoencoder     \n",
    "class AutoEncoder(torch.nn.Module):\n",
    "    \n",
    "    # defining the initial structure\n",
    "    def __init__(self, latent_dim, hidden_dim, input_dim):\n",
    "        \n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # defining the encoder\n",
    "        self.encoder = Encoder(latent_dim, hidden_dim, input_dim)\n",
    "        \n",
    "        # defining the decoder\n",
    "        # note the output dimension in the decoder is the same as input dimension\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "\n",
    "    # distribution function\n",
    "    def sampling(self, mu, logvar, k = 1):\n",
    "        \n",
    "        # assumming normal distribution\n",
    "#         s = torch.exp(0.5*sigma)\n",
    "#         eps = torch.rand_like(s) # generate a iid standard normal same shape as s\n",
    "#         return eps.mul(s).add_(mu)\n",
    "        batch_size, n_latent = logvar.shape\n",
    "        std = (0.5*logvar).exp()\n",
    "#         eps = torch.randn(batch_size, k, n_latent, device=std.device, requires_grad=False)\n",
    "        eps = torch.randn(batch_size, k, n_latent, requires_grad=False)\n",
    "        if \"cuda\" in str(mu.device):\n",
    "            eps = eps.cuda()\n",
    "        return eps.mul(std.unsqueeze(1)).add(mu.unsqueeze(1))\n",
    "    \n",
    "    def get_latent_variables(self, x):\n",
    "        \n",
    "        # get mu and logvar\n",
    "        mu, logVar = self.encoder(x)\n",
    "        \n",
    "        # sampling to get the latent variables\n",
    "        z = self.sampling(mu, logVar)\n",
    "        \n",
    "        # return values\n",
    "        return z\n",
    "    \n",
    "    # forward method (how to the nn works)\n",
    "    def forward(self, x):\n",
    "        \n",
    "#         print(\"input size: {0}\".format(x.shape))\n",
    "        \n",
    "#         print(\"## Encoder ##\")\n",
    "        # input (x) -> encoder -> latent variables\n",
    "        mu, logVar = self.encoder(x)\n",
    "#         print(\"output encoder size: {0}\".format(mu.shape))\n",
    "        \n",
    "#         print(\"mu \", mu.device)\n",
    "#         print(\"var \", logVar.device)\n",
    "        # getting sample\n",
    "        # mu, sigma -> distribution -> z\n",
    "        z = self.sampling(mu, logVar)\n",
    "#         print(\"z shape: \", z.shape)\n",
    "        \n",
    "#         print(\"## Dencoder ##\")\n",
    "        # latent variables -> decoder -> reconstruction (x)\n",
    "        decOutput = self.decoder(z)\n",
    "#         print(\"output decoder size: {0}\".format(decOutput.shape))\n",
    "        \n",
    "        # agregar mu, logvar, decOutput\n",
    "        return decOutput, mu, logVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "passband = passband\n",
    "\n",
    "# defining model\n",
    "model = AutoEncoder(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test the model data flow\n",
    "# model.forward(list(trainLoader)[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(\"input dimension: {0}\".format(len(list(trainLoader))))\n",
    "\n",
    "# # parameters number\n",
    "# count = 0\n",
    "\n",
    "# # # check model dimension\n",
    "# for name, param in model.state_dict().items():\n",
    "#     # name: str\n",
    "#     # param: Tensor\n",
    "# #     print(\"{0}: {1} \\n\".format(name, param.shape))\n",
    "# #     print(param.shape[0]*(param.shape[1] if len(param.shape)>1 else 1))\n",
    "# #     print(param.shape)\n",
    "#     count += param.shape[0]*(param.shape[1] if len(param.shape)>1 else 1)\n",
    "# # for param in model.parameters():\n",
    "    \n",
    "# print(\"number of parameters: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_delta_mask(mask):\n",
    "    \n",
    "#     print(\"mask; \", mask.shape)\n",
    "    \n",
    "#     print(\"mask 1: : \", mask[1:].type(torch.BoolTensor))\n",
    "    \n",
    "#     print(\"mask :-1 : \", mask[:-1].type(torch.BoolTensor))\n",
    "    \n",
    "    \n",
    "    mask_delta = mask[:, 1:].type(torch.BoolTensor) & mask[:, :-1].type(torch.BoolTensor)\n",
    "\n",
    "#     print(\"mask delta: \", mask_delta.shape)\n",
    "    \n",
    "    return mask_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar, mask):\n",
    "    \n",
    "#     print(\"reconstruction: {0}\".format(recon_x))\n",
    "#     print(\"x: {0}\".format(x))\n",
    "#     print(\"mu: {0}\".format(mu))\n",
    "#     print(\"logvar: {0}\".format(logvar))\n",
    "    \n",
    "#     print(recon_x.shape)\n",
    "#     print(x.shape)\n",
    "    \n",
    "#     print(\"before mask: \", mask)\n",
    "    mask = generate_delta_mask(mask).cuda()\n",
    "#     print(\"after mask: \", mask)\n",
    "#     print(\"loss shape: \", F.mse_loss(recon_x, x, reduction='none').shape)\n",
    "#     BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "\n",
    "    # this one is the normal (considering all datapoints)\n",
    "#     BCE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    # BCE  = [128, 2, 71]\n",
    "    \n",
    "    # this is considering mask\n",
    "    BCE = F.mse_loss(recon_x, x, reduction='none')\n",
    "#     print(F.mse_loss(recon_x, x, reduction='none').shape)\n",
    "    BCE[:, 0, :] = BCE[:, 0, :] * mask\n",
    "    BCE[:, 1, :] = BCE[:, 1, :] * mask\n",
    "#     print(BCE.shape)\n",
    "    # reducttion \n",
    "    BCE = torch.sum(BCE) / (BCE.shape[0]*BCE.shape[1]*BCE.shape[2])\n",
    "\n",
    "#     print(\"BCE: \", BCE)\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "#     KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    KLD = 0\n",
    "#     print(\"KLD: \", KLD)\n",
    "#     print(BCE)\n",
    "    \n",
    "    return BCE + KLD\n",
    "#     return BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize light curve\n",
    "# data: [batch size, 2 channels (time and magnitude), light curve length]\n",
    "def normalizeLightCurve(data):\n",
    "    \n",
    "#     print(\"data shape before normalization: \", data.shape)\n",
    "    \n",
    "    # get flux mean\n",
    "    means = data[:, 1, :].mean(dim=1)\n",
    "#     print(\"mean shape: \", means.shape)\n",
    "    \n",
    "    # get flux standar deviation \n",
    "    stds = data[:, 1, :].std(dim=1)\n",
    "#     print(\"stds shape: \", stds.shape)\n",
    "    \n",
    "    # overwrite flux\n",
    "    data[:, 1, :] = (data[:, 1, :] - means.unsqueeze(1).expand_as(data[:, 1, :])) / stds.unsqueeze(1).expand_as(data[:, 1, :])\n",
    "#     print(\"normalized data shape: \", data.shape)\n",
    "    \n",
    "    # return normalized data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate delta time and flux\n",
    "# data = [batchSize, channels, [time, flux, err, mask], light curve]\n",
    "def generateDeltas(data, passBand):\n",
    "    \n",
    "    # work with delta time and magnitude\n",
    "    \n",
    "#     print(\"generate deltas input shape: {0}\".format(data.shape) )\n",
    "    # delta time\n",
    "    tmpDeltaTime = data[:, passBand, 0, 1:] - data[:, passBand, 0, :-1]\n",
    "\n",
    "#     print(\"generate deltas time shape: {0}\".format(tmpDeltaTime.shape) )\n",
    "\n",
    "#     # delta magnitude\n",
    "    tmpDeltaMagnitude = data[:, passBand, 1, 1:] - data[:, passBand, 1, :-1]\n",
    "#     print(\"generate deltas flux shape: {0}\".format(tmpDeltaMagnitude.shape))\n",
    "    \n",
    "    # concatenate tensors\n",
    "    dataToUse = torch.cat((tmpDeltaTime.unsqueeze(1), tmpDeltaMagnitude.unsqueeze(1)), 1)\n",
    "#     print(\"data to use shape: {0}\".format(dataToUse.shape))\n",
    "    \n",
    "    # normalize data\n",
    "#     dataToUse = normalizeLightCurve(dataToUse)\n",
    "    \n",
    "    # returning data\n",
    "    return dataToUse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"299.14531011788375\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 1000\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    1 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    2 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    3 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    4 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    5 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    6 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    7 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    8 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    9 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    10 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    11 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    12 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    13 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    14 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    15 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    16 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    17 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    18 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    19 / 1000\n",
      "saving losses\n",
      "epoch:    20 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    21 / 1000\n",
      "saving losses\n",
      "epoch:    22 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    23 / 1000\n",
      "saving losses\n",
      "epoch:    24 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    25 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    26 / 1000\n",
      "saving losses\n",
      "epoch:    27 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    28 / 1000\n",
      "saving losses\n",
      "epoch:    29 / 1000\n",
      "saving losses\n",
      "epoch:    30 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    31 / 1000\n",
      "saving losses\n",
      "epoch:    32 / 1000\n",
      "saving losses\n",
      "epoch:    33 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    34 / 1000\n",
      "saving losses\n",
      "epoch:    35 / 1000\n",
      "saving losses\n",
      "epoch:    36 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    37 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    38 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    39 / 1000\n",
      "early stopping counter:  8\n",
      "saving losses\n",
      "epoch:    40 / 1000\n",
      "saving losses\n",
      "epoch:    41 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    42 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    43 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    44 / 1000\n",
      "saving losses\n",
      "epoch:    45 / 1000\n",
      "saving losses\n",
      "epoch:    46 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    47 / 1000\n",
      "saving losses\n",
      "epoch:    48 / 1000\n",
      "saving losses\n",
      "epoch:    49 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    50 / 1000\n",
      "saving losses\n",
      "epoch:    51 / 1000\n",
      "saving losses\n",
      "epoch:    52 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    53 / 1000\n",
      "saving losses\n",
      "epoch:    54 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    55 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    56 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    57 / 1000\n",
      "saving losses\n",
      "epoch:    58 / 1000\n",
      "saving losses\n",
      "epoch:    59 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    60 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    61 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    62 / 1000\n",
      "early stopping counter:  8\n",
      "saving losses\n",
      "epoch:    63 / 1000\n",
      "saving losses\n",
      "epoch:    64 / 1000\n",
      "saving losses\n",
      "epoch:    65 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    66 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    67 / 1000\n",
      "saving losses\n",
      "epoch:    68 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    69 / 1000\n",
      "saving losses\n",
      "epoch:    70 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    71 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    72 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    73 / 1000\n",
      "early stopping counter:  8\n",
      "saving losses\n",
      "epoch:    74 / 1000\n",
      "saving losses\n",
      "epoch:    75 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    76 / 1000\n",
      "saving losses\n",
      "epoch:    77 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    78 / 1000\n",
      "saving losses\n",
      "epoch:    79 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    80 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    81 / 1000\n",
      "saving losses\n",
      "epoch:    82 / 1000\n",
      "saving losses\n",
      "epoch:    83 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    84 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    85 / 1000\n",
      "saving losses\n",
      "epoch:    86 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    87 / 1000\n",
      "saving losses\n",
      "epoch:    88 / 1000\n",
      "saving losses\n",
      "epoch:    89 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    90 / 1000\n",
      "saving losses\n",
      "epoch:    91 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    92 / 1000\n",
      "saving losses\n",
      "epoch:    93 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    94 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    95 / 1000\n",
      "saving losses\n",
      "epoch:    96 / 1000\n",
      "saving losses\n",
      "epoch:    97 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    98 / 1000\n",
      "saving losses\n",
      "epoch:    99 / 1000\n",
      "saving losses\n",
      "epoch:    100 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    101 / 1000\n",
      "saving losses\n",
      "epoch:    102 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    103 / 1000\n",
      "saving losses\n",
      "epoch:    104 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    105 / 1000\n",
      "saving losses\n",
      "epoch:    106 / 1000\n",
      "saving losses\n",
      "epoch:    107 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    108 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    109 / 1000\n",
      "saving losses\n",
      "epoch:    110 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    111 / 1000\n",
      "saving losses\n",
      "epoch:    112 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    113 / 1000\n",
      "saving losses\n",
      "epoch:    114 / 1000\n",
      "saving losses\n",
      "epoch:    115 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    116 / 1000\n",
      "saving losses\n",
      "epoch:    117 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    118 / 1000\n",
      "saving losses\n",
      "epoch:    119 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    120 / 1000\n",
      "saving losses\n",
      "epoch:    121 / 1000\n",
      "saving losses\n",
      "epoch:    122 / 1000\n",
      "saving losses\n",
      "epoch:    123 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    124 / 1000\n",
      "saving losses\n",
      "epoch:    125 / 1000\n",
      "saving losses\n",
      "epoch:    126 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    127 / 1000\n",
      "saving losses\n",
      "epoch:    128 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    129 / 1000\n",
      "saving losses\n",
      "epoch:    130 / 1000\n",
      "saving losses\n",
      "epoch:    131 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    132 / 1000\n",
      "saving losses\n",
      "epoch:    133 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    134 / 1000\n",
      "saving losses\n",
      "epoch:    135 / 1000\n",
      "saving losses\n",
      "epoch:    136 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    137 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    138 / 1000\n",
      "saving losses\n",
      "epoch:    139 / 1000\n",
      "saving losses\n",
      "epoch:    140 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    141 / 1000\n",
      "saving losses\n",
      "epoch:    142 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    143 / 1000\n",
      "saving losses\n",
      "epoch:    144 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    145 / 1000\n",
      "saving losses\n",
      "epoch:    146 / 1000\n",
      "saving losses\n",
      "epoch:    147 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    148 / 1000\n",
      "saving losses\n",
      "epoch:    149 / 1000\n",
      "saving losses\n",
      "epoch:    150 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    151 / 1000\n",
      "saving losses\n",
      "epoch:    152 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    153 / 1000\n",
      "saving losses\n",
      "epoch:    154 / 1000\n",
      "saving losses\n",
      "epoch:    155 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    156 / 1000\n",
      "saving losses\n",
      "epoch:    157 / 1000\n",
      "saving losses\n",
      "epoch:    158 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    159 / 1000\n",
      "saving losses\n",
      "epoch:    160 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    161 / 1000\n",
      "saving losses\n",
      "epoch:    162 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    163 / 1000\n",
      "saving losses\n",
      "epoch:    164 / 1000\n",
      "saving losses\n",
      "epoch:    165 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving losses\n",
      "epoch:    166 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    167 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    168 / 1000\n",
      "saving losses\n",
      "epoch:    169 / 1000\n",
      "saving losses\n",
      "epoch:    170 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    171 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    172 / 1000\n",
      "saving losses\n",
      "epoch:    173 / 1000\n",
      "saving losses\n",
      "epoch:    174 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    175 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    176 / 1000\n",
      "saving losses\n",
      "epoch:    177 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    178 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    179 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    180 / 1000\n",
      "saving losses\n",
      "epoch:    181 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    182 / 1000\n",
      "saving losses\n",
      "epoch:    183 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    184 / 1000\n",
      "saving losses\n",
      "epoch:    185 / 1000\n",
      "saving losses\n",
      "epoch:    186 / 1000\n",
      "saving losses\n",
      "epoch:    187 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    188 / 1000\n",
      "saving losses\n",
      "epoch:    189 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    190 / 1000\n",
      "saving losses\n",
      "epoch:    191 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    192 / 1000\n",
      "saving losses\n",
      "epoch:    193 / 1000\n",
      "saving losses\n",
      "epoch:    194 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    195 / 1000\n",
      "saving losses\n",
      "epoch:    196 / 1000\n",
      "saving losses\n",
      "epoch:    197 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    198 / 1000\n",
      "saving losses\n",
      "epoch:    199 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    200 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    201 / 1000\n",
      "saving losses\n",
      "epoch:    202 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    203 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    204 / 1000\n",
      "saving losses\n",
      "epoch:    205 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    206 / 1000\n",
      "saving losses\n",
      "epoch:    207 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    208 / 1000\n",
      "saving losses\n",
      "epoch:    209 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    210 / 1000\n",
      "saving losses\n",
      "epoch:    211 / 1000\n",
      "saving losses\n",
      "epoch:    212 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    213 / 1000\n",
      "saving losses\n",
      "epoch:    214 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    215 / 1000\n",
      "saving losses\n",
      "epoch:    216 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    217 / 1000\n",
      "saving losses\n",
      "epoch:    218 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    219 / 1000\n",
      "saving losses\n",
      "epoch:    220 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    221 / 1000\n",
      "saving losses\n",
      "epoch:    222 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    223 / 1000\n",
      "saving losses\n",
      "epoch:    224 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    225 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    226 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    227 / 1000\n",
      "saving losses\n",
      "epoch:    228 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    229 / 1000\n",
      "saving losses\n",
      "epoch:    230 / 1000\n",
      "saving losses\n",
      "epoch:    231 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    232 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    233 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    234 / 1000\n",
      "saving losses\n",
      "epoch:    235 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    236 / 1000\n",
      "saving losses\n",
      "epoch:    237 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    238 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    239 / 1000\n",
      "saving losses\n",
      "epoch:    240 / 1000\n",
      "saving losses\n",
      "epoch:    241 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    242 / 1000\n",
      "saving losses\n",
      "epoch:    243 / 1000\n",
      "saving losses\n",
      "epoch:    244 / 1000\n",
      "saving losses\n",
      "epoch:    245 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    246 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    247 / 1000\n",
      "saving losses\n",
      "epoch:    248 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    249 / 1000\n",
      "saving losses\n",
      "epoch:    250 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    251 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    252 / 1000\n",
      "saving losses\n",
      "epoch:    253 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    254 / 1000\n",
      "saving losses\n",
      "epoch:    255 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    256 / 1000\n",
      "saving losses\n",
      "epoch:    257 / 1000\n",
      "saving losses\n",
      "epoch:    258 / 1000\n",
      "saving losses\n",
      "epoch:    259 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    260 / 1000\n",
      "saving losses\n",
      "epoch:    261 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    262 / 1000\n",
      "saving losses\n",
      "epoch:    263 / 1000\n",
      "saving losses\n",
      "epoch:    264 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    265 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    266 / 1000\n",
      "saving losses\n",
      "epoch:    267 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    268 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    269 / 1000\n",
      "saving losses\n",
      "epoch:    270 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    271 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    272 / 1000\n",
      "saving losses\n",
      "epoch:    273 / 1000\n",
      "saving losses\n",
      "epoch:    274 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    275 / 1000\n",
      "saving losses\n",
      "epoch:    276 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    277 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    278 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    279 / 1000\n",
      "saving losses\n",
      "epoch:    280 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    281 / 1000\n",
      "saving losses\n",
      "epoch:    282 / 1000\n",
      "saving losses\n",
      "epoch:    283 / 1000\n",
      "saving losses\n",
      "epoch:    284 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    285 / 1000\n",
      "saving losses\n",
      "epoch:    286 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    287 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    288 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    289 / 1000\n",
      "saving losses\n",
      "epoch:    290 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    291 / 1000\n",
      "saving losses\n",
      "epoch:    292 / 1000\n",
      "saving losses\n",
      "epoch:    293 / 1000\n",
      "saving losses\n",
      "epoch:    294 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    295 / 1000\n",
      "saving losses\n",
      "epoch:    296 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    297 / 1000\n",
      "saving losses\n",
      "epoch:    298 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    299 / 1000\n",
      "saving losses\n",
      "epoch:    300 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    301 / 1000\n",
      "saving losses\n",
      "epoch:    302 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    303 / 1000\n",
      "saving losses\n",
      "epoch:    304 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    305 / 1000\n",
      "saving losses\n",
      "epoch:    306 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    307 / 1000\n",
      "saving losses\n",
      "epoch:    308 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    309 / 1000\n",
      "saving losses\n",
      "epoch:    310 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    311 / 1000\n",
      "saving losses\n",
      "epoch:    312 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    313 / 1000\n",
      "saving losses\n",
      "epoch:    314 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    315 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    316 / 1000\n",
      "saving losses\n",
      "epoch:    317 / 1000\n",
      "saving losses\n",
      "epoch:    318 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    319 / 1000\n",
      "saving losses\n",
      "epoch:    320 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    321 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    322 / 1000\n",
      "saving losses\n",
      "epoch:    323 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    324 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    325 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    326 / 1000\n",
      "saving losses\n",
      "epoch:    327 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    328 / 1000\n",
      "saving losses\n",
      "epoch:    329 / 1000\n",
      "saving losses\n",
      "epoch:    330 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    331 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    332 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    333 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stopping counter:  8\n",
      "saving losses\n",
      "epoch:    334 / 1000\n",
      "saving losses\n",
      "epoch:    335 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    336 / 1000\n",
      "saving losses\n",
      "epoch:    337 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    338 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    339 / 1000\n",
      "saving losses\n",
      "epoch:    340 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    341 / 1000\n",
      "saving losses\n",
      "epoch:    342 / 1000\n",
      "saving losses\n",
      "epoch:    343 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    344 / 1000\n",
      "saving losses\n",
      "epoch:    345 / 1000\n",
      "saving losses\n",
      "epoch:    346 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    347 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    348 / 1000\n",
      "saving losses\n",
      "epoch:    349 / 1000\n",
      "saving losses\n",
      "epoch:    350 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    351 / 1000\n",
      "saving losses\n",
      "epoch:    352 / 1000\n",
      "saving losses\n",
      "epoch:    353 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    354 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    355 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    356 / 1000\n",
      "early stopping counter:  8\n",
      "saving losses\n",
      "epoch:    357 / 1000\n",
      "saving losses\n",
      "epoch:    358 / 1000\n",
      "saving losses\n",
      "epoch:    359 / 1000\n",
      "saving losses\n",
      "epoch:    360 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    361 / 1000\n",
      "saving losses\n",
      "epoch:    362 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    363 / 1000\n",
      "saving losses\n",
      "epoch:    364 / 1000\n",
      "saving losses\n",
      "epoch:    365 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    366 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    367 / 1000\n",
      "saving losses\n",
      "epoch:    368 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    369 / 1000\n",
      "saving losses\n",
      "epoch:    370 / 1000\n",
      "saving losses\n",
      "epoch:    371 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    372 / 1000\n",
      "saving losses\n",
      "epoch:    373 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    374 / 1000\n",
      "saving losses\n",
      "epoch:    375 / 1000\n",
      "saving losses\n",
      "epoch:    376 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    377 / 1000\n",
      "saving losses\n",
      "epoch:    378 / 1000\n",
      "saving losses\n",
      "epoch:    379 / 1000\n",
      "saving losses\n",
      "epoch:    380 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    381 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    382 / 1000\n",
      "saving losses\n",
      "epoch:    383 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    384 / 1000\n",
      "saving losses\n",
      "epoch:    385 / 1000\n",
      "saving losses\n",
      "epoch:    386 / 1000\n",
      "saving losses\n",
      "epoch:    387 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    388 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    389 / 1000\n",
      "saving losses\n",
      "epoch:    390 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    391 / 1000\n",
      "saving losses\n",
      "epoch:    392 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    393 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    394 / 1000\n",
      "saving losses\n",
      "epoch:    395 / 1000\n",
      "saving losses\n",
      "epoch:    396 / 1000\n",
      "saving losses\n",
      "epoch:    397 / 1000\n",
      "saving losses\n",
      "epoch:    398 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    399 / 1000\n",
      "saving losses\n",
      "epoch:    400 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    401 / 1000\n",
      "saving losses\n",
      "epoch:    402 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    403 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    404 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    405 / 1000\n",
      "saving losses\n",
      "epoch:    406 / 1000\n",
      "saving losses\n",
      "epoch:    407 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    408 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    409 / 1000\n",
      "saving losses\n",
      "epoch:    410 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    411 / 1000\n",
      "saving losses\n",
      "epoch:    412 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    413 / 1000\n",
      "saving losses\n",
      "epoch:    414 / 1000\n",
      "saving losses\n",
      "epoch:    415 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    416 / 1000\n",
      "saving losses\n",
      "epoch:    417 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    418 / 1000\n",
      "saving losses\n",
      "epoch:    419 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    420 / 1000\n",
      "saving losses\n",
      "epoch:    421 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    422 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    423 / 1000\n",
      "saving losses\n",
      "epoch:    424 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    425 / 1000\n",
      "saving losses\n",
      "epoch:    426 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    427 / 1000\n",
      "saving losses\n",
      "epoch:    428 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    429 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    430 / 1000\n",
      "saving losses\n",
      "epoch:    431 / 1000\n",
      "saving losses\n",
      "epoch:    432 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    433 / 1000\n",
      "saving losses\n",
      "epoch:    434 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    435 / 1000\n",
      "saving losses\n",
      "epoch:    436 / 1000\n",
      "saving losses\n",
      "epoch:    437 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    438 / 1000\n",
      "saving losses\n",
      "epoch:    439 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    440 / 1000\n",
      "saving losses\n",
      "epoch:    441 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    442 / 1000\n",
      "saving losses\n",
      "epoch:    443 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    444 / 1000\n",
      "saving losses\n",
      "epoch:    445 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    446 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    447 / 1000\n",
      "saving losses\n",
      "epoch:    448 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    449 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    450 / 1000\n",
      "saving losses\n",
      "epoch:    451 / 1000\n",
      "saving losses\n",
      "epoch:    452 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    453 / 1000\n",
      "saving losses\n",
      "epoch:    454 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    455 / 1000\n",
      "saving losses\n",
      "epoch:    456 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    457 / 1000\n",
      "saving losses\n",
      "epoch:    458 / 1000\n",
      "saving losses\n",
      "epoch:    459 / 1000\n",
      "saving losses\n",
      "epoch:    460 / 1000\n",
      "saving losses\n",
      "epoch:    461 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    462 / 1000\n",
      "saving losses\n",
      "epoch:    463 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    464 / 1000\n",
      "saving losses\n",
      "epoch:    465 / 1000\n",
      "saving losses\n",
      "epoch:    466 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    467 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    468 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    469 / 1000\n",
      "saving losses\n",
      "epoch:    470 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    471 / 1000\n",
      "saving losses\n",
      "epoch:    472 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    473 / 1000\n",
      "saving losses\n",
      "epoch:    474 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    475 / 1000\n",
      "saving losses\n",
      "epoch:    476 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    477 / 1000\n",
      "saving losses\n",
      "epoch:    478 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    479 / 1000\n",
      "saving losses\n",
      "epoch:    480 / 1000\n",
      "saving losses\n",
      "epoch:    481 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    482 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    483 / 1000\n",
      "saving losses\n",
      "epoch:    484 / 1000\n",
      "saving losses\n",
      "epoch:    485 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    486 / 1000\n",
      "saving losses\n",
      "epoch:    487 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    488 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    489 / 1000\n",
      "saving losses\n",
      "epoch:    490 / 1000\n",
      "saving losses\n",
      "epoch:    491 / 1000\n",
      "saving losses\n",
      "epoch:    492 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    493 / 1000\n",
      "saving losses\n",
      "epoch:    494 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    495 / 1000\n",
      "saving losses\n",
      "epoch:    496 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    497 / 1000\n",
      "saving losses\n",
      "epoch:    498 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    499 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    500 / 1000\n",
      "saving losses\n",
      "epoch:    501 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    502 / 1000\n",
      "saving losses\n",
      "epoch:    503 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    504 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    505 / 1000\n",
      "saving losses\n",
      "epoch:    506 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    507 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    508 / 1000\n",
      "saving losses\n",
      "epoch:    509 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    510 / 1000\n",
      "saving losses\n",
      "epoch:    511 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    512 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    513 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    514 / 1000\n",
      "saving losses\n",
      "epoch:    515 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    516 / 1000\n",
      "saving losses\n",
      "epoch:    517 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    518 / 1000\n",
      "saving losses\n",
      "epoch:    519 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    520 / 1000\n",
      "saving losses\n",
      "epoch:    521 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    522 / 1000\n",
      "saving losses\n",
      "epoch:    523 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    524 / 1000\n",
      "saving losses\n",
      "epoch:    525 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    526 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    527 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    528 / 1000\n",
      "saving losses\n",
      "epoch:    529 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    530 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    531 / 1000\n",
      "saving losses\n",
      "epoch:    532 / 1000\n",
      "saving losses\n",
      "epoch:    533 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    534 / 1000\n",
      "saving losses\n",
      "epoch:    535 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    536 / 1000\n",
      "saving losses\n",
      "epoch:    537 / 1000\n",
      "saving losses\n",
      "epoch:    538 / 1000\n",
      "saving losses\n",
      "epoch:    539 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    540 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    541 / 1000\n",
      "saving losses\n",
      "epoch:    542 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    543 / 1000\n",
      "saving losses\n",
      "epoch:    544 / 1000\n",
      "saving losses\n",
      "epoch:    545 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    546 / 1000\n",
      "saving losses\n",
      "epoch:    547 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    548 / 1000\n",
      "saving losses\n",
      "epoch:    549 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    550 / 1000\n",
      "saving losses\n",
      "epoch:    551 / 1000\n",
      "saving losses\n",
      "epoch:    552 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    553 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    554 / 1000\n",
      "saving losses\n",
      "epoch:    555 / 1000\n",
      "saving losses\n",
      "epoch:    556 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    557 / 1000\n",
      "saving losses\n",
      "epoch:    558 / 1000\n",
      "saving losses\n",
      "epoch:    559 / 1000\n",
      "saving losses\n",
      "epoch:    560 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    561 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    562 / 1000\n",
      "saving losses\n",
      "epoch:    563 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    564 / 1000\n",
      "saving losses\n",
      "epoch:    565 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    566 / 1000\n",
      "saving losses\n",
      "epoch:    567 / 1000\n",
      "saving losses\n",
      "epoch:    568 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    569 / 1000\n",
      "saving losses\n",
      "epoch:    570 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    571 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    572 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    573 / 1000\n",
      "saving losses\n",
      "epoch:    574 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    575 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    576 / 1000\n",
      "saving losses\n",
      "epoch:    577 / 1000\n",
      "saving losses\n",
      "epoch:    578 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    579 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    580 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    581 / 1000\n",
      "saving losses\n",
      "epoch:    582 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    583 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    584 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    585 / 1000\n",
      "saving losses\n",
      "epoch:    586 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    587 / 1000\n",
      "saving losses\n",
      "epoch:    588 / 1000\n",
      "saving losses\n",
      "epoch:    589 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    590 / 1000\n",
      "saving losses\n",
      "epoch:    591 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    592 / 1000\n",
      "saving losses\n",
      "epoch:    593 / 1000\n",
      "saving losses\n",
      "epoch:    594 / 1000\n",
      "saving losses\n",
      "epoch:    595 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    596 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    597 / 1000\n",
      "saving losses\n",
      "epoch:    598 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    599 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    600 / 1000\n",
      "saving losses\n",
      "epoch:    601 / 1000\n",
      "saving losses\n",
      "epoch:    602 / 1000\n",
      "saving losses\n",
      "epoch:    603 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    604 / 1000\n",
      "saving losses\n",
      "epoch:    605 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    606 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    607 / 1000\n",
      "saving losses\n",
      "epoch:    608 / 1000\n",
      "saving losses\n",
      "epoch:    609 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    610 / 1000\n",
      "saving losses\n",
      "epoch:    611 / 1000\n",
      "saving losses\n",
      "epoch:    612 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    613 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    614 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    615 / 1000\n",
      "saving losses\n",
      "epoch:    616 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    617 / 1000\n",
      "saving losses\n",
      "epoch:    618 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    619 / 1000\n",
      "saving losses\n",
      "epoch:    620 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    621 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    622 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    623 / 1000\n",
      "saving losses\n",
      "epoch:    624 / 1000\n",
      "saving losses\n",
      "epoch:    625 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    626 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    627 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    628 / 1000\n",
      "saving losses\n",
      "epoch:    629 / 1000\n",
      "saving losses\n",
      "epoch:    630 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    631 / 1000\n",
      "saving losses\n",
      "epoch:    632 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    633 / 1000\n",
      "saving losses\n",
      "epoch:    634 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    635 / 1000\n",
      "saving losses\n",
      "epoch:    636 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    637 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    638 / 1000\n",
      "saving losses\n",
      "epoch:    639 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    640 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    641 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    642 / 1000\n",
      "saving losses\n",
      "epoch:    643 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    644 / 1000\n",
      "saving losses\n",
      "epoch:    645 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    646 / 1000\n",
      "saving losses\n",
      "epoch:    647 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    648 / 1000\n",
      "saving losses\n",
      "epoch:    649 / 1000\n",
      "saving losses\n",
      "epoch:    650 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    651 / 1000\n",
      "saving losses\n",
      "epoch:    652 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    653 / 1000\n",
      "saving losses\n",
      "epoch:    654 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    655 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    656 / 1000\n",
      "saving losses\n",
      "epoch:    657 / 1000\n",
      "saving losses\n",
      "epoch:    658 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    659 / 1000\n",
      "saving losses\n",
      "epoch:    660 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    661 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    662 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    663 / 1000\n",
      "saving losses\n",
      "epoch:    664 / 1000\n",
      "saving losses\n",
      "epoch:    665 / 1000\n",
      "saving losses\n",
      "epoch:    666 / 1000\n",
      "saving losses\n",
      "epoch:    667 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    668 / 1000\n",
      "saving losses\n",
      "epoch:    669 / 1000\n",
      "saving losses\n",
      "epoch:    670 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    671 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving losses\n",
      "epoch:    672 / 1000\n",
      "saving losses\n",
      "epoch:    673 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    674 / 1000\n",
      "saving losses\n",
      "epoch:    675 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    676 / 1000\n",
      "saving losses\n",
      "epoch:    677 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    678 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    679 / 1000\n",
      "saving losses\n",
      "epoch:    680 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    681 / 1000\n",
      "saving losses\n",
      "epoch:    682 / 1000\n",
      "saving losses\n",
      "epoch:    683 / 1000\n",
      "saving losses\n",
      "epoch:    684 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    685 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    686 / 1000\n",
      "saving losses\n",
      "epoch:    687 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    688 / 1000\n",
      "saving losses\n",
      "epoch:    689 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    690 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    691 / 1000\n",
      "saving losses\n",
      "epoch:    692 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    693 / 1000\n",
      "saving losses\n",
      "epoch:    694 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    695 / 1000\n",
      "saving losses\n",
      "epoch:    696 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    697 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    698 / 1000\n",
      "saving losses\n",
      "epoch:    699 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    700 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    701 / 1000\n",
      "saving losses\n",
      "epoch:    702 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    703 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    704 / 1000\n",
      "saving losses\n",
      "epoch:    705 / 1000\n",
      "saving losses\n",
      "epoch:    706 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    707 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    708 / 1000\n",
      "saving losses\n",
      "epoch:    709 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    710 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    711 / 1000\n",
      "saving losses\n",
      "epoch:    712 / 1000\n",
      "saving losses\n",
      "epoch:    713 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    714 / 1000\n",
      "saving losses\n",
      "epoch:    715 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    716 / 1000\n",
      "saving losses\n",
      "epoch:    717 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    718 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    719 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    720 / 1000\n",
      "early stopping counter:  8\n",
      "saving losses\n",
      "epoch:    721 / 1000\n",
      "early stopping counter:  10\n",
      "saving losses\n",
      "epoch:    722 / 1000\n",
      "saving losses\n",
      "epoch:    723 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    724 / 1000\n",
      "saving losses\n",
      "epoch:    725 / 1000\n",
      "saving losses\n",
      "epoch:    726 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    727 / 1000\n",
      "saving losses\n",
      "epoch:    728 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    729 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    730 / 1000\n",
      "saving losses\n",
      "epoch:    731 / 1000\n",
      "saving losses\n",
      "epoch:    732 / 1000\n",
      "saving losses\n",
      "epoch:    733 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    734 / 1000\n",
      "saving losses\n",
      "epoch:    735 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    736 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    737 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    738 / 1000\n",
      "early stopping counter:  8\n",
      "saving losses\n",
      "epoch:    739 / 1000\n",
      "early stopping counter:  10\n",
      "saving losses\n",
      "epoch:    740 / 1000\n",
      "saving losses\n",
      "epoch:    741 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    742 / 1000\n",
      "saving losses\n",
      "epoch:    743 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    744 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    745 / 1000\n",
      "saving losses\n",
      "epoch:    746 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    747 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    748 / 1000\n",
      "saving losses\n",
      "epoch:    749 / 1000\n",
      "saving losses\n",
      "epoch:    750 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    751 / 1000\n",
      "saving losses\n",
      "epoch:    752 / 1000\n",
      "saving losses\n",
      "epoch:    753 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    754 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    755 / 1000\n",
      "saving losses\n",
      "epoch:    756 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    757 / 1000\n",
      "saving losses\n",
      "epoch:    758 / 1000\n",
      "saving losses\n",
      "epoch:    759 / 1000\n",
      "saving losses\n",
      "epoch:    760 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    761 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    762 / 1000\n",
      "saving losses\n",
      "epoch:    763 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    764 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    765 / 1000\n",
      "saving losses\n",
      "epoch:    766 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    767 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    768 / 1000\n",
      "saving losses\n",
      "epoch:    769 / 1000\n",
      "saving losses\n",
      "epoch:    770 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    771 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    772 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    773 / 1000\n",
      "saving losses\n",
      "epoch:    774 / 1000\n",
      "saving losses\n",
      "epoch:    775 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    776 / 1000\n",
      "saving losses\n",
      "epoch:    777 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    778 / 1000\n",
      "saving losses\n",
      "epoch:    779 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    780 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    781 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    782 / 1000\n",
      "saving losses\n",
      "epoch:    783 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    784 / 1000\n",
      "saving losses\n",
      "epoch:    785 / 1000\n",
      "saving losses\n",
      "epoch:    786 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    787 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    788 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    789 / 1000\n",
      "saving losses\n",
      "epoch:    790 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    791 / 1000\n",
      "saving losses\n",
      "epoch:    792 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    793 / 1000\n",
      "saving losses\n",
      "epoch:    794 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    795 / 1000\n",
      "saving losses\n",
      "epoch:    796 / 1000\n",
      "saving losses\n",
      "epoch:    797 / 1000\n",
      "saving losses\n",
      "epoch:    798 / 1000\n",
      "saving losses\n",
      "epoch:    799 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    800 / 1000\n",
      "saving losses\n",
      "epoch:    801 / 1000\n",
      "saving losses\n",
      "epoch:    802 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    803 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    804 / 1000\n",
      "saving losses\n",
      "epoch:    805 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    806 / 1000\n",
      "saving losses\n",
      "epoch:    807 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    808 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    809 / 1000\n"
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "# criterion = torch.nn.MSELoss(reduction = \"sum\")\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# use of GPU flag\n",
    "use_gpu = True\n",
    "\n",
    "# load model on GPU\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "# number of epochs\n",
    "epochs = epochs\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # # loss plot\n",
    "fig, ax = plt.subplots(figsize = (3, 3), tight_layout = True)\n",
    "# # fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Error\")\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.axis([0,1000,0,10])\n",
    "# plt.show()\n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "#     print(\"\\r{0}\".format((float(nepoch)/epochs)*100))\n",
    "#     sys.stdout.write('\\r')\n",
    "#     # the exact output you're looking for:\n",
    "#     sys.stdout.write(\"[%-20s] %d%%\" % ('='*nepoch, 5*nepoch))\n",
    "#     sys.stdout.flush()\n",
    "#     sleep(0.25)\n",
    "    \n",
    "    # train\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data_ in trainLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_gpu:\n",
    "            \n",
    "#             data = data.type(torch.FloatTensor).cuda()\n",
    "            data = generateDeltas(data, passband).type(torch.FloatTensor).cuda()\n",
    "#             print(data.device)\n",
    "#             print(model.device())\n",
    "            outputs, mu, logvar = model.forward(data)\n",
    "    \n",
    "#             # DO one fortwar!!\n",
    "#             mu, logvar = model.encoder.forward(data.type(torch.FloatTensor).cuda())\n",
    "            \n",
    "        else:\n",
    "                        \n",
    "            data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "#             generateDeltas(data, 0)\n",
    "#             outputs = model.forward(data.type(torch.FloatTensor))\n",
    "            outputs, mu, logvar = model.forward(data)\n",
    "#             mu, logvar = model.encoder.forward(data.type(torch.FloatTensor))\n",
    "        \n",
    "#         loss = criterion(outputs, data)\n",
    "        # use KLD + MSE\n",
    "#         loss = loss_function(outputs, data, mu, logvar)\n",
    "        loss = loss_function(outputs, data, mu, logvar, data_[0][:, passband, 3, :])\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    # test\n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    for data_ in validationLoader:\n",
    "        \n",
    "        data = data_[0]\n",
    "        \n",
    "        if use_gpu:\n",
    "            \n",
    "            data = generateDeltas(data, passband).type(torch.FloatTensor).cuda()\n",
    "#             data = data.type(torch.FloatTensor).cuda()\n",
    "#             outputs = model.forward(data)\n",
    "#             mu, logvar = model.encoder.forward(data.type(torch.FloatTensor).cuda())\n",
    "            outputs, mu, logvar = model.forward(data)\n",
    "        \n",
    "        else:\n",
    "#             data = data.type(torch.FloatTensor)\n",
    "            data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "            \n",
    "#             outputs = model.forward(data)\n",
    "            \n",
    "#             mu, logvar = model.encoder.forward(data.type(torch.FloatTensor))\n",
    "            outputs, mu, logvar = model.forward(data)\n",
    "        \n",
    "#         loss = criterion(outputs, data)\n",
    "#         loss = loss_function(outputs, data, mu, logvar)\n",
    "        loss = loss_function(outputs, data, mu, logvar, data_[0][:, passband, 3, :])\n",
    "        \n",
    "        epoch_test_loss += loss.item()\n",
    "    \n",
    "    test_loss[nepoch] = epoch_test_loss / test_size\n",
    "    \n",
    "# #     # plot loss\n",
    "    ax.plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "    ax.plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\") \n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"experiments/\" + number_experiment + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if epoch_test_loss < minTestLossGlobalSoFar:\n",
    "        \n",
    "        print(\"New min test loss. Saving model\")\n",
    "#         print(\"old: \", minTestLossGlobalSoFar)\n",
    "#         print(\"new: \", epoch_test_loss)\n",
    "        \n",
    "        # save model\n",
    "        torch.save(model.state_dict(), pathToSaveModel)\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = epoch_test_loss\n",
    "        \n",
    "        # write metrics\n",
    "        text_file = open(\"experiments/\" + number_experiment + \"/bestScoresModelTraining.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n Reconstruction test error: {1}\".format(nepoch, minTestLossGlobalSoFar)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "\n",
    "        \n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"experiments/\" + number_experiment + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "    \n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load losses array\n",
    "losses = pd.read_csv(\"/home/leo/Desktop/thesis/work/thesis/experiments/\"+ number_experiment + \"/training_losses.csv\")\n",
    "\n",
    "# plot losses\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# axis\n",
    "ax.set_xlabel(\"N° epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "\n",
    "# plot\n",
    "ax.plot(losses.iloc[:, 0], label = \"train\")\n",
    "ax.plot(losses.iloc[:, 1], label = \"test\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Latent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take the data to use to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# # train loader\n",
    "# trainLoader = torch.utils.data.DataLoader(trainDataset)\n",
    "\n",
    "# # # test loader\n",
    "# testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "# # trainLoader = torch.utils.data.DataLoader(torch_dataset_lazy, batch_size=256, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat experiments/3/bestScoresModelTraining.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# defining model\n",
    "model = AutoEncoder(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim)\n",
    "\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(pathToSaveModel))\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = testLoader\n",
    "size = test_size\n",
    "\n",
    "reconstructedLightCurves = np.zeros(shape = (size, 2, 72 ))\n",
    "originalLightCurves = np.zeros(shape = (size, 2, 72 ))\n",
    "mask = np.zeros(shape = (size, 72))\n",
    "loss_values = np.zeros(shape = (size))\n",
    "\n",
    "# print(test_size)\n",
    "# print(reconstructedLightCurves.shape)\n",
    "\n",
    "lastIndex = -1\n",
    "\n",
    "\n",
    "for i, data_ in enumerate(loader):\n",
    "\n",
    "    data = data_[0]\n",
    "    \n",
    "#     print(data.shape)\n",
    "    \n",
    "#     print(data[0, passband, 1, :].shape)\n",
    "    \n",
    "    data = generateDeltas(data, passband).type(torch.FloatTensor).cuda()\n",
    "    \n",
    "#     print(\"data: \", data.shape)\n",
    "    \n",
    "#     outputs = model(data)\n",
    "    outputs, mu, logvar = model.forward(data)\n",
    "    \n",
    "    # get loss function value\n",
    "    loss_values[lastIndex + 1 : (lastIndex + outputs.shape[0] + 1)] = loss_function(outputs, data, mu, logvar, data_[0][:, passband, 3, :]).detach().cpu()\n",
    "    \n",
    "    # save orignial light curve\n",
    "    originalLightCurves[lastIndex + 1 : (lastIndex + outputs.shape[0] + 1), :, : ] = data_[0][:, passband, 0:2, :]\n",
    "    mask[lastIndex + 1 : (lastIndex + outputs.shape[0] + 1),] = data_[0][:, passband, 3, :]\n",
    "    \n",
    "#     print(\"original: \", originalLightCurves)\n",
    "#     print(\"data: \", data_[0])\n",
    "#     originalLightCurves = np.append(originalLightCurves, data[:, passband, 0:2, :])\n",
    "\n",
    "#     # reconstructed data\n",
    "#     print(\"output: \", outputs.shape)\n",
    "    \n",
    "    reconstructedLightCurve = np.zeros(shape = data_[0][:, passband, 0:2, :].shape)\n",
    "    \n",
    "#     print(reconstructedLightCurve.shape)\n",
    "    \n",
    "    # convert from delta to original format\n",
    "    \n",
    "    # adding first element (index 0)\n",
    "    # adding time with index 0\n",
    "    reconstructedLightCurve[:, 0, 0] = data_[0][:, passband, 0, 0]\n",
    "#     print(reconstructedLightCurve)\n",
    "    # adding flux with index 0\n",
    "    reconstructedLightCurve[:, 1, 0] = data_[0][:, passband, 1, 0]\n",
    "    \n",
    "    # converting from 1 to end\n",
    "    for i_lightCurve in range(1, data_[0].shape[3]):\n",
    "        \n",
    "        # add time and flux \n",
    "        reconstructedLightCurve[:, :, i_lightCurve] = reconstructedLightCurve[:, :, i_lightCurve-1] + outputs[:, :, i_lightCurve-1].cpu().detach().numpy()\n",
    "        \n",
    "#     # plotting a light curve\n",
    "#     if i == 200:\n",
    "        \n",
    "#         # create plot\n",
    "#         fig, ax = plt.subplots(1, 1, figsize = (3,3), tight_layout = True)\n",
    "#         # add original\n",
    "#         ax.scatter(data_[0][0, passband, 0, :], data_[0][0, passband, 1, :], label = \"original\")\n",
    "#         ax.scatter(reconstructedLightCurve[0, 0, :], reconstructedLightCurve[0, 1, :])\n",
    "        \n",
    "    # add lightcurves from batch to array\n",
    "#     print(reconstructedLightCurves.shape)\n",
    "#     print(reconstructedLightCurves[lastIndex + 1 : (lastIndex + outputs.shape[0] + 1), :, : ].shape)\n",
    "    reconstructedLightCurves[lastIndex + 1 : (lastIndex + outputs.shape[0] + 1), :, : ] = reconstructedLightCurve\n",
    "#     print(lastIndex)\n",
    "#     print(lastIndex + 1, (lastIndex + outputs.shape[0] + 1))\n",
    "    \n",
    "    lastIndex = i*outputs.shape[0] + outputs.shape[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted array\n",
    "# ascendent order\n",
    "loss_values_sorted = np.argsort(loss_values)\n",
    "print(loss_values[loss_values_sorted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(loss_values, density = True)\n",
    "# loss_values_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# loss value stats\n",
    "print(stats.describe(loss_values))\n",
    "\n",
    "print(np.std(loss_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error with 0 value: \" + str(np.where(loss_values == 0)[0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot light curves\n",
    "n_lightCurves = 3\n",
    "\n",
    "# create random indexes\n",
    "# indexes = np.random.randint(test_size, size= n_lightCurves)\n",
    "# minimum error\n",
    "indexes = loss_values_sorted[: n_lightCurves]\n",
    "\n",
    "# max error\n",
    "# indexes = loss_values_sorted[:n_lightCurves:-1]\n",
    "print(indexes)\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots(n_lightCurves, 1, figsize = (5,n_lightCurves * 2), tight_layout = True)\n",
    "\n",
    "# plot light curves\n",
    "for i in range(n_lightCurves):\n",
    "    \n",
    "    # add original\n",
    "    ax[i].scatter(originalLightCurves[indexes[i], 0, mask[indexes[i]].astype(bool)], originalLightCurves[indexes[i], 1, mask[indexes[i]].astype(bool)], label = \"original\")\n",
    "    ax[i].scatter(reconstructedLightCurves[indexes[i], 0, mask[indexes[i]].astype(bool)], reconstructedLightCurves[indexes[i], 1, mask[indexes[i]].astype(bool)], label = \"reconstructed\")\n",
    "    ax[i].set_title(\"Object id: \" + str(indexes[i]) + \"\\nReconstruction error: \" + str(round(loss_values[indexes[i]], 2) )  )\n",
    "#     if i == 0:\n",
    "        \n",
    "#         fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training\n",
    "# latent_variables_train = np.zeros(shape = (train_size, latentDim))\n",
    "# labels_train = np.zeros(shape = (train_size))\n",
    "\n",
    "# # print(latent_variables_train.shape)\n",
    "\n",
    "# # testing\n",
    "# latent_variables_test = np.zeros(shape = (test_size, latentDim))\n",
    "# labels_test = np.zeros(shape = (test_size))\n",
    "\n",
    "# # counter\n",
    "# last_index = -1\n",
    "\n",
    "# for i, data_ in enumerate(trainLoader):\n",
    "\n",
    "#     data = data_[0]\n",
    "    \n",
    "#     data = generateDeltas(data, passband).type(torch.FloatTensor).cuda()\n",
    "\n",
    "#     outputs = model.get_latent_variables(data)\n",
    "    \n",
    "#     latent_variables_train[last_index + 1 : (last_index + outputs.shape[0] + 1), :] = outputs[:, 0, :].cpu().detach().numpy()\n",
    "#     labels_train[last_index + 1 : (last_index + outputs.shape[0] + 1)] = data_[1].numpy()[:,]\n",
    "    \n",
    "#     # updateing counter\n",
    "#     last_index = i*outputs.shape[0] + outputs.shape[0] - 1\n",
    "\n",
    "    \n",
    "# # counter\n",
    "# last_index = -1\n",
    "    \n",
    "# for i, data_ in enumerate(testLoader):\n",
    "    \n",
    "#     data = data_[0]\n",
    "    \n",
    "#     data = generateDeltas(data, passband).type(torch.FloatTensor).cuda()\n",
    "\n",
    "#     outputs = model.get_latent_variables(data)\n",
    "    \n",
    "#     latent_variables_test[last_index + 1 : (last_index + outputs.shape[0] + 1), :] = outputs[:, 0, :].cpu().detach().numpy()\n",
    "#     labels_test[last_index + 1 : (last_index + outputs.shape[0] + 1)] = data_[1].numpy()[:,]\n",
    "        \n",
    "#     # updating counter\n",
    "#     last_index = i*outputs.shape[0] + outputs.shape[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Analyze labels\n",
    "# fig, ax = plt.subplots(1, 2)\n",
    "# ax[0].set_title(\"training\")\n",
    "# ax[0].hist(labels_train)\n",
    "# ax[1].hist(labels_test)\n",
    "# ax[1].set_title(\"testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# # define model\n",
    "# classifier = RandomForestClassifier()\n",
    "\n",
    "# # train model\n",
    "# classifier.fit(latent_variables_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # get f1 score\n",
    "# print(\"F1 score: \", f1_score(labels_test, classifier.predict(latent_variables_test), average='macro'))\n",
    "\n",
    "# # get accuracy\n",
    "# print(\"Accuracy: \", accuracy_score(labels_test, classifier.predict(latent_variables_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
