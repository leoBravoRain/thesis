{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "trainingOnGuanaco = False\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 6\n",
    "number_experiment = str(number_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "only_these_labels=[16, 92]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 60\n",
    "hiddenDim = 20\n",
    "\n",
    "# training\n",
    "epochs = 1000\n",
    "\n",
    "# band\n",
    "passband = 5\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticc_torch/\"\n",
    "# path to file in guanaco\n",
    "# pathToFile = \"/home/shared/astro/PLAsTiCC/\"\n",
    "\n",
    "# path to file in local \n",
    "# pathToFile = \"/home/leo/Downloads/plasticc_torch/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 1 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticc_torch/plasticc_train_lightcurves.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting one light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc_data, lc_label, lc_plasticc_id = torch_dataset_lazy.__getitem__(123)\n",
    "# display(lc_plasticc_id, lc_label)\n",
    "# 6 bands: u g r i z Y\n",
    "# 4 sequences: mjd, flux, error, mask\n",
    "# 72 samples\n",
    "# display(lc_data.shape, lc_data.dtype)\n",
    "# print(lc_data.detach().numpy()[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_light_curve(torch_dataset_lazy, index_in_dataset=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data\n",
    "\n",
    "# selecting train splitting\n",
    "train_size = int(0.8 * torch_dataset_lazy.__len__())\n",
    "\n",
    "# getting test splitting\n",
    "test_size = torch_dataset_lazy.__len__() - train_size\n",
    "\n",
    "# spliting the torch dataset\n",
    "trainDataset, testDataset = torch.utils.data.random_split(torch_dataset_lazy, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# # train loader\n",
    "trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size= batch_training_size, shuffle=True, num_workers = 4)\n",
    "\n",
    "# # test loader\n",
    "testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "# trainLoader = torch.utils.data.DataLoader(torch_dataset_lazy, batch_size=256, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the path to save model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory /home/leo/Desktop/thesis/work/thesis/experiments/6 \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create experiment's folder\n",
    "folder_path = (\"/home/lbravo/thesis/work/thesis/experiments/\" + number_experiment) if trainingOnGuanaco else (\"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment)\n",
    "# !mkdir folder_path\n",
    "# os.makedirs(os.path.dirname(folder_path), exist_ok=True)\n",
    "\n",
    "# check if folder exists\n",
    "if not(os.path.isdir(folder_path)):\n",
    "        \n",
    "    # create folder\n",
    "    try:\n",
    "        os.mkdir(folder_path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % folder_path)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_path)\n",
    "else:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "# define paht to save model while training\n",
    "pathToSaveModel = \"/home/lbravo/thesis/work/thesis/experiments/\" + number_experiment + \"/model_guanaco_1\" if trainingOnGuanaco else \"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check data loader shape\n",
    "# text_file = open(\"experiments/\" + number_experiment + \"/datasetDescription.txt\", \"w\")\n",
    "\n",
    "# # training\n",
    "# text_file.write(\"#### TRAINING ####\")\n",
    "# text_file.write(\"\\nminibatches trainig: \"+ str(len(list(trainLoader))))\n",
    "# text_file.write(\"\\nminibatch trainig size: \" + str(list(trainLoader)[0][0].shape))\n",
    "\n",
    "\n",
    "# # testing\n",
    "# text_file.write(\"\\n#### TESTING ####\")\n",
    "# text_file.write(\"\\nminibatches test: \"+ str(len(list(testLoader))))\n",
    "# text_file.write(\"\\nminibatch trainig size: \" + str(list(testLoader)[0][0].shape))\n",
    "\n",
    "# text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define autoencoder structure\n",
    "To start with the work, It is going to build a very basic Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buiding autoencoder\n",
    "\n",
    "# Assuming this has a normal distrubtion in the latent part\n",
    "\n",
    "# encoder\n",
    "class Encoder(torch.nn.Module):\n",
    "    \n",
    "    # init method\n",
    "    def __init__(self, latent_dim, hidden_dim, input_dim):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # 1 Convolution layer\n",
    "        # Conv1d(input channel, output channel, kernel size)\n",
    "        self.conv1 = torch.nn.Conv1d(1,64,3)\n",
    "        \n",
    "        # this is to consider time and magnitude\n",
    "        # we should use shared weights?\n",
    "        self.conv1Time = torch.nn.Conv1d(1, 64, 3)\n",
    "        self.conv1Mag = torch.nn.Conv1d(1, 64, 3)\n",
    "        \n",
    "        # 2 Convolution layer\n",
    "        # Conv1d(input channel, output channel, kernel size)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 32, 3)\n",
    "        \n",
    "        # time and magnitude conv\n",
    "        self.conv2Time = torch.nn.Conv1d(64, 32, 3)\n",
    "        self.conv2Mag = torch.nn.Conv1d(64, 32, 3)\n",
    "        \n",
    "        # linear layer\n",
    "        self.hidden1 = torch.nn.Linear(2144*2, hidden_dim)\n",
    "        \n",
    "        # mu\n",
    "        self.mu = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # sigma\n",
    "        self.logVar = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # activation function\n",
    "        self.activationConv = torch.nn.ReLU() #max(0, x)\n",
    "    \n",
    "        self.activationLinear = torch.nn.Tanh()\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # input shape: [batch_size, channels, sequence_length]\n",
    "        # print(\"input shape: {0}\".format(x.shape))\n",
    "        \n",
    "        \n",
    "        # convolution 1\n",
    "        # x -> conv -> act -> ouput\n",
    "        # shape should be: [batch_size, number of ouput channels (64), length of output from convolution]\n",
    "\n",
    "        #conv to time\n",
    "        outputTimeConv = self.activationConv(self.conv1Time(x[:, 0, :].unsqueeze(1)))\n",
    "        \n",
    "        # conv to magnitude\n",
    "        outputMagConv = self.activationConv(self.conv1Mag(x[:, 1, :].unsqueeze(1)))\n",
    "        \n",
    "#         print(\"output conv1 shape: {0}\".format(outputMagConv.shape))\n",
    "#         print(\"output conv1 shape: {0}\".format(outputTimeConv.shape))\n",
    "        \n",
    "        # convolution 2\n",
    "#         # shape should be: [batch_size, number of ouput channels (32), length of output from convolution]\n",
    "        \n",
    "        # conv to time\n",
    "        outputTimeConv = self.activationConv(self.conv2(outputTimeConv))\n",
    "    \n",
    "        # conv to flux\n",
    "        outputMagConv = self.activationConv(self.conv2(outputMagConv))\n",
    "        \n",
    "#         print(\"output conv2 shape: {0}\".format(outputTimeConv.shape))\n",
    "#         print(\"output conv2 shape: {0}\".format(outputMagConv.shape))\n",
    "        \n",
    "        # flatten ouput\n",
    "        # shape should be: [batch_size, -1]\n",
    "        outputMagConv = outputMagConv.view(outputMagConv.shape[0], -1)\n",
    "        outputTimeConv = outputTimeConv.view(outputTimeConv.shape[0], -1)\n",
    "        \n",
    "#         print(\"output reshape: \", outputMagConv.shape)\n",
    "#         print(\"output reshape: \", outputTimeConv.shape)\n",
    "                \n",
    "        # concatenate 2 towers\n",
    "        output = torch.cat((outputMagConv, outputTimeConv), 1)\n",
    "#         print(\"concatenate output shape: \", output.shape)\n",
    "        \n",
    "        # x -> hidden1 -> activation\n",
    "        output = self.activationLinear(self.hidden1(output))\n",
    "#         print(\"hidden1 output shape: {0}\".format(output.shape))\n",
    "        \n",
    "        # get mu\n",
    "        # sin tangenteh!!!\n",
    "        mu = self.mu(output)\n",
    "#         print(\"mu shape: {0}\".format(mu.shape))\n",
    "        \n",
    "        # get sigma\n",
    "        logVar = self.logVar(output)\n",
    "#         print(\"sigma shape: {0}\".format(logVar.shape))\n",
    "        \n",
    "        # returning values\n",
    "        return mu, logVar\n",
    "\n",
    "    \n",
    "# decoder    \n",
    "class Decoder(torch.nn.Module):\n",
    "    \n",
    "    # define layers\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # linear layer\n",
    "        self.hidden1 = torch.nn.Linear(latent_dim, 2144*2)\n",
    "        \n",
    "        # 1 ConvolutionTrans layer\n",
    "        self.convTrans1 = torch.nn.ConvTranspose1d(32, 64, 3)\n",
    "        \n",
    "        # 2 ConvolutionTrans layer\n",
    "        self.convTrans2 = torch.nn.ConvTranspose1d(64, 1, 3)\n",
    "\n",
    "        # activation function\n",
    "        self.activationConv = torch.nn.ReLU() #max(0, x)\n",
    "    \n",
    "        self.activationLinear = torch.nn.Tanh()\n",
    "        \n",
    "    # forward method\n",
    "    def forward(self, z):\n",
    "        \n",
    "#         print(\"input dimension decoder: {0}\".format(z.shape))\n",
    "        \n",
    "        # linear (from latent to hidden dimension)\n",
    "        # z -> linaer layer -> activation -> output\n",
    "        output = self.activationLinear(self.hidden1(z))\n",
    "#         print(\"output hidden1: {0}\".format(output.shape))\n",
    "        \n",
    "        # split data (into time and flux)\n",
    "        outputTimeDeconv, outputMagDeconv = torch.split(output, 2144, dim=2)\n",
    "            \n",
    "        # reshape each tower (time and magnitude)\n",
    "        outputTimeDeconv = outputTimeDeconv.view(outputTimeDeconv.shape[0], 32, -1)\n",
    "        outputMagDeconv = outputMagDeconv.view(outputMagDeconv.shape[0], 32, -1)\n",
    "        \n",
    "#         print(\"output reshape: {0}\".format(outputTimeDeconv.shape))\n",
    "#         print(\"output reshape: {0}\".format(outputMagDeconv.shape))\n",
    "        \n",
    "        # 1 convolution\n",
    "        outputTimeDeconv = self.activationConv(self.convTrans1(outputTimeDeconv))\n",
    "        outputMagDeconv = self.activationConv(self.convTrans1(outputMagDeconv))\n",
    "#         print(\"ouput convTrans1: {0}\".format(outputTimeDeconv.shape))\n",
    "#         print(\"ouput convTrans1: {0}\".format(outputMagDeconv.shape))\n",
    "        \n",
    "        # 2 convolution\n",
    "        outputTimeDeconv = self.convTrans2(outputTimeDeconv)\n",
    "        outputMagDeconv = self.convTrans2(outputMagDeconv)\n",
    "        \n",
    "#         print(\"ouput convTrans2: {0}\".format(outputTimeDeconv.shape))\n",
    "#         print(\"ouput convTrans2: {0}\".format(outputMagDeconv.shape))\n",
    "        \n",
    "        # concatenate arrays in order to get the data with 2 channels\n",
    "        output = torch.cat((outputTimeDeconv, outputMagDeconv), 1)\n",
    "#         print(\"concatenate in channels: {0}\".format(output.shape))\n",
    "\n",
    "        # output\n",
    "        return output\n",
    "\n",
    "# building the autoencoder     \n",
    "class AutoEncoder(torch.nn.Module):\n",
    "    \n",
    "    # defining the initial structure\n",
    "    def __init__(self, latent_dim, hidden_dim, input_dim):\n",
    "        \n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # defining the encoder\n",
    "        self.encoder = Encoder(latent_dim, hidden_dim, input_dim)\n",
    "        \n",
    "        # defining the decoder\n",
    "        # note the output dimension in the decoder is the same as input dimension\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "\n",
    "    # distribution function\n",
    "    def sampling(self, mu, logvar, k = 1):\n",
    "        \n",
    "        # assumming normal distribution\n",
    "#         s = torch.exp(0.5*sigma)\n",
    "#         eps = torch.rand_like(s) # generate a iid standard normal same shape as s\n",
    "#         return eps.mul(s).add_(mu)\n",
    "        batch_size, n_latent = logvar.shape\n",
    "        std = (0.5*logvar).exp()\n",
    "#         eps = torch.randn(batch_size, k, n_latent, device=std.device, requires_grad=False)\n",
    "        eps = torch.randn(batch_size, k, n_latent, requires_grad=False)\n",
    "        if \"cuda\" in str(mu.device):\n",
    "            eps = eps.cuda()\n",
    "        return eps.mul(std.unsqueeze(1)).add(mu.unsqueeze(1))\n",
    "    \n",
    "    # forward method (how to the nn works)\n",
    "    def forward(self, x):\n",
    "        \n",
    "#         print(\"input size: {0}\".format(x.shape))\n",
    "        \n",
    "#         print(\"## Encoder ##\")\n",
    "        # input (x) -> encoder -> latent variables\n",
    "        mu, logVar = self.encoder(x)\n",
    "#         print(\"output encoder size: {0}\".format(mu.shape))\n",
    "        \n",
    "#         print(\"mu \", mu.device)\n",
    "#         print(\"var \", logVar.device)\n",
    "        # getting sample\n",
    "        # mu, sigma -> distribution -> z\n",
    "        z = self.sampling(mu, logVar)\n",
    "#         print(\"z shape: \", z.shape)\n",
    "        \n",
    "#         print(\"## Dencoder ##\")\n",
    "        # latent variables -> decoder -> reconstruction (x)\n",
    "        decOutput = self.decoder(z)\n",
    "#         print(\"output decoder size: {0}\".format(decOutput.shape))\n",
    "        \n",
    "        return decOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = 72\n",
    "\n",
    "passband = passband\n",
    "\n",
    "# defining model\n",
    "model = AutoEncoder(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test the model data flow\n",
    "# model.forward(list(trainLoader)[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(\"input dimension: {0}\".format(len(list(trainLoader))))\n",
    "\n",
    "# # parameters number\n",
    "# count = 0\n",
    "\n",
    "# # # check model dimension\n",
    "# for name, param in model.state_dict().items():\n",
    "#     # name: str\n",
    "#     # param: Tensor\n",
    "# #     print(\"{0}: {1} \\n\".format(name, param.shape))\n",
    "# #     print(param.shape[0]*(param.shape[1] if len(param.shape)>1 else 1))\n",
    "# #     print(param.shape)\n",
    "#     count += param.shape[0]*(param.shape[1] if len(param.shape)>1 else 1)\n",
    "# # for param in model.parameters():\n",
    "    \n",
    "# print(\"number of parameters: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \n",
    "#     print(\"reconstruction: {0}\".format(recon_x))\n",
    "#     print(\"x: {0}\".format(x))\n",
    "#     print(\"mu: {0}\".format(mu))\n",
    "#     print(\"logvar: {0}\".format(logvar))\n",
    "    \n",
    "#     BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    BCE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "#     print(BCE)\n",
    "    \n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# normalize light curve\n",
    "# data: [batch size, 2 channels (time and magnitude), light curve length]\n",
    "def normalizeLightCurve(data):\n",
    "    \n",
    "#     print(\"data shape before normalization: \", data.shape)\n",
    "    \n",
    "    # get flux mean\n",
    "    means = data[:, 1, :].mean(dim=1)\n",
    "#     print(\"mean shape: \", means.shape)\n",
    "    \n",
    "    # get flux standar deviation \n",
    "    stds = data[:, 1, :].std(dim=1)\n",
    "#     print(\"stds shape: \", stds.shape)\n",
    "    \n",
    "    # overwrite flux\n",
    "    data[:, 1, :] = (data[:, 1, :] - means.unsqueeze(1).expand_as(data[:, 1, :])) / stds.unsqueeze(1).expand_as(data[:, 1, :])\n",
    "#     print(\"normalized data shape: \", data.shape)\n",
    "    \n",
    "    # return normalized data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate delta time and flux\n",
    "# data = [batchSize, channels, [time, flux, err, mask], light curve]\n",
    "def generateDeltas(data, passBand):\n",
    "    \n",
    "    # work with delta time and magnitude\n",
    "    \n",
    "#     print(\"generate deltas input shape: {0}\".format(data.shape) )\n",
    "    # delta time\n",
    "    tmpDeltaTime = data[:, passBand, 0, 1:] - data[:, passBand, 0, :-1]\n",
    "\n",
    "#     print(\"generate deltas time shape: {0}\".format(tmpDeltaTime.shape) )\n",
    "\n",
    "#     # delta magnitude\n",
    "    tmpDeltaMagnitude = data[:, passBand, 1, 1:] - data[:, passBand, 1, :-1]\n",
    "#     print(\"generate deltas flux shape: {0}\".format(tmpDeltaMagnitude.shape))\n",
    "    \n",
    "    # concatenate tensors\n",
    "    dataToUse = torch.cat((tmpDeltaTime.unsqueeze(1), tmpDeltaMagnitude.unsqueeze(1)), 1)\n",
    "#     print(\"data to use shape: {0}\".format(dataToUse.shape))\n",
    "    \n",
    "    # normalize data\n",
    "    dataToUse = normalizeLightCurve(dataToUse)\n",
    "    \n",
    "    # returning data\n",
    "    return dataToUse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"299.4871904723042\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the training\n",
      "epoch:    0 / 1000\n",
      "early stopping counter:  2\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    1 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    2 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    3 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    4 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    5 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    6 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    7 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    8 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    9 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    10 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    11 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    12 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    13 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    14 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    15 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    16 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    17 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    18 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    19 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    20 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    21 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    22 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    23 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    24 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    25 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    26 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    27 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    28 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    29 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    30 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    31 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    32 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    33 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    34 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    35 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    36 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    37 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    38 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    39 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    40 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    41 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    42 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    43 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    44 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    45 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    46 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    47 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    48 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    49 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    50 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    51 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    52 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    53 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    54 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    55 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    56 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    57 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    58 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    59 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    60 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    61 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    62 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    63 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    64 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    65 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    66 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    67 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    68 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    69 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    70 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    71 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    72 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    73 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    74 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    75 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    76 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    77 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    78 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    79 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    80 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    81 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    82 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    83 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    84 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    85 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    86 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    87 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    88 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    89 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    90 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    91 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    92 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    93 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    94 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    95 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    96 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    97 / 1000\n",
      "saving losses\n",
      "epoch:    98 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    99 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    100 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    101 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    102 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    103 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    104 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    105 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    106 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    107 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    108 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    109 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    110 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    111 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    112 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    113 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    114 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    115 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    116 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    117 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    118 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    119 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    120 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    121 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    122 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    123 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    124 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    125 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    126 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    127 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    128 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    129 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    130 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    131 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    132 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    133 / 1000\n",
      "saving losses\n",
      "epoch:    134 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    135 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    136 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    137 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    138 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    139 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    140 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    141 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    142 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    143 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    144 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    145 / 1000\n",
      "saving losses\n",
      "epoch:    146 / 1000\n",
      "saving losses\n",
      "epoch:    147 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    148 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    149 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    150 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    151 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    152 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    153 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    154 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    155 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    156 / 1000\n",
      "saving losses\n",
      "epoch:    157 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    158 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    159 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    160 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    161 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    162 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    163 / 1000\n",
      "saving losses\n",
      "epoch:    164 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    165 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    166 / 1000\n",
      "saving losses\n",
      "epoch:    167 / 1000\n",
      "saving losses\n",
      "epoch:    168 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    169 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    170 / 1000\n",
      "saving losses\n",
      "epoch:    171 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    172 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    173 / 1000\n",
      "saving losses\n",
      "epoch:    174 / 1000\n",
      "saving losses\n",
      "epoch:    175 / 1000\n",
      "saving losses\n",
      "epoch:    176 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    177 / 1000\n",
      "saving losses\n",
      "epoch:    178 / 1000\n",
      "saving losses\n",
      "epoch:    179 / 1000\n",
      "saving losses\n",
      "epoch:    180 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    181 / 1000\n",
      "saving losses\n",
      "epoch:    182 / 1000\n",
      "saving losses\n",
      "epoch:    183 / 1000\n",
      "saving losses\n",
      "epoch:    184 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    185 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    186 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    187 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    188 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    189 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    190 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    191 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    192 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    193 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    194 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    195 / 1000\n",
      "New min test loss. Saving model\n",
      "saving losses\n",
      "epoch:    196 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    197 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    198 / 1000\n",
      "saving losses\n",
      "epoch:    199 / 1000\n",
      "early stopping counter:  2\n",
      "saving losses\n",
      "epoch:    200 / 1000\n",
      "early stopping counter:  4\n",
      "saving losses\n",
      "epoch:    201 / 1000\n",
      "early stopping counter:  6\n",
      "saving losses\n",
      "epoch:    202 / 1000\n",
      "early stopping counter:  8\n",
      "saving losses\n",
      "epoch:    203 / 1000\n",
      "early stopping counter:  10\n",
      "saving losses\n",
      "epoch:    204 / 1000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# loss function\n",
    "# criterion = torch.nn.MSELoss(reduction = \"sum\")\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# use of GPU flag\n",
    "use_gpu = True\n",
    "\n",
    "# load model on GPU\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "# number of epochs\n",
    "epochs = epochs\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# min global test loss \n",
    "minTestLossGlobalSoFar = float(\"inf\")\n",
    "\n",
    "# # loss plot\n",
    "fig, ax = plt.subplots(figsize = (3, 3), tight_layout = True)\n",
    "# fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Error\")\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.axis([0,1000,0,10])\n",
    "# plt.show()\n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 20\n",
    "\n",
    "print(\"starting the training\")\n",
    "\n",
    "for nepoch in range(epochs):\n",
    "        \n",
    "    print(\"epoch:    {0} / {1}\".format(nepoch, epochs))\n",
    "    \n",
    "#     print(\"\\r{0}\".format((float(nepoch)/epochs)*100))\n",
    "#     sys.stdout.write('\\r')\n",
    "#     # the exact output you're looking for:\n",
    "#     sys.stdout.write(\"[%-20s] %d%%\" % ('='*nepoch, 5*nepoch))\n",
    "#     sys.stdout.flush()\n",
    "#     sleep(0.25)\n",
    "    \n",
    "    # train\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data in trainLoader:\n",
    "        \n",
    "        data = data[0]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_gpu:\n",
    "            \n",
    "#             data = data.type(torch.FloatTensor).cuda()\n",
    "            data = generateDeltas(data, passband).type(torch.FloatTensor).cuda()\n",
    "#             print(data.device)\n",
    "#             print(model.device())\n",
    "            outputs = model.forward(data)\n",
    "            mu, logvar = model.encoder.forward(data.type(torch.FloatTensor).cuda())\n",
    "            \n",
    "        else:\n",
    "                        \n",
    "            data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "#             generateDeltas(data, 0)\n",
    "            outputs = model.forward(data.type(torch.FloatTensor))\n",
    "            mu, logvar = model.encoder.forward(data.type(torch.FloatTensor))\n",
    "        \n",
    "#         loss = criterion(outputs, data)\n",
    "        # use KLD + MSE\n",
    "        loss = loss_function(outputs, data, mu, logvar)\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    train_loss[nepoch] = epoch_train_loss / train_size\n",
    "    \n",
    "    # test\n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    for data in testLoader:\n",
    "        \n",
    "        data = data[0]\n",
    "        \n",
    "        if use_gpu:\n",
    "            \n",
    "            data = generateDeltas(data, passband).type(torch.FloatTensor).cuda()\n",
    "#             data = data.type(torch.FloatTensor).cuda()\n",
    "            outputs = model.forward(data)\n",
    "            mu, logvar = model.encoder.forward(data.type(torch.FloatTensor).cuda())\n",
    "        \n",
    "        else:\n",
    "#             data = data.type(torch.FloatTensor)\n",
    "            data = generateDeltas(data, passband).type(torch.FloatTensor)\n",
    "            \n",
    "            outputs = model.forward(data)\n",
    "            \n",
    "            mu, logvar = model.encoder.forward(data.type(torch.FloatTensor))\n",
    "        \n",
    "#         loss = criterion(outputs, data)\n",
    "        loss = loss_function(outputs, data, mu, logvar)\n",
    "        \n",
    "        epoch_test_loss += loss.item()\n",
    "    \n",
    "    test_loss[nepoch] = epoch_test_loss / test_size\n",
    "    \n",
    "#     # plot loss\n",
    "    ax.plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "    ax.plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\") \n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    #### Early stopping #####\n",
    "    \n",
    "    # if new test loss is greater than the older one\n",
    "    count_early_stop += 1\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        text_file = open(\"experiments/\" + number_experiment + \"/earlyStopping.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n ES counter: {1}\\n, Reconstruction test error: {2}\".format(nepoch, count_early_stop, epoch_test_loss)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "        break\n",
    "        \n",
    "    #### Saving best model ####\n",
    "    \n",
    "    # if epoch test loss is smaller than global min\n",
    "    if epoch_test_loss < minTestLossGlobalSoFar:\n",
    "        \n",
    "        print(\"New min test loss. Saving model\")\n",
    "#         print(\"old: \", minTestLossGlobalSoFar)\n",
    "#         print(\"new: \", epoch_test_loss)\n",
    "        \n",
    "        # save model\n",
    "        torch.save(model.state_dict(), pathToSaveModel)\n",
    "        \n",
    "        # update global min\n",
    "        minTestLossGlobalSoFar = epoch_test_loss\n",
    "        \n",
    "        # write metrics\n",
    "        text_file = open(\"experiments/\" + number_experiment + \"/bestScoresModelTraining.txt\", \"w\")\n",
    "        metricsText = \"Epoch: {0}\\n Reconstruction test error: {1}\".format(nepoch, minTestLossGlobalSoFar)\n",
    "        text_file.write(metricsText)\n",
    "        text_file.close()\n",
    "\n",
    "        \n",
    "    # save losses\n",
    "    print(\"saving losses\")\n",
    "    losses = np.asarray([train_loss, test_loss]).T\n",
    "    np.savetxt(\"experiments/\" + number_experiment + \"/training_losses.csv\", losses, delimiter=\",\")\n",
    "    \n",
    "    \n",
    "print(\"training has finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save loss arrays (train and testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"saving losses\")\n",
    "# losses = np.asarray([train_loss, test_loss]).T\n",
    "# np.savetxt(\"experiments/1/training_losses.csv\", losses, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"experiment has finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathToSaveModel = \"/home/leo/Desktop/thesis/work/thesis/models/model\"\n",
    "# pathToSaveModel = \"/home/lbravo/thesis/work/thesis/models/model_guanaco_1\"\n",
    "# add guanaco path\n",
    "\n",
    "# modelName = \"model\"\n",
    "\n",
    "# torch.save(model.state_dict(), pathToSaveModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model path\n",
    "# # pathToSaveModel = \"/home/leo/Desktop/thesis/work/thesis/models/model\"\n",
    "# pathToSaveModel = \"/home/lbravo/thesis/work/thesis/models/model_guanaco_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "# # defining model\n",
    "# model = AutoEncoder(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim)\n",
    "\n",
    "# # model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(pathToSaveModel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check reconstructed light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reconstruction\n",
    "# print(len(list(trainLoader)))\n",
    "\n",
    "# lID = 0\n",
    "\n",
    "# reconstructedLightCurve = model.forward(generateDeltas(list(trainLoader)[lID][0], 0))\n",
    "\n",
    "# # print(reconstructedLightCurve.shape)\n",
    "# # print(list(testLoader)[0][0].shape)\n",
    "# # # display(reconstructedLightCurve.detach().numpy()[0].shape)\n",
    "# # print(list(testLoader)[0][0][0, 1, :].shape)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# ax.plot(reconstructedLightCurve.detach().numpy()[0, 1, :], label = \"reconstructed\", color = \"red\")\n",
    "\n",
    "# # ax.plot(list(trainLoader)[lID][0][0, 1, :].detach().numpy(), label = \"original\", color = \"green\")\n",
    "\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Things to do:</font>\n",
    "- Define metrics for evaluate models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
