{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove this notebook. It was only for getting confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on guanaco\n",
    "# ATENTION: if it is going to run on guanaco, so comment the %matplotlib magic in next block\n",
    "trainingOnGuanaco = False\n",
    "\n",
    "# train without notebook\n",
    "trainWithJustPython = False\n",
    "\n",
    "# number_experiment (this is just a name)\n",
    "# priors:\n",
    "# 1\n",
    "number_experiment = 5\n",
    "number_experiment = str(number_experiment)\n",
    "\n",
    "# add general comment about experiment \n",
    "comment = \"training encoder as classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to analyze\n",
    "# 42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#        95,   6,  53, 994,  64\n",
    "only_these_labels = [16, 92, 53]\n",
    "# 53 has 24 light curves\n",
    "\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [16, 92]\n",
    "# only_these_labels = [42,  90,  16,  67,  62, 993,  92,  52,  88,  65, 991, 992,  15,\n",
    "#         95,   6,  53, 994,  64]\n",
    "\n",
    "# VAE parameters\n",
    "latentDim = 100\n",
    "hiddenDim = 100\n",
    "inputDim = 72\n",
    "\n",
    "# training\n",
    "epochs = 2000\n",
    "\n",
    "# band\n",
    "# passband = 5\n",
    "passband = 5\n",
    "\n",
    "batch_training_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "# import functions to load dataset\n",
    "import sys\n",
    "sys.path.append(\"./codesToDatasets\")\n",
    "from plasticc_dataset_torch import get_plasticc_datasets\n",
    "# from plasticc_plotting import plot_light_curve\n",
    "\n",
    "import math\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "pathToFile = \"/home/shared/astro/PLAsTiCC/\" if trainingOnGuanaco else \"/home/leo/Downloads/plasticc_torch-master/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset with pytorch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected lazy loading. Light curves will be loaded ondemand from the harddrive\n",
      "Found 3 csv files at given path\n",
      "Loading /home/leo/Downloads/plasticc_torch-master/plasticc_train_lightcurves.csv\n",
      "Loading /home/leo/Downloads/plasticc_torch-master/plasticc_test_set_batch1.csv\n",
      "Loading /home/leo/Downloads/plasticc_torch-master/plasticc_test_set_batch2.csv\n"
     ]
    }
   ],
   "source": [
    "# torch_dataset_lazy = get_plasticc_datasets(pathToFile)\n",
    "\n",
    "# Light curves are tensors are now [bands, [mjd, flux, err, mask],\n",
    "# lc_data, lc_label, lc_plasticc_id                              \n",
    "torch_dataset_lazy = get_plasticc_datasets(pathToFile, only_these_labels=only_these_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 25030\n",
      "validation size:  3129\n",
      "test size: 3129\n",
      "sum:  31288\n"
     ]
    }
   ],
   "source": [
    "# Spliting the data\n",
    "\n",
    "# print(torch_dataset_lazy.__len__())\n",
    "\n",
    "# selecting train splitting\n",
    "train_size = int(0.8 * torch_dataset_lazy.__len__())\n",
    "#print(train_size)\n",
    "\n",
    "# getting test splitting\n",
    "validation_size = math.floor((torch_dataset_lazy.__len__() - train_size)/2)\n",
    "#print(validation_size)\n",
    "\n",
    "# getting test splitting\n",
    "test_size = torch_dataset_lazy.__len__() - train_size - validation_size\n",
    "#print(test_size)\n",
    "\n",
    "# spliting the torch dataset\n",
    "trainDataset, validationDataset,  testDataset = torch.utils.data.random_split(torch_dataset_lazy, [train_size, validation_size, test_size])\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"validation size: \", validation_size)\n",
    "print(\"test size:\", test_size)\n",
    "print(\"sum: \", train_size+ validation_size + test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loader (minibatches)\n",
    "\n",
    "# # train loader\n",
    "trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size= batch_training_size, shuffle=True, num_workers = 4)\n",
    "\n",
    "# validation loader\n",
    "validationLoader = torch.utils.data.DataLoader(validationDataset, batch_size= batch_training_size, shuffle=True, num_workers = 4)\n",
    "\n",
    "# # test loader\n",
    "testLoader = torch.utils.data.DataLoader(testDataset)\n",
    "# trainLoader = torch.utils.data.DataLoader(torch_dataset_lazy, batch_size=256, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define autoencoder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementacion adaptada a 1D de https://github.com/naoto0804/pytorch-inpainting-with-partial-conv\n",
    "\n",
    "class PartialConv(nn.Module):\n",
    "    def __init__(self, in_channels_C,in_channels_M, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.input_conv = nn.Conv1d(in_channels_C, out_channels, kernel_size,\n",
    "                                    stride, padding, dilation, groups, bias)\n",
    "        self.mask_conv = nn.Conv1d(in_channels_M, out_channels, kernel_size,\n",
    "                                   stride, padding, dilation, groups, False)\n",
    "        # self.input_conv.apply(weights_init('kaiming'))\n",
    "\n",
    "        torch.nn.init.constant_(self.mask_conv.weight, 1.0)\n",
    "\n",
    "        # mask is not updated\n",
    "        for param in self.mask_conv.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self,input, mask):\n",
    "        # http://masc.cs.gmu.edu/wiki/partialconv\n",
    "        # C(X) = W^T * X + b, C(0) = b, D(M) = 1 * M + 0 = sum(M)\n",
    "        # W^T* (M .* X) / sum(M) + b = [C(M .* X) â€“ C(0)] / D(M) + C(0)\n",
    "        #print(input.shape, mask.shape)\n",
    "        output = self.input_conv(input * mask)\n",
    "        if self.input_conv.bias is not None:\n",
    "            output_bias = self.input_conv.bias.view(1, -1, 1).expand_as(output)\n",
    "        else:\n",
    "            output_bias = torch.zeros_like(output)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_mask = self.mask_conv(mask)\n",
    "\n",
    "        no_update_holes = output_mask == 0\n",
    "        mask_sum = output_mask.masked_fill_(no_update_holes, 1.0)\n",
    "\n",
    "        output_pre = (output - output_bias) / mask_sum + output_bias\n",
    "        output = output_pre.masked_fill_(no_update_holes, 0.0)\n",
    "\n",
    "        new_mask = torch.ones_like(output)\n",
    "        new_mask = new_mask.masked_fill_(no_update_holes, 0.0)\n",
    "\n",
    "        return output, new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building classifier\n",
    "\n",
    "# encoder\n",
    "class Encoder(torch.nn.Module):\n",
    "    \n",
    "\n",
    "    # init method\n",
    "    def __init__(self, latent_dim, hidden_dim, input_dim, num_classes):\n",
    "    \n",
    "    \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # 1 Convolution layer\n",
    "        # Conv1d(input channel, output channel, kernel size)\n",
    "#         self.conv1 = torch.nn.Conv1d(1,64,3)\n",
    "#         self.conv1 = torch.nn.Conv1d(1,64,3, stride = 2)\n",
    "        \n",
    "        # partial convolution\n",
    "        self.pconv1 = PartialConv(in_channels_C = 1,in_channels_M = 1, out_channels = 64, kernel_size = 3, stride=2, padding=0, dilation=1, bias=True)\n",
    "        \n",
    "        # 2 Convolution layer\n",
    "        # Conv1d(input channel, output channel, kernel size)\n",
    "#         self.conv2 = torch.nn.Conv1d(64, 32, 3)\n",
    "#         self.conv2 = torch.nn.Conv1d(64, 32, 3, stride = 2)\n",
    "        \n",
    "        # partial convolution\n",
    "        self.pconv2 = PartialConv(in_channels_C = 64,in_channels_M = 64, out_channels = 32, kernel_size = 3, stride=2, padding=0, dilation=1, bias=True)\n",
    "        \n",
    "        \n",
    "        # linear layer\n",
    "#         self.hidden1 = torch.nn.Linear(2144*2, hidden_dim)\n",
    "#         self.hidden1 = torch.nn.Linear(1088, hidden_dim)\n",
    "        self.hidden1 = torch.nn.Linear(1632, hidden_dim)\n",
    "        \n",
    "#         self.hidden2 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # output layer\n",
    "        self.outputLayer = torch.nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "        # activation function\n",
    "        self.activationConv = torch.nn.ReLU() #max(0, x)\n",
    "#         self.activationConv = torch.nn.Tanh()\n",
    "    \n",
    "        # this works well.(comparing with relu)\n",
    "        self.activationLinear = torch.nn.Tanh()\n",
    "\n",
    "        # this is getting nan values\n",
    "#         self.activationLinear = torch.nn.ReLU()\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # input shape: [batch_size, channels, sequence_length]\n",
    "        # print(\"input shape: {0}\".format(x.shape))\n",
    "#         print(\"input to encoder: \")\n",
    "#         print(x.shape)\n",
    "        \n",
    "        # convolution 1\n",
    "        # x -> conv -> act -> ouput\n",
    "        # shape should be: [batch_size, number of ouput channels (64), length of output from convolution]\n",
    "        \n",
    "        #conv to time\n",
    "        # normal convolution\n",
    "#         outputTimeConv = self.activationConv(self.conv1Time(x[:, 0, :].unsqueeze(1)))\n",
    "#         outputTimeConv = self.activationConv(self.conv1(x[:, 0, :].unsqueeze(1)))\n",
    "        # partial conv\n",
    "        # output, newMask = pconv1(data, mask)\n",
    "        outputTimeConv, maskTime = self.pconv1(x[:, 0, :].unsqueeze(1), x[:, 3, :].unsqueeze(1))\n",
    "        # activation function\n",
    "        outputTimeConv = self.activationConv(outputTimeConv)\n",
    "        \n",
    "        \n",
    "        # conv to magnitude\n",
    "#         outputMagConv = self.activationConv(self.conv1Mag(x[:, 1, :].unsqueeze(1)))\n",
    "#         outputMagConv = self.activationConv(self.conv1(x[:, 1, :].unsqueeze(1)))\n",
    "        \n",
    "        # partial conv\n",
    "        # output, newMask = pconv1(data, mask)\n",
    "        outputMagConv, maskMag = self.pconv1(x[:, 1, :].unsqueeze(1), x[:, 3, :].unsqueeze(1))\n",
    "        # activation function\n",
    "        outputMagConv = self.activationConv(outputMagConv)\n",
    "        \n",
    "        \n",
    "        # conv to mag error\n",
    "#         outputMagErrorConv = self.activationConv(self.conv1(x[:, 2, :].unsqueeze(1)))\n",
    "        \n",
    "        # partial conv\n",
    "        # output, newMask = pconv1(data, mask)\n",
    "        outputMagErrorConv, maskError = self.pconv1(x[:, 2, :].unsqueeze(1), x[:, 3, :].unsqueeze(1))\n",
    "        # activation function\n",
    "        outputMagErrorConv = self.activationConv(outputMagErrorConv)\n",
    "        \n",
    "#         print(\"output conv1 shape: {0}\".format(outputMagConv.shape))\n",
    "#         print(\"output conv1 shape: {0}\".format(outputTimeConv.shape))\n",
    "        \n",
    "        # convolution 2\n",
    "#         # shape should be: [batch_size, number of ouput channels (32), length of output from convolution]\n",
    "        \n",
    "        \n",
    "        # conv to time\n",
    "#         outputTimeConv = self.activationConv(self.conv2(outputTimeConv))\n",
    "        \n",
    "        # partial conv\n",
    "        outputTimeConv, maskTime = self.pconv2(outputTimeConv, maskTime)\n",
    "        outputTimeConv = self.activationConv(outputTimeConv)\n",
    "        \n",
    "        \n",
    "        # conv to flux\n",
    "#         outputMagConv = self.activationConv(self.conv2(outputMagConv))\n",
    "        # part conv\n",
    "        outputMagConv, maskMag = self.pconv2(outputMagConv, maskMag)\n",
    "        outputMagConv = self.activationConv(outputMagConv)\n",
    "        \n",
    "        # conv to mag error\n",
    "#         outputMagErrorConv = self.activationConv(self.conv2(outputMagErrorConv))\n",
    "        # partial conv\n",
    "        outputMagErrorConv, maskError = self.pconv2(outputMagErrorConv, maskError)\n",
    "        outputMagErrorConv = self.activationConv(outputMagErrorConv)\n",
    "        \n",
    "#         print(\"output conv2 shape: {0}\".format(outputTimeConv.shape))\n",
    "#         print(\"output conv2 shape: {0}\".format(outputMagConv.shape))\n",
    "        \n",
    "        # flatten ouput\n",
    "        # shape should be: [batch_size, -1]\n",
    "        outputMagConv = outputMagConv.view(outputMagConv.shape[0], -1)\n",
    "        \n",
    "        outputTimeConv = outputTimeConv.view(outputTimeConv.shape[0], -1)\n",
    "        \n",
    "        outputMagErrorConv = outputMagErrorConv.view(outputMagErrorConv.shape[0], -1)\n",
    "        \n",
    "#         print(\"output reshape: \", outputMagConv.shape)\n",
    "#         print(\"output reshape: \", outputTimeConv.shape)\n",
    "                \n",
    "        # concatenate 3 towers\n",
    "#         output = torch.cat((outputMagConv, outputTimeConv), 1)\n",
    "        output = torch.cat((outputTimeConv, outputMagConv, outputMagErrorConv), 1)\n",
    "#         print(\"concatenate output shape: \", output.shape)\n",
    "        \n",
    "        # x -> hidden1 -> activation\n",
    "#         print(\"before linear layer: {0}\".format(output.shape))\n",
    "        output = self.activationLinear(self.hidden1(output))\n",
    "        # Should be an activiation function here?\n",
    "#         output = (self.hidden1(output))\n",
    "        \n",
    "        output = self.outputLayer(output)\n",
    "        \n",
    "        # this should return the classification\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (pconv1): PartialConv(\n",
       "    (input_conv): Conv1d(1, 64, kernel_size=(3,), stride=(2,))\n",
       "    (mask_conv): Conv1d(1, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
       "  )\n",
       "  (pconv2): PartialConv(\n",
       "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
       "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
       "  )\n",
       "  (hidden1): Linear(in_features=1632, out_features=100, bias=True)\n",
       "  (outputLayer): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (activationConv): ReLU()\n",
       "  (activationLinear): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of parameters\n",
    "# latentDim = 5\n",
    "# hiddenDim = 10\n",
    "# inputDim = 72\n",
    "\n",
    "latentDim = latentDim\n",
    "hiddenDim = hiddenDim\n",
    "inputDim = inputDim\n",
    "\n",
    "passband = passband\n",
    "\n",
    "num_classes = len(only_these_labels)\n",
    "\n",
    "\n",
    "# defining model\n",
    "model = Encoder(latent_dim = latentDim, hidden_dim = hiddenDim, input_dim = inputDim, num_classes = num_classes)\n",
    "\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (pconv1): PartialConv(\n",
      "    (input_conv): Conv1d(1, 64, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(1, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (pconv2): PartialConv(\n",
      "    (input_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,))\n",
      "    (mask_conv): Conv1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "  )\n",
      "  (hidden1): Linear(in_features=1632, out_features=100, bias=True)\n",
      "  (outputLayer): Linear(in_features=100, out_features=3, bias=True)\n",
      "  (activationConv): ReLU()\n",
      "  (activationLinear): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it builds a mask for the deltas. It compares the next with the previous one element.\n",
    "# original mask: [1,1, 0, 0]\n",
    "# delta mask: [1, 0, 0]\n",
    "# The same results is got with original_mask[:, 1:]\n",
    "def generate_delta_mask(mask):\n",
    "    \n",
    "    # generate delta mask\n",
    "#     mask_delta = mask[:, 1:].type(torch.BoolTensor) & mask[:, :-1].type(torch.BoolTensor)\n",
    "    mask_delta = mask[:, 1:]\n",
    "    \n",
    "    return mask_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate delta time and flux\n",
    "# data = [batchSize, channels, [time, flux, err, mask], light curve]\n",
    "def generateDeltas(data, passBand):\n",
    "    \n",
    "    # work with delta time and magnitude\n",
    "    \n",
    "#     print(\"generate deltas input shape: {0}\".format(data.shape) )\n",
    "    # delta time\n",
    "    tmpDeltaTime = data[:, passBand, 0, 1:] - data[:, passBand, 0, :-1]\n",
    "\n",
    "#     print(\"generate deltas time shape: {0}\".format(tmpDeltaTime.shape) )\n",
    "\n",
    "#     # delta magnitude\n",
    "    tmpDeltaMagnitude = data[:, passBand, 1, 1:] - data[:, passBand, 1, :-1]\n",
    "#     print(\"generate deltas flux shape: {0}\".format(tmpDeltaMagnitude.shape))\n",
    "    \n",
    "    # delta errors\n",
    "    tmpDeltaMagError = data[:, passBand, 2, 1:] - data[:, passBand, 2, :-1]\n",
    "    \n",
    "    # delta mask\n",
    "    tmpMask = generate_delta_mask(data[:, passBand, 3,:])\n",
    "    \n",
    "    # concatenate tensors\n",
    "    dataToUse = torch.cat((tmpDeltaTime.unsqueeze(1), tmpDeltaMagnitude.unsqueeze(1), tmpDeltaMagError.unsqueeze(1), tmpMask.unsqueeze(1)), 1)\n",
    "#     print(\"data to use shape: {0}\".format(dataToUse.shape))\n",
    "    \n",
    "    # normalize data\n",
    "    # this was commented because it considerate that delta is already a normalization\n",
    "#     dataToUse = normalizeLightCurve(dataToUse)\n",
    "    \n",
    "    # returning data\n",
    "    return dataToUse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping the labels to classes 0 to C-1\n",
    "\n",
    "def mapLabels(labels):\n",
    "\n",
    "    for i in range(len(only_these_labels)):\n",
    "        \n",
    "        labels[labels == only_these_labels[i]] = i \n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathToSaveModel = \"/home/lbravo/thesis/thesis/work/thesis/experiments/\" + number_experiment + \"/model\" if trainingOnGuanaco else \"/home/leo/Desktop/thesis/work/thesis/experiments/\" + number_experiment + \"/model\"\n",
    "\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(pathToSaveModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get y true and labels\n",
    "\n",
    "predictions = np.zeros(shape = (0,))\n",
    "labels_ = np.zeros(shape = (0,))\n",
    "\n",
    "# minibatches\n",
    "for data_ in validationLoader:\n",
    "        \n",
    "    data = data_[0].cuda()\n",
    "    labels = data_[1].cuda()\n",
    "\n",
    "    data = generateDeltas(data, passband).type(torch.FloatTensor).cuda()\n",
    "\n",
    "    outputs = model.forward(data)\n",
    "    \n",
    "    prediction = torch.argmax(outputs, 1).cpu().numpy()\n",
    "\n",
    "    label = mapLabels(labels).cpu().numpy()\n",
    "    \n",
    "    predictions = np.append(predictions, prediction)\n",
    "    labels_ = np.append(labels_, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1071   34    0]\n",
      " [  72 1929    0]\n",
      " [   0    0   23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.95      1105\n",
      "         1.0       0.98      0.96      0.97      2001\n",
      "         2.0       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           0.97      3129\n",
      "   macro avg       0.97      0.98      0.98      3129\n",
      "weighted avg       0.97      0.97      0.97      3129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(labels_, predictions)\n",
    "\n",
    "print(cm)\n",
    "# print(\"saving confusion matrix scores\")\n",
    "# np.savetxt(\"experiments/\" + number_experiment + \"/confusionMatrix.csv\", cm, delimiter=\",\")\n",
    "\n",
    "\n",
    "# np.savetxt(\"experiments/\" + number_experiment + \"/clasificationReport.txt\", classification_report(labels_, predictions))\n",
    "\n",
    "print(classification_report(labels_, predictions))\n",
    "\n",
    "# print(\"saving clasification report\")\n",
    "# text_file = open(\"experiments/\" + number_experiment + \"/clasificationReport.txt\", \"w\")\n",
    "# text = classification_report(labels_, predictions)\n",
    "# text_file.write(text)\n",
    "# text_file.close()\n",
    "# print(\"experiment parameters file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9329.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>686.0</td>\n",
       "      <td>19165.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1      2\n",
       "0  9329.0    317.0    0.0\n",
       "1   686.0  19165.0    4.0\n",
       "2     0.0     11.0  125.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cm = pd.read_csv('./experiments/5/confusionMatrix.csv', header = None) \n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5462881b50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "sn.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "         0.0       0.93      0.97      0.95      9646\r\n",
      "         1.0       0.98      0.97      0.97     19855\r\n",
      "         2.0       0.97      0.92      0.94       136\r\n",
      "\r\n",
      "    accuracy                           0.97     29637\r\n",
      "   macro avg       0.96      0.95      0.96     29637\r\n",
      "weighted avg       0.97      0.97      0.97     29637\r\n"
     ]
    }
   ],
   "source": [
    "cat ./experiments/5/clasificationReport.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
