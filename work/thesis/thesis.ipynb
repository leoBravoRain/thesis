{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# %matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to dataset\n",
    "\n",
    "# path to file in guanaco\n",
    "# pathToFile = \"/home/shared/astro/PLAsTiCC/\"\n",
    "\n",
    "# path to file in local \n",
    "pathToFile = \"/home/leo/Desktop/thesis/work/plasticc_dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Things to do:</font>\n",
    "- Use all the data (not just training)\n",
    "- Using only a specific type of astronomical object (variable stars used in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train path\n",
    "trainPath = \"plasticc_train_lightcurves.csv\"\n",
    "trainMetaPath = \"plasticc_train_metadata.csv\"\n",
    "\n",
    "# load in df\n",
    "df1 = pd.read_csv(pathToFile + trainPath)\n",
    "mdf1 = pd.read_csv(pathToFile + trainMetaPath)\n",
    "\n",
    "# display head\n",
    "display(df1.head())\n",
    "display(mdf1.head())\n",
    "\n",
    "# merge dataframes\n",
    "# merging data using object_id \n",
    "mdf1 = df1.merge(mdf1, on = \"object_id\")\n",
    "\n",
    "# display merged data\n",
    "display(mdf1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing dataframe shapes\n",
    "print(\"Shape of data to work: \", mdf1.shape)\n",
    "print(\"Unique targets: \", mdf1.true_target.unique().shape[0])\n",
    "print(\"targets: \", mdf1.true_target.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting one light curve\n",
    "To check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one light curve\n",
    "oneLightCurve = mdf1[mdf1[\"object_id\"] == 713]\n",
    "\n",
    "# display plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(oneLightCurve[\"mjd\"], oneLightCurve[\"flux\"])\n",
    "ax.set_xlabel(\"MJD (date)\")\n",
    "ax.set_ylabel(\"Flux (bright)\")\n",
    "ax.set_title(\"Light curve for an specific object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formating dataset to work\n",
    "- Change name to dataframe (for simplicity)\n",
    "\n",
    "- Select useful variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Things to do:</font>\n",
    "- Are we going to work only with \"flux\"? (Maybe flux error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change name to dataframe\n",
    "lightCurves = mdf1\n",
    "\n",
    "# for take only a part of classes and remove anothers ones\n",
    "# lightCurves = lightCurves.loc[lightCurves[\"true_target\"].isin(classesToAnalyze)]\n",
    "\n",
    "# filter by passband\n",
    "# for simplicity selecting one passband\n",
    "lightCurves = lightCurves[lightCurves.passband == 1]\n",
    "\n",
    "\n",
    "# getting only useful features\n",
    "lightCurves = lightCurves[[\"object_id\", \"mjd\", \"flux\", \"flux_err\", \"true_target\"]]\n",
    "lightCurves = lightCurves.rename(columns={\"true_target\": \"target\"})\n",
    "# display(lightCurves.head())\n",
    "\n",
    "\n",
    "# printing information\n",
    "display(lightCurves.head())\n",
    "print(\"data shape: \", lightCurves.shape)\n",
    "print(\"original objects ids: \", lightCurves.object_id.unique().shape)\n",
    "# print(\"original classes: \", lightCurves.true_target.unique().shape)\n",
    "print(\"original classes: \", lightCurves.target.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Things to do:</font>\n",
    "- Is the StandarScaler correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarizing variables\n",
    "# this returns a numpy array\n",
    "stdLightCurves = StandardScaler().fit_transform(lightCurves.loc[:, [\"flux\", \"flux_err\"]])\n",
    "display(stdLightCurves.shape)\n",
    "\n",
    "# create new array wth standarized data\n",
    "lightCurvesStd = lightCurves\n",
    "# overwrite data\n",
    "lightCurvesStd[\"flux\"] = stdLightCurves[:, 0]\n",
    "lightCurvesStd[\"flux_err\"] = stdLightCurves[:, 1]\n",
    "\n",
    "#printing dataset\n",
    "display(lightCurvesStd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction with Variatonal Autoencoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formating data to train VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining data to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Things to do:</font>\n",
    "- We have to use the \"paper\" data forma (detla time and delta flux)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "# selecting columns to use\n",
    "variableIndexStart = 2\n",
    "variableIndexEnd = -2\n",
    "\n",
    "# define data to use\n",
    "dataToUse = lightCurvesStd.iloc[:, variableIndexStart:variableIndexEnd].values\n",
    "\n",
    "# display data shape\n",
    "display(dataToUse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform dataset to light curves dataset \n",
    "Because all the light curves have different lenghts, I am going to take a specific number of sample for each light curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Things to do:</font>\n",
    "- Is it correct to \"truncate\" the light curve to a fixed length?\n",
    "- If we work with variable starts, maybe we can apply margin technique (paper) to fill the missed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  check the different lenghts of all light curves\n",
    "lightCurvesLenght = np.zeros(shape = (lightCurvesStd.object_id.unique().shape[0],))\n",
    "\n",
    "# transform ethe data set into array: [light curve,]\n",
    "for i, objectId in enumerate(lightCurvesStd.object_id.unique()):\n",
    "    \n",
    "#     print(objectId)\n",
    "    lightCurvesLenght[i] = lightCurvesStd[lightCurvesStd.object_id == objectId].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(lightCurvesLenght, bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to select a fixed lenght for each light curve of specific points for each light curve\n",
    "\n",
    "# selecting the fixed lenght for each light curve\n",
    "count = 0\n",
    "lengthToSelect = 50\n",
    "\n",
    "for i, objectId in enumerate(lightCurvesStd.object_id.unique()):\n",
    "    if lightCurvesStd[lightCurvesStd.object_id == objectId].shape[0] > lengthToSelect:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking df es working correctly\n",
    "lightCurvesStd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset with new fixed lenght of each llight curve\n",
    "lightCurvesById = np.zeros(shape = (count, lengthToSelect))\n",
    "i_ = 0\n",
    "\n",
    "for i, objectId in enumerate(lightCurvesStd.object_id.unique()):\n",
    "    \n",
    "    if lightCurvesStd[lightCurvesStd.object_id == objectId].shape[0] > lengthToSelect:\n",
    "        \n",
    "        lightCurvesById[i_, :] = lightCurvesStd[lightCurvesStd.object_id == objectId][\"flux\"][0:lengthToSelect]\n",
    "        \n",
    "        i_ += 1\n",
    "        \n",
    "lightCurvesById.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset is an array where each row is a time serie of fixed length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check visualizelly the correctnes of array\n",
    "# display(lightCurvesById)\n",
    "plt.figure()\n",
    "plt.plot(lightCurvesById[10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "torchData = torch.from_numpy(lightCurvesById).float()\n",
    "\n",
    "# torchData.shape\n",
    "\n",
    "# targets\n",
    "# target is the same as \n",
    "# torchTargets = torch.tensor(lightCurvesStd.iloc[:, -1].values).float()\n",
    "\n",
    "# creating dataset\n",
    "dataset = data.TensorDataset(torchData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data\n",
    "\n",
    "# selecting train splitting\n",
    "train_size = int(0.8 * lightCurvesById.shape[0])\n",
    "\n",
    "# getting test splitting\n",
    "test_size = lightCurvesById.shape[0] - train_size\n",
    "\n",
    "# spliting the torch dataset\n",
    "trainDataset, testDataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "# Create data loader (minibatches)\n",
    "\n",
    "# train loader\n",
    "trainLoader = data.DataLoader(trainDataset, batch_size=256)\n",
    "\n",
    "# test loader\n",
    "testLoader = data.DataLoader(testDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define autoencoder structure\n",
    "To start with the work, It is going to build a very basic Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Things to do:</font>\n",
    "- Is it correct the structure? Because the distribution function is in the reparametize function (assuming it is normal distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buiding autoencoder\n",
    "\n",
    "# Assuming this has a normal distrubtion in the latent part\n",
    "\n",
    "# encoder\n",
    "class Encoder(torch.nn.Module):\n",
    "    \n",
    "    # init method\n",
    "    def __init__(self, latent_dim, hidden_dim, input_dim):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # 1 Convolution layer\n",
    "        # Conv1d(input channel, output channel, kernel size)\n",
    "        self.conv1 = torch.nn.Conv1d(1, 64, 3)\n",
    "        \n",
    "        # 2 Convolution layer\n",
    "        # Conv1d(input channel, output channel, kernel size)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 32, 3)\n",
    "        \n",
    "        # linear layer\n",
    "        self.hidden1 = torch.nn.Linear(1472, hidden_dim)\n",
    "        \n",
    "        # mu\n",
    "        self.mu = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # sigma\n",
    "        self.sigma = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # activation function\n",
    "        self.activationConv = torch.nn.ReLU() #max(0, x)\n",
    "    \n",
    "        self.activationLinear = torch.nn.Tanh()\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "            \n",
    "#         print(\"input shape: {0}\".format(x.shape))\n",
    "        \n",
    "         # Input shape to conv:\n",
    "        # [batch_size, channels, sequence_length]\n",
    "        # reshapa data (add number of channels)\n",
    "        # shape should be: [batch_size, 1 channel, lenght of light curve (50)]\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "#         print(\"input reshape: {0}\".format(x.shape))\n",
    "        \n",
    "        # convolution 1\n",
    "        # x -> conv -> act -> ouput\n",
    "        # shape should be: [batch_size, number of ouput channels (64), length of output from convolution]\n",
    "        output = self.activationConv(self.conv1(x))\n",
    "        \n",
    "#         print(\"output conv1 shape: {0}\".format(output.shape))\n",
    "        \n",
    "        # convolution 2\n",
    "        # shape should be: [batch_size, number of ouput channels (32), length of output from convolution]\n",
    "        output = self.activationConv(self.conv2(output))\n",
    "#         print(\"output conv2 shape: {0}\".format(output.shape))\n",
    "        \n",
    "        # flatten ouput\n",
    "        # shape should be: [batch_size, -1]\n",
    "        output = output.view(output.shape[0], -1)\n",
    "        \n",
    "#         print(\"output reshape: \", output.shape)\n",
    "        \n",
    "        # x -> hidden1 -> activation\n",
    "        output = self.activationLinear(self.hidden1(output))\n",
    "#         print(\"hidden1 output shape: {0}\".format(output.shape))\n",
    "        \n",
    "#         output = self.activation(self.hidden2(output))\n",
    "        \n",
    "        # get mu\n",
    "        mu = self.activationLinear(self.mu(output))\n",
    "#         print(\"mu shape: {0}\".format(mu.shape))\n",
    "        \n",
    "        # get sigma\n",
    "        sigma = self.activationLinear(self.sigma(output))\n",
    "#         print(\"sigma shape: {0}\".format(sigma.shape))\n",
    "        \n",
    "        # returning values\n",
    "        return mu, sigma\n",
    "\n",
    "    \n",
    "# decoder    \n",
    "class Decoder(torch.nn.Module):\n",
    "    \n",
    "    # define layers\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # linear layer\n",
    "        self.hidden1 = torch.nn.Linear(latent_dim, 1472)\n",
    "        \n",
    "        # 1 ConvolutionTrans layer\n",
    "        self.convTrans1 = torch.nn.ConvTranspose1d(32, 64, 3)\n",
    "        \n",
    "        # 2 ConvolutionTrans layer\n",
    "        self.convTrans2 = torch.nn.ConvTranspose1d(64, 1, 3)\n",
    "\n",
    "        # activation function\n",
    "        self.activationConv = torch.nn.ReLU() #max(0, x)\n",
    "    \n",
    "        self.activationLinear = torch.nn.Tanh()\n",
    "        \n",
    "    # forward method\n",
    "    def forward(self, z):\n",
    "        \n",
    "#         print(\"input dimension decoder: {0}\".format(z.shape))\n",
    "        \n",
    "        # linear (from latent to hidden dimension)\n",
    "        # z -> linaer layer -> activation -> output\n",
    "        output = self.activationLinear(self.hidden1(z))\n",
    "#         print(\"output hidden1: {0}\".format(output.shape))\n",
    "        \n",
    "        # reshape (I don't know if it is correct)\n",
    "        # output = output.view(output.shape[0], 1, -1)\n",
    "        output = output.view(output.shape[0], 32, -1)\n",
    "#         print(\"output reshape: {0}\".format(output.shape))\n",
    "        \n",
    "        # 1 convolution\n",
    "        output = self.activationConv(self.convTrans1(output))\n",
    "#         print(\"ouput convTrans1: {0}\".format(output.shape))\n",
    "        \n",
    "        # 2 convolution\n",
    "        output = self.activationConv(self.convTrans2(output))\n",
    "#         print(\"ouput convTrans2: {0}\".format(output.shape))\n",
    "        \n",
    "        # remove one dimensionl (channel)\n",
    "        output = output.view(output.shape[0], -1)\n",
    "#         print(\"remove channel: {0}\".format(output.shape))\n",
    "        \n",
    "        # Maybe add activation function?\n",
    "#         return (self.decode(output))\n",
    "        return output\n",
    "\n",
    "# building the autoencoder     \n",
    "class AutoEncoder(torch.nn.Module):\n",
    "    \n",
    "    # defining the initial structure\n",
    "    def __init__(self, latent_dim, hidden_dim, input_dim = lightCurvesById.shape[1]):\n",
    "        \n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # defining the encoder\n",
    "        self.encoder = Encoder(latent_dim, hidden_dim, input_dim)\n",
    "        \n",
    "        # defining the decoder\n",
    "        # note the output dimension in the decoder is the same as input dimension\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "\n",
    "    # distribution function\n",
    "    def sampling(self, mu, sigma):\n",
    "        \n",
    "        # assumming normal distribution\n",
    "        s = torch.exp(0.5*sigma)\n",
    "        eps = torch.rand_like(s) # generate a iid standard normal same shape as s\n",
    "        return eps.mul(s).add_(mu)\n",
    "    \n",
    "    # forward method (how to the nn works)\n",
    "    def forward(self, x):\n",
    "        \n",
    "#         print(\"input size: {0}\".format(x.shape))\n",
    "        \n",
    "#         print(\"## Encoder ##\")\n",
    "        # input (x) -> encoder -> latent variables\n",
    "        mu, sigma = self.encoder(x)\n",
    "#         print(\"output encoder size: {0}\".format(encOutput.shape))\n",
    "    \n",
    "        # getting sample\n",
    "        # mu, sigma -> distribution -> z\n",
    "        z = self.sampling(mu, sigma)\n",
    "            \n",
    "#         print(\"## Dencoder ##\")\n",
    "        # latent variables -> decoder -> reconstruction (x)\n",
    "#         decOutput = self.decoder(encOutput)\n",
    "        decOutput = self.decoder(z)\n",
    "#         print(\"output decoder size: {0}\".format(decOutput.shape))\n",
    "        \n",
    "        return decOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of parameters\n",
    "latentDim = 5\n",
    "hiddenDim = 5\n",
    "\n",
    "# defining model\n",
    "model = AutoEncoder(latent_dim = latentDim, hidden_dim = hiddenDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"input dimension: {0}\".format(lightCurvesById.shape))\n",
    "\n",
    "# parameters number\n",
    "count = 0\n",
    "\n",
    "# # check model dimension\n",
    "for name, param in model.state_dict().items():\n",
    "    # name: str\n",
    "    # param: Tensor\n",
    "#     print(\"{0}: {1} \\n\".format(name, param.shape))\n",
    "#     print(param.shape[0]*(param.shape[1] if len(param.shape)>1 else 1))\n",
    "#     print(param.shape)\n",
    "    count += param.shape[0]*(param.shape[1] if len(param.shape)>1 else 1)\n",
    "# for param in model.parameters():\n",
    "    \n",
    "print(\"number of parameters: \" + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Things to do:</font>\n",
    "- Is it correct this loss function? Or just use: \"criterion = torch.nn.MSELoss(reduction = \"sum\") \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \n",
    "#     print(\"reconstruction: {0}\".format(recon_x))\n",
    "#     print(\"x: {0}\".format(x))\n",
    "#     print(\"mu: {0}\".format(mu))\n",
    "#     print(\"logvar: {0}\".format(logvar))\n",
    "    \n",
    "#     BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    BCE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "#     print(BCE)\n",
    "    \n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = torch.nn.MSELoss(reduction = \"sum\")\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# use of GPU flag\n",
    "use_gpu = False\n",
    "\n",
    "# load model on GPU\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "# number of epochs\n",
    "epochs = 1000000\n",
    "\n",
    "# loss\n",
    "train_loss = np.zeros((epochs,))\n",
    "test_loss = np.zeros((epochs,))\n",
    "\n",
    "# loss plot\n",
    "fig, ax = plt.subplots(figsize = (3, 3), tight_layout = True)\n",
    "# fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Error\")\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.axis([0,1000,0,10])\n",
    "# plt.show()\n",
    "\n",
    "# early stopping\n",
    "prior_test_error = 0\n",
    "count_early_stop = 0\n",
    "threshold_early_stop = 100\n",
    "\n",
    "for nepoch in tqdm_notebook(range(epochs)):\n",
    "    \n",
    "#     print(\"epoch: {0}\".format(nepoch))\n",
    "    \n",
    "    # train\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for data in trainLoader:\n",
    "        \n",
    "        data = data[0]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_gpu:\n",
    "            \n",
    "            data = data.type(torch.FloatTensor).cuda()\n",
    "            outputs = model.forward(data.type(torch.FloatTensor).cuda())\n",
    "            mu, logvar = model.encoder.forward(data.type(torch.FloatTensor).cuda())\n",
    "            \n",
    "        else:\n",
    "                        \n",
    "            data = data.type(torch.FloatTensor)\n",
    "            outputs = model.forward(data.type(torch.FloatTensor))\n",
    "            mu, logvar = model.encoder.forward(data.type(torch.FloatTensor))\n",
    "        \n",
    "#         loss = criterion(outputs, data)\n",
    "        # use KLD + MSE\n",
    "        loss = loss_function(outputs, data, mu, logvar)\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    train_loss[nepoch] = epoch_train_loss\n",
    "    \n",
    "#     print(train_loss)\n",
    "    \n",
    "    # test\n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    for data in testLoader:\n",
    "        \n",
    "        data = data[0]\n",
    "        \n",
    "        if use_gpu:\n",
    "            \n",
    "            data = data.type(torch.FloatTensor).cuda()\n",
    "            outputs = model.forward(data.cuda())\n",
    "            mu, logvar = model.encoder.forward(data.type(torch.FloatTensor).cuda())\n",
    "        else:\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            \n",
    "            outputs = model.forward(data)\n",
    "            \n",
    "            mu, logvar = model.encoder.forward(data.type(torch.FloatTensor))\n",
    "        \n",
    "#         loss = criterion(outputs, data)\n",
    "        loss = loss_function(outputs, data, mu, logvar)\n",
    "        \n",
    "        epoch_test_loss += loss.item()\n",
    "    \n",
    "    test_loss[nepoch] = epoch_test_loss\n",
    "    \n",
    "    # plot loss\n",
    "    ax.plot(train_loss[0: nepoch], label = \"train\", linewidth = 3, c = \"red\") \n",
    "    ax.plot(test_loss[0: nepoch], label = \"test\", linestyle = \"--\", linewidth = 3, c = \"green\") \n",
    "    \n",
    "    fig.canvas.draw()\n",
    "#     plt.pause(0.000005)\n",
    "    \n",
    "        # Early stopping\n",
    "    if epoch_test_loss > prior_test_error:\n",
    "        count_early_stop += 1\n",
    "        print(\"early stopping counter: \", count_early_stop)\n",
    "    else: \n",
    "        count_early_stop = 0\n",
    "    \n",
    "    # update prior test error\n",
    "    prior_test_error = epoch_test_loss\n",
    "    \n",
    "    # analyze early stopping\n",
    "    if count_early_stop > threshold_early_stop:\n",
    "        \n",
    "        print(\"Early stopping in epoch: \", nepoch)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction\n",
    "reconstructedLightCurve = model.forward(data.type(torch.FloatTensor))\n",
    "# display(reconstructedLightCurve.detach().numpy()[0])\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(reconstructedLightCurve.detach().numpy()[0], label = \"reconstructed\", color = \"red\")\n",
    "ax.plot(data.detach().numpy()[0], label = \"original\", color = \"blue\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Things to do:</font>\n",
    "- Define metrics for evaluate models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
